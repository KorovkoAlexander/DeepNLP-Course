{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vacV4BIFI8l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  quora.zip\n",
      "  inflating: train.csv               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alexander/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip3 -qq install torch==0.4.1\n",
    "#!pip install -q --upgrade nltk gensim bokeh pandas\n",
    "\n",
    "!wget -O quora.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ERtxpdWOgGQ3HOigqAMHTJjmOE_tWvoF\"\n",
    "!unzip quora.zip\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIFSTdJG95SZ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbpWIAreB6ky"
   },
   "source": [
    "# Введение в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_M0mMOadG8aZ"
   },
   "source": [
    "PyTorch - это один из самых известных фреймворков для работы с нейронными сетями.\n",
    "\n",
    "Почему именно он? Ну, он няшен, питоняч и проще в отладке - по сравнению с монстрами типа tensoflow (хотя tf 2.0 с eager execution будет примерно таким же).\n",
    "\n",
    "И вообще, мы тут не фреймворки, а сеточки учить собирались :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsScdJ7DLZCm"
   },
   "source": [
    "## Автоматическое дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bY9FHLM-M4aW"
   },
   "source": [
    "### Графы вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkvCloDpNXdH"
   },
   "source": [
    "Графы вычислений - это такой удобный способ быстро считать градиенты сложных-пресложных функций.\n",
    "\n",
    "Например, функция\n",
    "\n",
    "$$f = (x + y) \\cdot z$$\n",
    "\n",
    "представится графом\n",
    "\n",
    "![graph](Images/Circuit.png \"Graph\")  \n",
    "*From [Backpropagation, Intuitions - CS231n](http://cs231n.github.io/optimization-2/)*\n",
    "\n",
    "**Задание** Зададим значения $x, y, z$ (зеленым на картинке). Как посчитать $\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z}$? (*Вспоминаем, что такое backpropagation*)\n",
    "\n",
    "В PyTorch такие вычисления делаются очень просто.\n",
    "\n",
    "Сначала определяется функция - просто последовательность операций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lw4ASRktLdO4"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(-2., requires_grad=True)\n",
    "y = torch.tensor(5., requires_grad=True)\n",
    "z = torch.tensor(-4., requires_grad=True)\n",
    "\n",
    "q = x + y\n",
    "f = q * z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-78COM99N8YL"
   },
   "source": [
    "А затем говорим ей: \"Посчитай градиенты, пожалуйста\". И происходит магия - какая-то такая:\n",
    "\n",
    "![graph](https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/dynamic_graph.gif)  \n",
    "*From [github.com/pytorch/pytorch](https://github.com/pytorch/pytorch)*\n",
    "\n",
    "По описанной последовательности операций *на лету* строится граф вычислений, и обратный проход выполняется по нему.\n",
    "\n",
    "В этом ключевое отличие от tensoflow: граф не нужно компилировать до исполнения кода - это позволяет более гибко управлять его структурой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FOlPMIQMfbq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dz = tensor(3.)\n",
      "df/dx = tensor(-4.)\n",
      "df/dy = tensor(-4.)\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "\n",
    "print('df/dz =', z.grad)\n",
    "print('df/dx =', x.grad)\n",
    "print('df/dy =', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JotDf1naGU-R"
   },
   "source": [
    "Вызов метода `backward()` вычисляет градиенты для всех тензоров, у которых `requires_grad == True`.\n",
    "\n",
    "Есть еще альтернативный способ не вычислять градиенты - пользоваться менеджерами контекста ([Locally disabling gradient computation](https://pytorch.org/docs/stable/autograd.html#locally-disabling-gradient-computation)):\n",
    "```python\n",
    "torch.autograd.no_grad()\n",
    "torch.autograd.enable_grad()\n",
    "torch.autograd.set_grad_enabled(mode)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQEJeqfnJPpA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dz = tensor(3.)\n",
      "df/dx = None\n",
      "df/dy = None\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.no_grad():\n",
    "    x = torch.tensor(-2., requires_grad=True)\n",
    "    y = torch.tensor(5., requires_grad=True)\n",
    "    q = x + y\n",
    "\n",
    "z = torch.tensor(-4., requires_grad=True)\n",
    "f = q * z\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print('df/dz =', z.grad)\n",
    "print('df/dx =', x.grad)\n",
    "print('df/dy =', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSiB1CGyJMzt"
   },
   "source": [
    "Подробнее о том, как работает autograd, можно почитать здесь: [Autograd mechanics](https://pytorch.org/docs/stable/notes/autograd.html).\n",
    "\n",
    "В целом, любой тензор в pytorch - аналог многомерных матриц в numpy.\n",
    "\n",
    "Он содержит данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DY2CcCw2Gmgq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYxD8N_9GpJl"
   },
   "source": [
    "Накопленный градиент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYCD5P24GufX"
   },
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwLx4szvGwMb"
   },
   "source": [
    "Функцию, как градиент считать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTfGdUF_GzV8"
   },
   "outputs": [],
   "source": [
    "q.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgK1Esa6HHAB"
   },
   "source": [
    "И всякую дополнительную метаинформацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nazaer0AG4pL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.FloatTensor', torch.Size([]), device(type='cpu'), torch.strided)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(), x.shape, x.device, x.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvLFlc4iQOQv"
   },
   "source": [
    "Зачем... У меня один вопрос - зачем вот это вот нам нужно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlhLBWwHG3Xe"
   },
   "source": [
    "### Задача для разминки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kaqtIIvJOEut"
   },
   "source": [
    "Чтобы разобраться - решим простенькую задачу на линейную регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDZpEHF8AKH2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGvhJREFUeJzt3Xt4XHWdx/HPN5MmWsESC1KllxDQIiAqkweioAVBxF1Yr2DBC1axPrvRR4H1gqh0WeVxFbyt8VJYKkpLUZAHRBTwsVt1NWoGBLm0GNNGW8WWGi6KNE3mt39kpszlzMzJzDlz5sx5v/6BmTlzzi+P8skv3/P9/Y455wQAaH8dUQ8AANAcBD4AJASBDwAJQeADQEIQ+ACQEAQ+ACQEgQ8ACUHgA0BCEPgAkBCdUQ+g0P777+96e3ujHgYAxEomk3nYOXdAreNaKvB7e3s1MjIS9TAAIFbMbNzPcZR0ACAhCHwASAgCHwASgsAHgIQg8AEgIQh8AEgIAh8AIpYZn9DQhlFlxidCvU5L9eEDQNJkxif0liuHNTmVVVdnh9aeO6D0kp5QrsUMHwAiNDy2S5NTWWWdtGcqq+GxXaFdi8AHgAgN9M1XV2eHUibN6ezQQN/80K5FSQcAIpRe0qO15w5oeGyXBvrmh1bOkQh8AIhceklPqEGfR0kHABKCwAeAJiprwZwYl655o7TjgdCvTUkHAJqkuAXT9PNDrtGztn5/5sOXvFV69gtCvT6BDwBNkm/BTGuTvpO6RNqa++D0L0pHvD706xP4ANAkxz3XNNh99t7Xk894rrrO+43U2d2U6xP4ANAMq+bpxQUvN7/mOi099tSmDoHAB4Aw/fZ66YZ3Fb938SNaatb0oRD4ABCWVfOKX59woXTCR6IZiwh8AAjc1KUL1Tn5ePGbqx6NZjAF6MMHgABkxid0xR13SavmFYX9rcdd3xJhLzHDB5AQmfGJuverqfXdzPiE0mt6lS55v/fJdercsEcHPn+iKVsn1ELgA2h7jew5X/O7d1+n9I0ri75z2O5v6EnXJUnKZp2Gx3YpvaSnoV86QSDwAbQ9rz3nSwO3UhhX2q9+eGyXBjcWz+n3uJRemF2rd7y8V1f+bIuyWaeuOTNbHjfzQSeVEPgA2l5+z/k9U1nPPeerhXHpd3vmdmnBVf0atIeLz7Fiq4bHdmlt7hfGq45YUPQLZGjDaM1fOmEj8AG0vVp7zlf7C6Dwuy9dsq+O/ubzpYIW+p8c+kG94q0fUzp3bOE1C1/X+qXTDIEEvpldJek0STucc0fm3nuWpOsk9Wpmx4gznXPhPqEXACqotud8rTBOL+lRek1v2fcOm16vtS8f8H39Zj3opBJzzjV+ErNXSPqbpG8WBP5nJP3VOfdpM/uIpB7n3Iernae/v9+NjIw0PB4AmK2KN1QfvE1ad2bRsfec8XP9dEd3ZMFdyswyzrn+mscFEfi5C/ZKuqUg8DdLOsE592cze46k/3XOLa12DgIfQEspXSkrtUxPfSG/gR9mDf9A59yfc//+kKQDQ7wWAATnC0dJj4wXv9eCQT9bTVlp62b+jPD8U8LMVprZiJmN7Ny5sxnDAQBvzs3M6gvDfsFRgYR92ZOuIhDmDP8vZvacgpLODq+DnHOrJa2WZko6IY4HACoLsXzTCj34Urgz/JslnZP793Mk3RTitQCgPg/dWx72b7850BJOpcVbzRZUW+a1kk6QtL+ZbZN0saRPS/q2mb1L0rikMyufAQAi4DGrzy+gGkgFt/9NK/TgSwEFvnPurAofnRTE+QEgUOveLD34w+L3Pr5LmW2Ph1J6aYUefImVtgCSpkqt3s+eO/WqtvCrWQh8ALHmewdKHzdlW6X0EhYCH0Bs+ep++dtO6bJDi9878WPSsg+Wna9VSi9hIfABxFbNEkwdrZatUHoJC4EPILYqlmB+eKE0/JXigy94UJm/dml4w2hbzt79IPABxJZnCabCrL5VFj9FicAHEGt7SzA1yjdhduDERVP20gGAoJTtSTM9VR728xZV7MBJmdqyA8cPZvgAYqO0LLMptbz8oAo3Zdu9A8cPAh9AbOTLMq+zn+hzqa8Vf/jO26TF1Z8+1c4dOH4Q+ABiY6Bvvsa6zy57P7Niq4Z/v0sDLrj9b9oRgQ+gpWXGJ/TdO7fpU3cfr3Tphxc/oswfHkl8941fBD6AlpUZn9BZVwzrwc7KtXq6b/wj8AG0rPSaXj1YklJDyzIaPPGprRLaff+bIBH4AFrP9ox0xSuL3vri1Os15M7UtSWBTveNfwQ+gFnxvTtlvTwWUF30op/JSbr26IWe10x6941fBD4A30LdnuCS+VJ2qvi9C7dL3fvoU8FcIfFYaQvAt9CezbpqXnnYr3pU6t4nmPNDEjN8ALNQ6QZp3WWeOrYvRv0IfAC+ed0gravM8/dd0mf7it6a6pqnr7/0xxoYZ/FUWAh8ALNSeoN01n3wHrP6zIqtM780bt/M4qkQUcMH0BDfu1BefXp52K/cKK16NLx7AyjCDB9AQ3z1wVd5KMnwhlH1zO1i8VQTEPgAGlaxD94j6Pt2r1NXZ4fecesDuvJnWzSddeqe06FPnHaEJp6YZPFUiAh8AA0r69LJZqVLykO7b/c6ZZ00OZXV6p+OKetm3p/ck9XEE5NFWyYgeAQ+gIYUdul0mGm066zyg3Llm64rh7VnKisz01Q+7SV1dBhlnCbgpi2AhuRvuJ7dcUd52J/yyb199fla//mnLNW5xx9cdNi5xx9MGacJmOEDaEilh5J4LaDK1/qHNozKJDlJJmnfp88Je5gQgQ+gEavmlT2U5PDpdfrWuS8rf1hJgZ65XcoXdFzuNcIXeuCb2VZJj0ualjTlnOsP+5oAgld2Y9ajA2doWUbf8tFlM/HE5N4ZfkfuNcLXrBn+ic65h5t0LQABK7wxW618M+jzfAN989U9h777ZqOkA6Cm4bFdet707/W97ouKPzjgMGnwl7M+Hw8tiUYzAt9Jut3MnKSvO+dWN+GaAAI0uDGtwdIye4O7WvLQkuZrRuAf75zbbmbPlnSHmW1yzv0k/6GZrZS0UpIWL17chOEA8M2jTn/PmcM66vAXRDAYNCr0Pnzn3PbcP3dIulHSMSWfr3bO9Tvn+g844ICwhwPArwo3Zfc8Y0EEg0EQQp3hm9kzJHU45x7P/fspki4J85oAGsT2xW0r7Bn+gZJ+ZmZ3S/qVpO87534Y8jWBtpUZn9DQhlFlxieCP/mTj1Xc1ZLti9tDqDN859yYpBeFeQ0gKUJ9gHiNRw1WerQh4oW2TCAmZv1kKT+uPVva/P2it96z5zxt7DhWawseNUgbZXsg8IGYCHyWXWGv+qyTUtnyXyi0UcYfgQ/ERGCz7CpPn8pvX0zZpj2Zc672UU3S39/vRkZGoh4G0L5q1OrL9stBLJhZxs8+ZczwgSSoEfR5lG3aGw9AAdrZXWvLw/7INza8LQLiiRk+EHMVyzA+Z/VIDgIfiDHP3vw1veUHXvSQNOfpTR8fWguBD8RYaW++Z9iXzOq5MZtcBD4QM4WBne/N35RaXn6gR/km1NW6aHkEPhAjpYF9/RkH+g57KaTVuogNAh+IkcLA3pRaLn235IAaN2XZEyfZCHwgRgb65ns/U/bfhqVn134oCXviJBuBD8RIEDdlWVyVXAQ+EAc+e+q5KYtqWGkLhKjhB5ZMTc5qARUPKkE1zPCBkDQ8265jpSw3ZVENgQ+EpO4WyFvOk0auKnpr/KWf1JJXv6/mV7kpi2oIfCAkdc22PWb1h+xep/O7lmrQ53W5KYtKCHwgJLOabXsE/WHT12rPlKM0g8AQ+ECI8iGfv3nqGfoVavVrC9orJWlowyhlGjSEwAdCVPXGbY2bsvnSDK2WCAptmUCIPNskf//j8rA/KE2rJULHDB8IUemN28GN6fKDaLVEk/AQcyBkmfEJ7y0RPrRFmvss3+eg1RKV8BBzoEX42f+m5jlotUQACHwgLAE9U5bZPYJC4ANBe/wh6fKl5e8XhL3fEKdDB0Ei8IEg+ZjVzybEeUIVghR6W6aZnWpmm81s1Mw+Evb1gChMXbqoPOzffpNnCWc2bZYDffPVmeqQSUql6NBBY0Kd4ZtZStKQpFdJ2ibp12Z2s3Pu/jCvCzTVqnnl/yFVqdXPus0y30nXQh11iKewSzrHSBp1zo1Jkpmtl/RaSQQ+4s+jfNO3e50uOKX6Rmez2WNneGyXprJOTtJ01lHSQUPCDvyDJP2x4PU2SccWHmBmKyWtlKTFixeHPBwgANmsdEl56PY+uU6S1DO3q+Yp/LZZsugKQYr8pq1zbrWk1dLMwquIhwNU5zGrH1qW0WW3bZY0c1Ns4onJwC7H/vYIUtiBv13SooLXC3PvAfFy+8eln3+p+L0Xv0V63Vc0MD6h7jnhzcJZdIWghB34v5b0PDM7WDNBv1zS2SFfEwiWj10tmYUjDkINfOfclJm9V9JtklKSrnLO3RfmNYF6eC6E8gr6j++SUuX/2TALRxyEXsN3zt0q6dawrwPUy3MhlI/9b9jyAHET+U1bIGqFC6E2pZZLa0oO8OipZ8sDxBEPQEHiDfTN18s6N2vr0zxuL/FQErQRZvhIvPSaXl2TKnlzFg8lSXWY/vTIP2b2vWeWjxbGA1CQXF43Zd93pzT/kKK3KtXqM+MTuuHObbo+s01T05R2EB0egAJU43Ov+mq1+vSSnpmtD6bZzRLxQOCjrZXNzmf5UJLCWv2kR6Cz9QHihMBH2yqcnc/v/Id+nXpX+UE1avU9c7uUzVU9s658nxwWXSFOCHy0lcIZfX52Ptbtv/um1MQTkzJJTpX3yWHRFeKCwEfbKK23/3y/VRrs3lR80OlfktLn+D7nQN/8UPfJAZqJwEfbKFtA9XjJAXU8QJySDdoJgY+2MdA3v6HyTSWUbNAuWGmLtuFn/xsgyZjhI/48Wi0zK7bOlGFY/QrsReAjvoa/Jv3ww8XvLRpQ5uT1bGwGeCDwEU9VFlANbxgt29iMwAcIfMSNV9BfuF3q3mfvy1qrX9nHHklF4CM+fG6LUK2Vkn3skWQEPlrfLPe/kSq3UnrtY0/gIyloy0TgMuMTGtowqsz4RGMn+sv9dYV9NflyT8rEylkkDjN8BKrRkkm+vj64MV3+YQA99aycRZIR+AhUIyWTzPiE0mt6VRb177pDWnRMYGNk5SySisBHoGazP3xptwwrZYFwEfhoSFlo+yyZFJZ+vPa/OWx6/Uw5KOwfAEgQAh91q1Sv91MyGR7bJU3t1lh3+VbFQ8syWpv7ZUHPPBAcAh91q1Sv9xPSgxvTGuwufi8/qx/MfYeeeSBYtGWibl4tjvmQvvz2zXrLlcPlrZnXvKms1fLLU69T75Pr9v7SyPP6hQKgfszwUTevev1QtX1sKuxq+eUrh5Wy8pu8PCAcCBaBj4aU1us9Q9pr8dTFj0hmSksVb/LSMw8Ey5xz4ZzYbJWkd0vamXvro865W6t9p7+/342MjIQyHjRPUQ2fVksgdGaWcc711zou7Bn+551zl4V8DbSYvT31G0s+IOiBSHHTFsG694byEk6qi7AHWkDYM/z3mtnbJY1IusA51+BuWmhpAW90BiBYDQW+mf1I0gKPjy6S9FVJ/ynJ5f55uaR3epxjpaSVkrR48eJGhoOoeAX9BQ9K+x7Y/LEAqCi0m7ZFFzHrlXSLc+7Iasdx0zY+Gt3VkhW0QHAiv2lrZs9xzv059/L1ku4N61poroq7Wvos37CCFohGmDdtP2NmvzWzeySdKOm8EK+FZnnsTw23WrKCFohGaDN859zbwjo3glOttFL4mSTPoK9nV0tW0ALRYKVtglUrrRR+dmfXu7Wf/b3ou6MnXaHbpo7eu6ul17kr/SJhBS0QDQI/wao9nSr/mdde9UPLMhp8+aE6tMJ5/dToeeoU0HwsvEqwag/0HtyYLgv7Q3av02HT6/fuilnpQeXU6IHWxAw/BsJqYfQsrWSz0iUeJZoVW3V+QT0/P4Pv7DCd0b9Ibzh64d6xUaMHWlNT+vD9og+/XFNbGH2ulB3aMKrLb9+sbO7/Oiape075PQBq9EBz+O3Dp6TT4ppSHvnp5WVhv3PpWyq2WuZn8JZ77VQ+tvSSHg2eeChhD7QQSjotLvTyiMesvm/3OnXd36G14xOegZ0vBd1w5zZdn9mm6WlKN0AcEPgtLrQWRo+g/8orfqnL7vi999OqPMaVXtKjNx69kNINEBMEfgwE3sJYoVZ/7PiEujZsmdVfE7RXAvFB4CdJjZuyLIgC2huBnwR/uktafULxe0/vkT68tezQSjN2um6A+CPw20TFQA7goSTsbgm0BwK/DXgGsteOlu+/R+pZMuvzV9uCAUB8EPgxUKucUhrIjW5fXIqVs0B7IPBbXOns/ROnHaGJJyaLwj8fyJtSy8tPEMAzZbmZC7QHAr/FFc7eJ/dk9Ymb7lXWuaJaenrBnNDCPo/2SyD+CPwWV1hOMTNlnSuupQdcvgHQvgj8FldYTumZ26VLbrlPe6ay+mrXF3TKxl8VH/ymq6Qj3xjNQAG0PAK/Ts3sSy8spyxdsC+zegB1IfDrEFlf+qp55c+OJegB+MT2yHVo5hOd8k+W8lpANbQs4/nEKQDwwgy/DmH3pefLRT1zu3T2D15YNqvPrNg68xfG7ZtZ+QrANwK/DmH2pefLRSdmh/XVOV8o+ux3B5yi5w1+R8MbRln5CmDWCPw6BdWXXnrzd3hs10xPfar4uMOm12vtaQOSWPkKoD4EfoRKb/5uSi3XYMkx153yKz28O6W1BX9JsPIVQD0I/AgV3vz1WimbWbFVb67xxCkA8IvAD4HfHv2Bvvka6z67/INcq2VZCyYANIDAD1i1Hv2iXwTzHld6zQuLv9z5NOljf/F1Dco5AGaLwA9Ypb3jC38ReM3qD5ter7UrBmrO6nkYCYB6NbTwyszOMLP7zCxrZv0ln11oZqNmttnMXt3YMFtbfnFUZnxibwdNylTUQTM8tks32IfLwv7Vk59R75PrfC/gauaiLwDtpdEZ/r2S3iDp64VvmtnhkpZLOkLScyX9yMye75ybbvB6Lcdrxu3VQTO4MV326zWzYqvGrxxWyvlvr6QlE0C9Ggp859wDkmRmpR+9VtJ659xuSVvMbFTSMZJ+0cj1WpHXjHvwxEOfKrN4bImQWbF1pstGmnV7JS2ZAOoVVg3/IEnDBa+35d4rY2YrJa2UpMWLF4c0nPBUmnFntuxU+upDy7+w6tGiOn097ZW0ZAKoR83AN7MfSVrg8dFFzrmbGh2Ac261pNWS1N/f7xo9X7N5zrjZ1RJAC6oZ+M65k+s473ZJiwpeL8y917IaaXXcO+O++zppzcqiz96/5716/skrylbQAkCzhVXSuVnSOjP7nGZu2j5P0q+qfyU6gbQ6etTqD9m9TnM6O/R2bqwCaAENBb6ZvV7Sf0s6QNL3zew3zrlXO+fuM7NvS7pf0pSkwVbu0KnUO++LR9Dr4keU+cMjOp8bqwBaSKNdOjdKurHCZ5+S9KlGzt8sdbc6eoV9flsEbqwCaDGstFUdrY5Vgh4AWhWBn5MP+fzK1fx2CEW/BHZskr5ybPEXjz9fOvnivS/Z5wZAqyLwc0pv3H7itCO06uZ7tWfaaU7K9OCcs8q/VDKrZ58bAK0sMYFfa+ZdeON2956srvq/LZqcdvrGnP/SCam7iw++cJvUvW/Vc3jd/GX2DyBKiQh8PzPvgb756kx1aHIqKydpbMfftPVplfeq91Lt5i+zfwBRS0Tg+2m7TC/p0ZvSC3XtL/+gLR5Bn9//pppqN38bav0EgAAkIvC9Zt5e5ZU3HbW/Lr37+KLvju5/kh49/X98h3Oldkx2uQQQNXOudbav6e/vdyMjI4GcqzTQC19LKi+vrOktP0nArZbU8AGEwcwyzrn+Wse15Qy/Ur08H7JDG0b3lldeMn2f0mtKHiB+/gPSM58b+LhYjAUgSm0Z+LXq5fnyyqbU8vIvV5nVM0MHEGdtGfi16uXpP16tTamLi79Uo3xDlw2AuGvLwC/slumZ2/XU6tnF+0n/sV/xwQOD0qmX1jwnXTYA4q4tA196aquE/Kz8mq5LJbu3+KBZ3JSlywZA3LVF4FeqrQ+P7dLTpx7Tpu7ih5LovPukeQtndQ2eJQsg7mIf+NVq6+fcf64Gu+/ae+xjzzlOz3zPrXVfiy4bAHEW+8D3rK3Pn5IuO1T7FByXeccWpXufFdk4ASBqsQ/80tr6GTu+JF129VMHnPM96eBXlD1UnBZLAEkT+8DP19Z/d88vtDyzXHog98FJF0svP9/zO7RYAkii2Ae+JKWf+ZjSmdx+9aku6UNjntsX59FiCSCJ2iLw1b2vdPAyaeBfpaWvqXk4LZYAkqhtN0+rhRo+gHaR6M3T/KDFEkDSdEQ9AABAcxD4AJAQBD4AJASBDwAJQeADQEIQ+ACQEAQ+ACRESy28MrOdksajHscs7S/p4agHEQF+7mTh525tS5xzB9Q6qKUCP47MbMTPCrd2w8+dLPzc7YGSDgAkBIEPAAlB4DduddQDiAg/d7Lwc7cBavgAkBDM8AEgIQj8AJnZBWbmzGz/qMcSNjP7rJltMrN7zOxGM9sv6jGFycxONbPNZjZqZh+JejzNYGaLzGyDmd1vZveZ2fujHlMzmVnKzO4ys1uiHktQCPyAmNkiSadI+kPUY2mSOyQd6Zw7StKDki6MeDyhMbOUpCFJr5F0uKSzzOzwaEfVFFOSLnDOHS5pQNJgQn7uvPfrqadktwUCPzifl/QhSYm4KeKcu905N5V7OSxpYZTjCdkxkkadc2POuUlJ6yW9NuIxhc4592fn3J25f39cM+F3ULSjag4zWyjpnyVdGfVYgkTgB8DMXitpu3Pu7qjHEpF3SvpB1IMI0UGS/ljwepsSEnx5ZtYr6SWSfhntSJrmC5qZwGWjHkiQEvuIw9kysx9JWuDx0UWSPqqZck5bqfYzO+duyh1zkWb+9F/bzLGhecxsH0k3SPqAc+6xqMcTNjM7TdIO51zGzE6IejxBIvB9cs6d7PW+mb1Q0sGS7jYzaaa0caeZHeOce6iJQwxcpZ85z8zeIek0SSe59u7v3S5pUcHrhbn32p6ZzdFM2K91zn036vE0yXGS/sXM/knS0yQ908yucc69NeJxNYw+/ICZ2VZJ/c65OGy4VDczO1XS5yQtc87tjHo8YTKzTs3cmD5JM0H/a0lnO+fui3RgIbOZGczVkv7qnPtA1OOJQm6G/+/OudOiHksQqOGjXl+WtK+kO8zsN2b2tagHFJbczen3SrpNMzcuv93uYZ9znKS3SXpl7n/j3+RmvYgpZvgAkBDM8AEgIQh8AEgIAh8AEoLAB4CEIPABICEIfABICAIfABKCwAeAhPh/Wz37xLYqOWYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_orig, b_orig = 2.6, -0.4\n",
    "\n",
    "X = np.random.rand(100) * 10. - 5.\n",
    "y_orig = w_orig * X + b_orig\n",
    "\n",
    "y = y_orig + np.random.randn(100)\n",
    "\n",
    "plt.plot(X, y, '.')\n",
    "plt.plot(X, y_orig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2K5MVtiSGuC"
   },
   "source": [
    "Хочется прикрутить сюда backpropagation, да.\n",
    "\n",
    "Есть два параметра $w$ и $b$ - их нужно подобрать такими, чтобы они были как можно ближе к исходным $w_{orig}, b_{orig}$.\n",
    "\n",
    "Что будем оптимизировать? Оптимизировать будем MSE:\n",
    "$$J(w, b) = \\frac{1}{N} \\sum_{i=1}^N || \\hat y_i - y_i(w, b)||^2 =\\frac{1}{N} \\sum_{i=1}^N || \\hat y_i - (w \\cdot x_i + b)||^2. $$\n",
    "\n",
    "С такой функций потерь можем запустить простой градиентный спуск (даже не стохастический пока):\n",
    "$$w_{t+1} := w_t - \\alpha \\cdot \\frac{\\partial J}{\\partial w}(w_t, b_t)$$\n",
    "$$b_{t+1} := w_t - \\alpha \\cdot \\frac{\\partial J}{\\partial b}(w_t, b_t)$$\n",
    "\n",
    "**Задание** Реализовать оптимизацию на чистом numpy.\n",
    "\n",
    "Для этого нужно:\n",
    "1. Посчитать значение функции на прямом проходе: $y(w, b) = w \\cdot x + b$;\n",
    "2. Подумать и посчитать градиенты $\\frac{\\partial J}{\\partial w}, \\frac{\\partial J}{\\partial b}$ на обратном проходе;\n",
    "3. Сдвинуть $w, b$ по антиградиентам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKbqTNVXFB3A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 100, Loss = 0.029362309994758463, w = 2.5935973607180016, b = -0.5688026446280502\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAG0ZJREFUeJzt3X+UXWV97/HPd85kJkQRhgRRCMkwomIIFjlTyL1Y01SXxYrNKl40BCmlSrzeoYtWvBKhYsy6tKhg9V7nQtPU1LYZEAXUCyIIxoirjjonDZaQUIdpBoL8DKe5cGMzmZzn/nHOGc6PfX7MnP3j7LPfr7Vczeyzz95P7PIzT77Pdz/bnHMCAHS+rqgHAAAIB4EPAAlB4ANAQhD4AJAQBD4AJASBDwAJQeADQEIQ+ACQEAQ+ACREd9QDKLVo0SLX398f9TAAIFYymcwLzrnjG53XVoHf39+vsbGxqIcBALFiZpPNnEdJBwASgsAHgIQg8AEgIQh8AEgIAh8AEoLAB4CEIPABIGKZyayGt40rM5kN9D5t1YcPAEmTmczq4s2jmprOqae7S1s/skLppX2B3IsZPgBEaHRiv6amc8o56fB0TqMT+wO7F4EPABFaMbBQPd1dSpk0r7tLKwYWBnYvSjoAEKH00j5t/cgKjU7s14qBhYGVcyQCHwAil17aF2jQF1HSAYCEIPABIERhtWB6oaQDACGp2YI5PSV1dUtdwc7BmeEDQEgqWzDHfrlP+ssl0v84Xnp4JPD7E/gAEJLSFsyPzrtHH/3x26VDB/IfDqwK/P6UdAAgJOmlffrGB0/SGd/8rZKDfyS978uh3J/AB4Aw5HLSxj6dUXrsE7+UXv3a0IZA4ANA0DYcU/7zeTdIKz4W+jAIfADwWWYyq9GJ/Vp5XFbL73pX+YdXT0pHHRvJuAh8APBBMeT7FvRo4927tCe1pvyEhW+U/mQsmsEVEPgAEqEYyHPZr6bRd0v762/svll7Ug+Vf37Z3lC2TmiEwAfQ8VrZc76Z745O7Nfh6WlN9H6o7PgnD1+ubx5Zpasm9iu9tK+lXzp+IPABdDyvPecrA7dWGNfar7703KHtaQ31lt/z1Klblcs59czLb3kc5otOaiHwAXS84gNPh6dznnvO1wvjyu/2LeiZOfec7l/q1tRnyq71iw+M6q3L3qKvV/wCGd423vCXTtAIfAAdr9Ge8/X+BVD53eK5E71rq2+04YDeWnLP0vs0+qUTBl8C38y+Kul8Sc8555YXjh0n6euS+iXtlfQB51z428MBgOrvOd8ojEu/u/wbv6Wh3ifLL7DhQFP3D+tFJ7WYc671i5i9Q9LLkv6+JPA/L+lF59wNZrZeUp9z7up61xkcHHRjY9G2LQFIpoYLqrkj0sbjyg49e/qHdcKFXwxphLWZWcY5N9joPF9m+M65H5lZf8Xh1ZJ+u/Dnr0n6oaS6gQ8AUan71qnKJ2UlacMBnRDskHwXZA3/BOfc04U/PyPF7r8bAEn32PekWz9YfuyKMWnRG6MZT4tCWbR1zjkz86wdmdk6SeskacmSJWEMBwAaqzGrn6uoe/ClYAP/WTN7vXPuaTN7vaTnvE5yzm2StEnK1/ADHA8ANLZxkZQ7XH6shaCXWnvwy09BvgDlO5IuLfz5UknfDvBeANCa3JH8rL407Jee23LYS7Uf3gqbX22Ztyq/QLvIzPZJ+oykGyTdbmYfljQp6QN+3AsAfOdRvvFz/5t26MGXfGrL9AttmQBCtetb0jcuLTv0+0c+p0emT/a99BJkDT/UtkwAiB2PWf3wyoweuf+xQLY/qNv2GRICH0CszXrmXKf7ZsVkti1KL0Eh8AHE1qy6XzyelFVfv3TlwzM/tsP2B0Ei8AHEVjPbHkuaVU99O5ReghJkWyYABKrY/ZIyeZdgdvx9Vdh/YOo6nXbkNmUmk7eXIzN8ALFVtwTjMasfODSinJNSLpr96KNG4AOItaoSTI3yTWYyq57Nox27INsMAh9ArNTsyvFalJVmavWdviDbDAIfQGzU7MppclG2kxdkm8GiLYDYqOzKefmhm6vD/pJv+bL/TSdihg8gNkr3pHm8d600Xv65n/vfdCICH0Bby0xmdeeOfXKS3n/WYu1JrZFS5eecduS2fJln82hkWw/HAYEPoG1lJrO66G/yNfsu5fQXD7+96pzhlRlNBbT/Tach8AG0rdGJ/To8ndPe+WurP0zI/jd+IvABtK3VL9+uofmfKzv2+Kpb9IaVF838TLtl8wh8ALMS2rtZNxyjxZX3rrEom/R2y2YR+ACaFsq7Wev01Kf9vVPi0IcPoGm13s2amcxqeNt4axuS5XKz2tUSs8cMH0DTvN7N6susn6APBTN8AE0rLpB+/N1vngn2WrP+pmz/QlXYfyJ3hTKX7fV34JDEDB/ALFUukHrN+pviMavv/48RpUw6hV76QBD4AFoy67ZIj6AfOe8X2njPo0oZvfRBIvABtKyptshcTtpYfc7AoRH13POorjv/dGUPTtFLHyACH0DwPGb1lw88qAcefVZO+dp/9uCUhladGv7YEoRFWwAtq9mW+f3rqsJ+4+FLNHBoRD/Y85xc4ViqyyjjhIAZPoCWlLZldplp4+rlWnvOEs9Z/WlHbtPhXP686ZybOX7h4MmUcUJA4ANoSWlbZs45rb33DOneipM+8++SmbYWtmV46deHdcuPJmY+Pv1Ejz58+I6SDoCWrBhYqC4zmersamkmKb+4O7TqVB191DxZ4WOTlD04Fdp4k4wZPoCWpJf2abznouoP6jwp27egZ6Z+7wo/I3iBz/DNbK+Z/YuZ7TSzsaDvByAYnguz911bVavfN7i+4bYI2YNTMzP8LjHDD0tYM/xVzrkXQroXAJ957pezpb/6xA0HqrY09rJiYKF65/HSkrBR0gHQUOnC7J7UGmlLxQmFRdlm8dKSaIQR+E7S/WbmJP21c25T6Ydmtk7SOklasmRJCMMBMFsrBhaqt1vanar9qsHZ4qUl4Qsj8N/unHvKzF4r6ftmtsc596Pih4VfAJskaXBw0NW6CIDopLf0a3eq4iDbF8dO4Iu2zrmnCv/3OUl3STo76HsC8InHk7K/OvNKwj6mAp3hm9mrJHU5514q/PndkjYGeU8APvF4Unbg0Ih6Ml3a+rYs5ZgYCnqGf4KkH5vZw5J+Juke59z3Ar4n0LF8eZVgg+trwzFVYT/8jjENHBqZ20tO0DYCneE75yYk/UaQ9wCSIugXiGf2vqj0351S/cGGA1oxmVXPtnHaKGOOtkwgJrxeJehb4G84RumKQ8MrMzPbFdNG2RkIfCAm5vwqwXruu1b6yVfKDm2efq9utEu0teL6tFHGH4EPxITvs2yPRdnMZXt1aGK/tjKL70gEPhAjvsyyPYK++KRsunAPdCYCH0gK56TPHlt9nJ76xCDwgZjLFF4qUrfM4zWrJ+gTh8AHYqxhq+a966Wf3lz+pfRl0vu+FO5A0RYIfCDG6rZqMqtHBQIfiDHPVk2voL8uK3XlH6xvqgSEjkTgAzFTGdgzrZqnHFfzpSSl3w3yaV20NwIfiJFagZ3e0i9trzjZo3wT6NO6aHuBb48MwD+Vga0HPltdwvnNy2vW6osloJSJPXESiBk+ECOlNfvHe9dKT1acsOFAvuSzbdyzRs+eOMlG4AMxkl7al3+nbOXbpwqLss3U6NkTJ7ko6QBx4VztVstCB45XjR4oYoYPBMi3Fsgme+oD2VETHYPABwLSagtkZjKr3A+u129O/k35B6dfIF24xfM71OhRD4EPBKSVFsjMZLZhT30t1OhRC4EPBGTO5RWvt0+94+ca+p03+T5GJAuLtkBAiuWVNWcv0QVnLW78hRqLsqcduU19r5of6MvLkQzM8IGA3bFjn6amc7pzx77adfwab58andiv6xb0aOPdu9gOAS1jhg8EqGGb5A+urw77My6UNhxQemmfhladquzBKVot4Qtm+ECA6tbxabVEyMw5F/UYZgwODrqxsbGohwH4qqoX33P74helrsrHZ+tcAyhhZhnn3GCj85jhAwGbaZOs96Rss9cAWkDgA2Fo4e1TzO7hFwIfCNIPb5B++Jflx868WJm3XV9zR8tSvLAEfiLwgaDUmNXPJsR5YQn8FHjgm9l5kr6s/Iaum51zNwR9TyBSXkH/6f1SKv8/t9mE+IqBhepO5Tt0Uik6dNCaQPvwzSwlaVjSeyQtk3SRmS0L8p5AFDKTWQ1vG69dq0+9Mrea9Vunip10bdRRh3gKeoZ/tqRx59yEJJnZbZJWS3o04PsCoSludFa5/02tRdnZ7Gg5OrFf0zknJ+lIzlHSQUuCDvyTVP4Stn2Szgn4nkB4vvcppUf/d9mhx45eoTdfdV/drzXbZslDV/BT5Iu2ZrZO0jpJWrJkScSjAWbBo3zT/x8jWvsbS/QXPt2C/e3hp6AD/ylJJ5f8vLhwbIZzbpOkTVL+SduAxwO0ziPolx3+B/36SEo9KdP7m9kZcxZ46Ap+CTrwfy7pjWZ2ivJBv0bS2oDvCQSnxqLsP/BwFGIg0MB3zk2b2RWS7lO+LfOrzrldQd4TmIuGT7M2eFKWWTjiIPAavnPuu5K+G/R9gLmq+yDU/Z+W/ul/ln/hdWdI//XHbHmA2Il80RaIWs0HoerM6tnyAHFE4CPxKlsfh7anpe0VJ/3581J3z8yPbHmAOOKNV0i8Yuvjx9/9Zu1Jrak+YcOBsrCXyp+WTXWZfvXvv+Z9s2h7vAAFkBqWb7xq9ZnJrO7YsU/fzOzT9BFKO4hOsy9AYYaPZHvgs9Vh/9plVbX6m+5/TBdvHi2bxaeX9umkY4/S9BHeN4t4oIaPjla3k6aJl5KU1uqnPGr1bH2AOCHw0bFqdtJ4BX3FomxR34Ie5QpVz5zL/1yKrQ8QJwQ+OkrpjN6zk2ZLf/WX6rxqMHtwSibJKV//zB6cqjqHh64QFwQ+OkbljP6680+fKbc83ru2utWyiXfKrhhYqN55lGzQGQh8dIzKGX324JR+kP6JTtz55fITF54q/UmmqWtSskEnIfDRMTwfoKrUxKy+EiUbdAoCHx2jOBv3rNP/+XNSd2/oYwLaCYGPjjLbRVkgSQh8dAaPVsuBQyP5dszJLCUZQDxpi7jb/vmqsD8w/yQNHBrh6VegAjN8xFeNJ2XHJ7Pq2Txas5WSfeyRVAQ+4scr6K99Rpp3lKT6rZTsY48kI/ARL03sfyPVbqVkH3skGYEP3wVSMmky6BthszMkGYEPX7VaMqn6ZfHQTdKDG8tPOvpE6ardcxofT84iyQh8+KqVkknlL4uab59qEU/OIqkIfPhqNiWTytl88ZfFRO/a6pOveVrqWRDgyIHOR+CjJZWh3WzJxKv0s2JgoXfY86Qs4AsCH3NWq17fTMmk8k1StbZEyExmNbptnHo74AMCH3NWq17fTJdOsfTzx+5b+mT3beUf9rxauuYpeuYBnxH4mDOven2zIZ1e2ue5KDu8MqOhVadKomce8BuBjznzqtcPbxtvHNIePfXLD31V090LtLVkkZeeecBfBD5aUlmvbxjSHmGfuWyvPuZRAqJnHvCXOeeCubDZBkmXS3q+cOga59x3631ncHDQjY2NBTIehMezhu/Tk7IAqplZxjk32Oi8oGf4f+WcuzHge6DNlM36H/qi9OBnq08i7IHQUdJBcJjVA20l6MC/wsz+UNKYpKucc9mA74d24BX0n9on9R4d/lgAzGjpjVdm9oCZPeLxn9WSbpb0BklnSnpa0k01rrHOzMbMbOz555/3OgVxUmtWT9gDkQts0bbsJmb9ku52zi2vdx6LtvFRtTA7y/INb50C/BP5oq2Zvd4593Thxz+Q9EhQ90K4Sh+u+vC8+5Tu+lr1SQ3CnidogfAFWcP/vJmdKclJ2ivpowHeCyGqu6tlE4uyPEELRCOwwHfOXRLUtRG+0hLM0Pa0hnorTlj/pDT/NU1diydogWjQlplw9Wrpxc/6FvRo4927WprVl+IJWiAaBH6C1aull37WZabxnoukVMUFWliU5a1TQPhaastEvHnV0is/+2DXg/mwL+Fkyly2V8PbxpWZrH60ovjL4qb7H9PFm0c9zwEQPmb4CVavll7r7VOZy/ZK0szsv7vLdOHgybrgrMUzM3YWZYH2RODHQFA96zVr6RuOUbry5PVPSPPzx0u3QJ464jTy0yd0x459MyUhFmWB9kTgt7mge9araulNPEBVDPRDh3Nyyvfdls7kWZQF2hOB3+ZCK4/M4knZYqDfsWOfvpnZpyNHqmfyLMoC7YfAb3OBl0d+cbt05+Vlh551x2pl7hZtnczWDO1ioL//rMXM5IGYIPDbXKDlEY9Z/cChEeWclLLm/jXBTB6IDwI/BnwPVa/yzfonlXn2iHo2j7LYCnQoAj9p6tTq00tV818T7G4JxB+B3yEaBnKTi7Je/5pgd0ugMxD4HaBuID/6Hen2in3sjlki/dm/NH19HqQCOgOBHwONZu81A9mnd8ryIBXQGQj8Nlc5e7/u/NOVPThVFv6VgTy0PS1tr7hQ4UnZueBBKqAzEPhtrnT2PnU4p+u+/YhyzpWVbkoDeWh71aYIc5rVV6L9Eog/Ar/Nlc7ezUw55zxr6ekt/dX73/gQ9AA6B4Hf5kpn78UXkZTV0nffLX394vIvHX2idNXuaAYMoG0R+DFQWk558+uOfqWWvqW/+mRm9QBqIPDnKKoHkdJL+/JBX7koe/WkdNSxoY0DQPwQ+HMQ5oNIVb9YfGq1BJA8BP4cBP0gUrMvDx84NJL/hVNnV0sAKCLw5yDIB5EqXx5+rnbqa72fKzvn4LzjtPzlr/DkK4BZIfDnwM8HkSpLNqX/epjovaj6CxsOaPdkll0tAcyaOeeiHsOMwcFBNzY2FvUwQuO1FiDJs/tm59qHdeab+su+y5OvACTJzDLOucFG5zHDj5DXWkCtJ2XPrDjEk68AZovAj1DpWsDjvWurWy3pvgHgo66oB9CJMpNZDW8bV2YyW/d4emmfhv/Ty/mwL7XoTXXDvtb1AaAeZvg+q9Wj73l8S7/eWXmBBrN6XkYCYK5amuGb2YVmtsvMcmY2WPHZp8xs3MweM7PfbW2Y7a10xu1Vl5fK6/V7UmuqFmbPOrRJwyszDe9V6/oA0EirM/xHJF0g6a9LD5rZMklrJJ0u6URJD5jZm5xzR1q8X9vx2q/eq0e/WK/fk1pTdY03HBppur2Sl5EAmKuWAt85t1uSzKzyo9WSbnPOHZL0b2Y2LulsST9p5X7tqHLGnT045dmjn97Srz2pii9vOKDMZFYfn0V7JS8jATBXQdXwT5I0WvLzvsKxjuM14y6G8OjEfr3quR067Z4Lyr/Ud4p05U5Jc2uvpCUTwFw0DHwze0DS6zw+utY59+1WB2Bm6yStk6QlS5a0ernQec24i2Uer/INrZYAotIw8J1z75rDdZ+SdHLJz4sLx7yuv0nSJin/pO0c7uWLVp5crZxxe5Zvrt4rHcWsHEB0girpfEfSiJl9UflF2zdK+llA92qZr62OHtsXZy7bqzRhDyBiLQW+mf2BpP8l6XhJ95jZTufc7zrndpnZ7ZIelTQtaaidO3R82e7YI+iHV2ZYWAXQNlrt0rlL0l01Prte0vWtXD8sLbU6PrtLuvk/lx97y/ukD/6jhvwdJgC0hCdt1UKrI2+fAhAjBH5BaStl6c+ebnqL9NKvyo+tf0KafwzbFgNoWwR+gdfC7WPPvKR7H3la71n+eq09p9AyWmdWzz43ANpZYgK/0cy7dOH20OGcPnfvbv1sb343yod++YLW3ntG9UUryjeNFn+Z/QOIUiICv5mZ94qBhepOdWlqOicn6eeFsF9qz2h778fLL/i2D0mrh6vuU2/xl9k/gKglIvCbabtML+3Tf0kv1q0/fULFp7/2zl9bfbE6i7L1Fn99af0EgBYkIvC9Zt5e5ZX3n7VYd+7Ypxv1JZ2fGi2/yPonpfmvaXivWvvcsMslgKh17EvMKwO99GdJtcsrAbZaUsMHEIREv8S8Vr28GLLD28aryysVLySR5HtPPbtcAohSR77TttFboYrllZRJx3f/Pw1tT5df4D1f8Ax73iULIM46cobfqF5eXFydzayeLhsAcdeRgV/aLdO3oKf66dl/vV/pkQvLv3Tts9K8+TWvSZcNgLjryMCXXgn3qll55az+VcdL/3284fXosgEQdx0R+LW6X0pn5dfob5XeUvEGqlksyvIuWQBxF/vAr1dbXzGwUK/pPqydqUvLv/SRB6XFDTuYqtBlAyDOYt+lU68jJ/1P/6087F99Qn5WP4ewB4C4i/0M37O2fvBF6fOnlJ/46Rek1LyZH3kICkDSxD7wq2rre26UtnzllRPWjEinvbfsO7RYAkii2Ae+VKit9z4l3dL/ysGV66VVn/I8nxZLAEnUEYGv7KR0y7n5P1uXdPVk3Y3OaLEEkESdEfi9R0unvEM652PSab/X8HRaLAEkUWcE/oLjpEv/z6y+QoslgKSJfVsmAKA5BD4AJASBDwAJQeADQEIQ+ACQEAQ+ACQEgQ8ACUHgA0BCmHMu6jHMMLPnJU1GPY5ZWiTphagHEQH+3snC37u9LXXOHd/opLYK/DgyszHnXOI22OfvnSz8vTsDJR0ASAgCHwASgsBv3aaoBxAR/t7Jwt+7A1DDB4CEYIYPAAlB4PvIzK4yM2dmi6IeS9DM7AtmtsfMfmFmd5nZsVGPKUhmdp6ZPWZm42a2PurxhMHMTjazbWb2qJntMrMrox5TmMwsZWb/bGZ3Rz0WvxD4PjGzkyW9W9ITUY8lJN+XtNw591ZJ/yrJ+wXCHcDMUpKGJb1H0jJJF5nZsmhHFYppSVc555ZJWiFpKCF/76IrJe2OehB+IvD981eSPikpEYsizrn7nXPThR9HJS2OcjwBO1vSuHNuwjk3Jek2SasjHlPgnHNPO+d2FP78kvLhd1K0owqHmS2W9F5Jm6Mei58IfB+Y2WpJTznnHo56LBH5Y0n3Rj2IAJ0k6cmSn/cpIcFXZGb9kt4m6afRjiQ0X1J+ApeLeiB+6ox32obAzB6Q9DqPj66VdI3y5ZyOUu/v7Jz7duGca5X/p//WMMeG8JjZqyXdIelPnXP/N+rxBM3Mzpf0nHMuY2a/HfV4/ETgN8k59y6v42Z2hqRTJD1sZlK+tLHDzM52zj0T4hB9V+vvXGRmfyTpfEnvdJ3d3/uUpJNLfl5cONbxzGye8mG/1Tl3Z9TjCcm5kn7fzH5P0nxJrzGzf3TOfSjicbWMPnyfmdleSYPOuThsuDRnZnaepC9KWumcez7q8QTJzLqVX5h+p/JB/3NJa51zuyIdWMAsP4P5mqQXnXN/GvV4olCY4X/COXd+1GPxAzV8zNVXJB0t6ftmttPMbol6QEEpLE5fIek+5Rcub+/0sC84V9Ilkn6n8P/jnYVZL2KKGT4AJAQzfABICAIfABKCwAeAhCDwASAhCHwASAgCHwASgsAHgIQg8AEgIf4/5nQgTklNtSYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_progress(epoch, loss, w, b, X, y, y_pred):\n",
    "    clear_output(True)\n",
    "    print('Epoch = {}, Loss = {}, w = {}, b = {}'.format(epoch, loss, w, b))\n",
    "    plt.plot(X, y, '.')\n",
    "    plt.plot(X, y_pred)\n",
    "    plt.show()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "w = np.random.randn()\n",
    "b = np.random.randn()\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "for i in range(100):\n",
    "    y_pred = w * X + b\n",
    "\n",
    "    loss = np.power(y_orig - y_pred, 2).mean()\n",
    "\n",
    "    w_grad = (-2*(y_orig - y_pred)*X).mean()\n",
    "    b_grad = (-2*(y_orig - y_pred)).mean()\n",
    "\n",
    "    w -= alpha * w_grad\n",
    "    b -= alpha * b_grad\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        display_progress(i + 1, loss, w, b, X, y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8WgWrF4C2WK"
   },
   "source": [
    "На PyTorch то же самое сделать несколько проще - подсчет прямого прохода копируется почти дословно.\n",
    "\n",
    "Обратный проход мы уже умеем - нужно просто вызвать `loss.backward()`.\n",
    "\n",
    "Для обновления `w` и `b` нужно иметь в виду следующее. Во-первых, pytorch не даст просто так обновить их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zx4DoGeBMJd4"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad has been used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-656a5a42591d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad has been used in an in-place operation."
     ]
    }
   ],
   "source": [
    "w = torch.randn(1, requires_grad=True)\n",
    "\n",
    "w -= 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OjoUh-SMPBt"
   },
   "source": [
    "Проблема в сложности поддержки in-place операций для работы autograd ([In place operations with autograd](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd)).\n",
    "\n",
    "Но нам и не нужна поддержка градиентов! Мы не будем делать backward pass через эту операцию - нужно всего лишь обновить значение переменной. Чтобы сделать это, можно воспользовать контекстом `no_grad`, либо производить обновление непосредственно буфера, который использует данный тензор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zegkKd-cMOMj"
   },
   "outputs": [],
   "source": [
    "w.data -= 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVlaIdvHNXR_"
   },
   "source": [
    "Другое, что нужно помнить - градиенты в тензорах накапливаются. Между вызовами `loss.backward()` нужно обнулять градиенты у `w` и `b`:\n",
    "```python\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "```\n",
    "\n",
    "**Задание** Реализовать линейную регрессию на pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRqxypuEU2ig"
   },
   "outputs": [],
   "source": [
    "X = torch.as_tensor(X).float()\n",
    "y = torch.as_tensor(y).float()\n",
    "\n",
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "for i in range(100):\n",
    "    <copy forward pass and add backward pass + parameters updates>\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        display_progress(i + 1, loss, w.item(), b.item(), \n",
    "                         X.data.numpy(), y.data.numpy(), y_pred.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KaKTKN_fOvo-"
   },
   "source": [
    "Думать нужно уже гораздо меньше, да? :)\n",
    "\n",
    "Про другие фишки низкоуровнего pytorch можно почитать здесь: [PyTorch — ваш новый фреймворк глубокого обучения](https://habr.com/post/334380/) (статья веселая, но немного устарела, читать лучше с оглядкой на [PyTorch 0.4.0 Migration Guide](https://pytorch.org/blog/pytorch-0_4_0-migration-guide/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZNq6ujzPtvd"
   },
   "source": [
    "## Word embeddings и высокоуровневый API PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITLgcVz66AfV"
   },
   "source": [
    "Займёмся рассмотрением высокоуровневого API - в нем уже реализованы разные классы-запчасти для обучения нейронок.\n",
    "\n",
    "Будем решать всё ту же задачу, что и в прошлый раз - обучение словных эмбеддингов, только теперь мы будем учить их самостоятельно!\n",
    "\n",
    "Для начала нужно подготовить данные для обучения.\n",
    "\n",
    "Соберем и токенизируем тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKKb9Ya8hzIb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "quora_data = pd.read_csv('train.csv')\n",
    "\n",
    "quora_data.question1 = quora_data.question1.replace(np.nan, '', regex=True)\n",
    "quora_data.question2 = quora_data.question2.replace(np.nan, '', regex=True)\n",
    "\n",
    "texts = list(pd.concat([quora_data.question1, quora_data.question2]).unique())\n",
    "\n",
    "tokenized_texts = [word_tokenize(text.lower()) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYoj91iDDDfT"
   },
   "source": [
    "Соберем индекс самых частотных слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PL471pGjuVN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28634\n",
      "Tokens count: 6969946\n",
      "Unknown tokens appeared: 123601\n",
      "Most freq words: ['?', 'the', 'what', 'is', 'a', 'i', 'to', 'in', 'how', 'of', 'do', 'are', 'and', 'for', ',', 'can', 'you', 'why', 'it', 'my']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "MIN_COUNT = 5\n",
    "\n",
    "words_counter = Counter(token for tokens in tokenized_texts for token in tokens)\n",
    "word2index = {\n",
    "    '<unk>': 0\n",
    "}\n",
    "\n",
    "for word, count in words_counter.most_common():\n",
    "    if count < MIN_COUNT:\n",
    "        break\n",
    "        \n",
    "    word2index[word] = len(word2index)\n",
    "    \n",
    "index2word = [word for word, _ in sorted(word2index.items(), key=lambda x: x[1])]\n",
    "    \n",
    "print('Vocabulary size:', len(word2index))\n",
    "print('Tokens count:', sum(len(tokens) for tokens in tokenized_texts))\n",
    "print('Unknown tokens appeared:', sum(1 for tokens in tokenized_texts for token in tokens if token not in word2index))\n",
    "print('Most freq words:', index2word[1:21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DF5mYpCsE9Uh"
   },
   "source": [
    "### Skip-Gram Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "om1IG5XEMGRa"
   },
   "source": [
    "Начнем с skip-gram модели обучения word2vec.\n",
    "\n",
    "Это простая модель всего из двух слоев. Ее идея - учить вектора эмбеддингов такими, чтобы по ним можно было как можно лучше предсказать контекст соответствующих слов. То есть если мы хорошо научились кодировать слова, с которыми встречается данное - значит, мы что-то знаем и о нем самом. Например, естественным образом получится, что слова, встречающиеся в одинаковых контекстах (скажем, `apple` и `orange`)  будут иметь близкие вектора эмбеддингов.\n",
    "\n",
    "![loss](Images/Word2vecExample.jpeg \"Loss\")  \n",
    "*From cs224n, Lecture 2*\n",
    "\n",
    "Для этого мы моделируем вероятности $\\{P(w_{c+j}|w_c):  j = c-k, ..., c+k, j \\neq c\\}$, где $k$ - размер контекстного окна, $c$ - индекс центрального слова.\n",
    "\n",
    "![obj](Images/Objective.png \"Objective\")\n",
    "\n",
    "Соберем такую модель: будем учить пару матриц $U$ - матрицу эмбеддингов, которую потом и возьмем для своих задач, и $V$ - матрицу выходного слоя.\n",
    "\n",
    "Каждому слову в словаре соответствует строка в матрице $U$ и столбец $V$.\n",
    "\n",
    "![skip-gram](Images/SkipGram.png \"SkipGram\")\n",
    "\n",
    "Что тут происходит? Слово отображается в эмбеддинг - строку $u_c$. Дальше этот эмбеддинг умножается на матрицу $V$. \n",
    "\n",
    "В итоге получаем набор числе $v_j^T u_c$ - степень похожести слова с номером $j$ и нашего слова.\n",
    "\n",
    "Преобразуем эти числа в что-то вроде вероятностей - воспользуемся функцией softmax: $P(i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}$.\n",
    "\n",
    "А дальше будем считать кросс-энтропийные потери:\n",
    "\n",
    "$$-\\sum_{-k \\leq j \\leq k, j \\neq 0} \\log \\frac{\\exp(v_{c+j}^T u_c)}{\\sum_{i=1}^{|V|} \\exp(v_i^T u_c)} \\to \\min_{U, V}.$$\n",
    "\n",
    "В итоге, вектор $u_c$ будет приближаться к векторам $v_{c_j}$ из его контекста.\n",
    "\n",
    "Реализуем это всё, чтобы разобраться.\n",
    "\n",
    "#### Генерация батчей\n",
    "\n",
    "Для начала нужно собрать контексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocrsXgaynYPG"
   },
   "outputs": [],
   "source": [
    "def build_contexts(tokenized_texts, window_size):\n",
    "    contexts = []\n",
    "    for tokens in tokenized_texts:\n",
    "        for i in range(len(tokens)):\n",
    "            central_word = tokens[i]\n",
    "            context = [tokens[i + delta] for delta in range(-window_size, window_size + 1) \n",
    "                       if delta != 0 and i + delta >= 0 and i + delta < len(tokens)]\n",
    "\n",
    "            contexts.append((central_word, context))\n",
    "            \n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQBa6yQ9BXjp"
   },
   "outputs": [],
   "source": [
    "contexts = build_contexts(tokenized_texts, window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyQNK-9SBdb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', ['is', 'the']),\n",
       " ('is', ['what', 'the', 'step']),\n",
       " ('the', ['what', 'is', 'step', 'by']),\n",
       " ('step', ['is', 'the', 'by', 'step']),\n",
       " ('by', ['the', 'step', 'step', 'guide'])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbQKln_6yC4l"
   },
   "source": [
    "Преобразуем слова в индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOPRlKlLvUBA"
   },
   "outputs": [],
   "source": [
    "contexts = [(word2index.get(central_word, 0), [word2index.get(word, 0) for word in context]) \n",
    "            for central_word, context in contexts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYmrAi9gyIe-"
   },
   "source": [
    "Реализуем генератор батчей для нашей нейронки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6opX5cEp8LxC"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_skip_gram_batchs_iter(contexts, window_size, num_skips, batch_size):\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * window_size\n",
    "    \n",
    "    central_words = [word for word, context in contexts if len(context) == 2 * window_size and word != 0]\n",
    "    contexts = [context for word, context in contexts if len(context) == 2 * window_size and word != 0]\n",
    "    \n",
    "    batch_size = int(batch_size / num_skips)\n",
    "    batchs_count = int(math.ceil(len(contexts) / batch_size))\n",
    "    \n",
    "    print('Initializing batchs generator with {} batchs per epoch'.format(batchs_count))\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(len(contexts))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for i in range(batchs_count):\n",
    "            batch_begin, batch_end = i * batch_size, min((i + 1) * batch_size, len(contexts))\n",
    "            batch_indices = indices[batch_begin: batch_end]\n",
    "\n",
    "            batch_data, batch_labels = [], []\n",
    "\n",
    "            for data_ind in batch_indices:\n",
    "                central_word, context = central_words[data_ind], contexts[data_ind]\n",
    "                \n",
    "                words_to_use = random.sample(context, num_skips)\n",
    "                batch_data.extend([central_word] * num_skips)\n",
    "                batch_labels.extend(words_to_use)\n",
    "            \n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0D79MwB_gMe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing batchs generator with 295262 batchs per epoch\n"
     ]
    }
   ],
   "source": [
    "batch, labels = next(make_skip_gram_batchs_iter(contexts, window_size=2, num_skips=2, batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DXjZS3JyQZh"
   },
   "source": [
    "#### nn.Sequential\n",
    "\n",
    "Простейший способ реализовать модель на PyTorch - использовать модуль `nn.Sequential`. В нем нужно просто перечислить все слои, и он будет применять их последовательно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRw9Z4G__46O"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(len(word2index), 32),\n",
    "    nn.Linear(32, len(word2index))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ysn0DDpLyj1S"
   },
   "source": [
    "Еще одна особенность pytorch, о которой до сих пор не говорили - поддержка вычислений на видеокарте. На видеокарте большинство нейронок считается гораздо быстрее благодаря высокой параллелизации. Сказать pytorch'у, чтобы он считал на видеокарте, очень просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfmaUi3Uy9YT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Embedding(28634, 32)\n",
       "  (1): Linear(in_features=32, out_features=28634, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3c3UEa2zHhk"
   },
   "source": [
    "либо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHxAg5ZWzEKT"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHi1CL2pzxOg"
   },
   "source": [
    "Создать тензоры на видеокарте можно, например, так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ycx1O3_SzvmC"
   },
   "outputs": [],
   "source": [
    "batch = torch.cuda.LongTensor(batch)\n",
    "labels = torch.cuda.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtLMvOO2z3c8"
   },
   "source": [
    "Заставить модель посчитать значение можно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9wTpewTz3Dk"
   },
   "outputs": [],
   "source": [
    "logits = model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWJmDy_uzJgD"
   },
   "source": [
    "Теперь нам нужна функция потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7rlD62_ykYl"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss().cuda() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OxLBiBua0OZM"
   },
   "source": [
    "Посчитать значение можно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCaTB5cc0GVw"
   },
   "outputs": [],
   "source": [
    "loss = loss_function(logits, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAwx-pck0RxX"
   },
   "source": [
    "А теперь, конечно же, backprop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWt6gL0_0Npp"
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJkDOl6szRLm"
   },
   "source": [
    "И, наконец, оптимизатор.\n",
    "\n",
    "Будем использовать Adam. Интерфейс - передать список оптимизируемых параметров и learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-b5CIARzQ6m"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju5lO0Xi0hsV"
   },
   "source": [
    "Оптимизация идет просто - нужно вызвать `step()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9QK7nHu0Zw8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0196, -0.0375,  0.1588,  ..., -0.0771,  0.1564,  0.1165],\n",
      "        [-0.0805,  0.1727,  0.0152,  ...,  0.1089, -0.0936, -0.0901],\n",
      "        [ 0.0752,  0.0550,  0.1010,  ...,  0.1246,  0.1562, -0.0927],\n",
      "        ...,\n",
      "        [ 0.0023, -0.0448,  0.1571,  ..., -0.1264, -0.1630, -0.1352],\n",
      "        [ 0.1286,  0.0096, -0.0683,  ...,  0.0490,  0.0273,  0.1145],\n",
      "        [-0.0547, -0.1639,  0.0871,  ...,  0.1081,  0.0355, -0.1706]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0296, -0.0475,  0.1688,  ..., -0.0871,  0.1464,  0.1065],\n",
      "        [-0.0706,  0.1824,  0.0231,  ...,  0.0995, -0.0840, -0.0900],\n",
      "        [ 0.0850,  0.0647,  0.1101,  ...,  0.1163,  0.1658, -0.1008],\n",
      "        ...,\n",
      "        [ 0.0121, -0.0349,  0.1475,  ..., -0.1353, -0.1531, -0.1439],\n",
      "        [ 0.1384,  0.0194, -0.0602,  ...,  0.0396,  0.0370,  0.1056],\n",
      "        [-0.0449, -0.1540,  0.0783,  ...,  0.0988,  0.0453, -0.1797]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[1].weight)\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "print(model[1].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hnxyk1ew0pSk"
   },
   "source": [
    "И последнее - нужно обнулить градиенты!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMsuvEP90svi"
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PibTw33Azg7q"
   },
   "source": [
    "#### Реализация обучения skip-gram модели\n",
    "\n",
    "Наконец, напишем цикл обучения - как уже было с линейной регрессией.\n",
    "\n",
    " **Задание** Заполните цикл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewGMgYTXANzz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing batchs generator with 147631 batchs per epoch\n",
      "Step = 1000, Avg Loss = 7.4345, Time = 3.60s\n",
      "Step = 2000, Avg Loss = 6.8184, Time = 1.73s\n",
      "Step = 3000, Avg Loss = 6.7709, Time = 1.73s\n",
      "Step = 4000, Avg Loss = 6.6924, Time = 1.75s\n",
      "Step = 5000, Avg Loss = 6.6637, Time = 1.74s\n",
      "Step = 6000, Avg Loss = 6.6524, Time = 1.74s\n",
      "Step = 7000, Avg Loss = 6.6193, Time = 1.73s\n",
      "Step = 8000, Avg Loss = 6.6207, Time = 1.73s\n",
      "Step = 9000, Avg Loss = 6.6166, Time = 1.74s\n",
      "Step = 10000, Avg Loss = 6.5980, Time = 1.74s\n",
      "Step = 11000, Avg Loss = 6.5846, Time = 1.74s\n",
      "Step = 12000, Avg Loss = 6.5897, Time = 1.74s\n",
      "Step = 13000, Avg Loss = 6.5827, Time = 1.73s\n",
      "Step = 14000, Avg Loss = 6.5747, Time = 1.73s\n",
      "Step = 15000, Avg Loss = 6.5597, Time = 1.73s\n",
      "Step = 16000, Avg Loss = 6.5670, Time = 1.74s\n",
      "Step = 17000, Avg Loss = 6.5531, Time = 1.73s\n",
      "Step = 18000, Avg Loss = 6.5520, Time = 1.75s\n",
      "Step = 19000, Avg Loss = 6.5469, Time = 1.76s\n",
      "Step = 20000, Avg Loss = 6.5472, Time = 1.73s\n",
      "Step = 21000, Avg Loss = 6.5486, Time = 1.74s\n",
      "Step = 22000, Avg Loss = 6.5318, Time = 1.73s\n",
      "Step = 23000, Avg Loss = 6.5216, Time = 1.73s\n",
      "Step = 24000, Avg Loss = 6.5411, Time = 1.73s\n",
      "Step = 25000, Avg Loss = 6.5225, Time = 1.74s\n",
      "Step = 26000, Avg Loss = 6.5348, Time = 1.75s\n",
      "Step = 27000, Avg Loss = 6.5193, Time = 1.73s\n",
      "Step = 28000, Avg Loss = 6.5222, Time = 1.73s\n",
      "Step = 29000, Avg Loss = 6.5325, Time = 1.74s\n",
      "Step = 30000, Avg Loss = 6.5219, Time = 1.73s\n",
      "Step = 31000, Avg Loss = 6.5248, Time = 1.74s\n",
      "Step = 32000, Avg Loss = 6.5098, Time = 1.74s\n",
      "Step = 33000, Avg Loss = 6.5283, Time = 1.76s\n",
      "Step = 34000, Avg Loss = 6.5141, Time = 1.73s\n",
      "Step = 35000, Avg Loss = 6.5054, Time = 1.73s\n",
      "Step = 36000, Avg Loss = 6.5081, Time = 1.73s\n",
      "Step = 37000, Avg Loss = 6.5076, Time = 1.73s\n",
      "Step = 38000, Avg Loss = 6.5003, Time = 1.74s\n",
      "Step = 39000, Avg Loss = 6.4962, Time = 1.74s\n",
      "Step = 40000, Avg Loss = 6.5127, Time = 1.76s\n",
      "Step = 41000, Avg Loss = 6.4981, Time = 1.73s\n",
      "Step = 42000, Avg Loss = 6.5229, Time = 1.72s\n",
      "Step = 43000, Avg Loss = 6.5168, Time = 1.73s\n",
      "Step = 44000, Avg Loss = 6.4823, Time = 1.74s\n",
      "Step = 45000, Avg Loss = 6.5001, Time = 1.73s\n",
      "Step = 46000, Avg Loss = 6.5018, Time = 1.73s\n",
      "Step = 47000, Avg Loss = 6.5084, Time = 1.75s\n",
      "Step = 48000, Avg Loss = 6.5036, Time = 1.74s\n",
      "Step = 49000, Avg Loss = 6.4797, Time = 1.74s\n",
      "Step = 50000, Avg Loss = 6.5010, Time = 1.74s\n",
      "Step = 51000, Avg Loss = 6.5024, Time = 1.74s\n",
      "Step = 52000, Avg Loss = 6.4902, Time = 1.73s\n",
      "Step = 53000, Avg Loss = 6.4993, Time = 1.73s\n",
      "Step = 54000, Avg Loss = 6.4892, Time = 1.74s\n",
      "Step = 55000, Avg Loss = 6.5082, Time = 1.75s\n",
      "Step = 56000, Avg Loss = 6.4948, Time = 1.73s\n",
      "Step = 57000, Avg Loss = 6.4828, Time = 1.74s\n",
      "Step = 58000, Avg Loss = 6.4911, Time = 1.74s\n",
      "Step = 59000, Avg Loss = 6.4966, Time = 1.74s\n",
      "Step = 60000, Avg Loss = 6.4792, Time = 1.73s\n",
      "Step = 61000, Avg Loss = 6.4880, Time = 1.74s\n",
      "Step = 62000, Avg Loss = 6.4800, Time = 1.73s\n",
      "Step = 63000, Avg Loss = 6.4902, Time = 1.74s\n",
      "Step = 64000, Avg Loss = 6.4927, Time = 1.73s\n",
      "Step = 65000, Avg Loss = 6.4990, Time = 1.73s\n",
      "Step = 66000, Avg Loss = 6.4886, Time = 1.75s\n",
      "Step = 67000, Avg Loss = 6.4924, Time = 1.73s\n",
      "Step = 68000, Avg Loss = 6.4915, Time = 1.74s\n",
      "Step = 69000, Avg Loss = 6.4788, Time = 1.76s\n",
      "Step = 70000, Avg Loss = 6.4646, Time = 1.74s\n",
      "Step = 71000, Avg Loss = 6.4804, Time = 1.74s\n",
      "Step = 72000, Avg Loss = 6.4793, Time = 1.73s\n",
      "Step = 73000, Avg Loss = 6.4936, Time = 1.74s\n",
      "Step = 74000, Avg Loss = 6.4735, Time = 1.74s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-3a11b2be2f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/temp3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/temp3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_every_nsteps = 1000\n",
    "total_loss = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for step, (batch, labels) in enumerate(make_skip_gram_batchs_iter(contexts, window_size=2, num_skips=4, batch_size=128)):\n",
    "    batch = torch.Tensor(batch).long().cuda()\n",
    "    labels = torch.Tensor(labels).long().cuda()\n",
    "    \n",
    "    \n",
    "    output = model(batch)\n",
    "    \n",
    "    loss = loss_function(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    if step != 0 and step % loss_every_nsteps == 0:\n",
    "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
    "                                                                    time.time() - start_time))\n",
    "        total_loss = 0\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pqq9kee41L4P"
   },
   "source": [
    "#### Анализ\n",
    "\n",
    "Получить эмбеддинги можно, скаставав такое заклинание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWsYkNn-Hnl_"
   },
   "outputs": [],
   "source": [
    "embeddings = model[0].weight.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZtxY2D01RB6"
   },
   "source": [
    "Проверим, получилось ли хоть сколько-то адекватно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhDwuhDSHEDm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm',\n",
       " 'lemon',\n",
       " 'perm',\n",
       " 'diabetic',\n",
       " 'shower',\n",
       " 'liter',\n",
       " 'odor',\n",
       " 'salt',\n",
       " 'strain',\n",
       " 'frozen']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def most_similar(embeddings, index2word, word2index, word):\n",
    "    word_emb = embeddings[word2index[word]]\n",
    "    \n",
    "    similarities = cosine_similarity([word_emb], embeddings)[0]\n",
    "    top10 = np.argsort(similarities)[-10:]\n",
    "    \n",
    "    return [index2word[index] for index in reversed(top10)]\n",
    "\n",
    "most_similar(embeddings, index2word, word2index, 'warm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VS1x-mO1WKS"
   },
   "source": [
    "И визуализируем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yuXv2HxsAecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1000 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1000 samples in 0.065s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1000\n",
      "[t-SNE] Mean sigma: 1.029957\n",
      "[t-SNE] Computed conditional probabilities in 0.035s\n",
      "[t-SNE] Iteration 50: error = 76.7710724, gradient norm = 0.3174151 (50 iterations in 2.412s)\n",
      "[t-SNE] Iteration 100: error = 76.5398102, gradient norm = 0.3147166 (50 iterations in 2.624s)\n",
      "[t-SNE] Iteration 150: error = 78.5041504, gradient norm = 0.3070565 (50 iterations in 2.644s)\n",
      "[t-SNE] Iteration 200: error = 78.8458939, gradient norm = 0.3119738 (50 iterations in 2.741s)\n",
      "[t-SNE] Iteration 250: error = 78.0395813, gradient norm = 0.3163238 (50 iterations in 2.931s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 78.039581\n",
      "[t-SNE] Iteration 300: error = 2.0139270, gradient norm = 0.0028015 (50 iterations in 1.997s)\n",
      "[t-SNE] Iteration 350: error = 1.9157159, gradient norm = 0.0004876 (50 iterations in 1.640s)\n",
      "[t-SNE] Iteration 400: error = 1.8850043, gradient norm = 0.0003353 (50 iterations in 1.645s)\n",
      "[t-SNE] Iteration 450: error = 1.8691894, gradient norm = 0.0003051 (50 iterations in 3.285s)\n",
      "[t-SNE] Iteration 500: error = 1.8609747, gradient norm = 0.0002071 (50 iterations in 2.951s)\n",
      "[t-SNE] Iteration 550: error = 1.8574791, gradient norm = 0.0001146 (50 iterations in 2.639s)\n",
      "[t-SNE] Iteration 600: error = 1.8550096, gradient norm = 0.0001310 (50 iterations in 2.302s)\n",
      "[t-SNE] Iteration 650: error = 1.8534472, gradient norm = 0.0001187 (50 iterations in 2.142s)\n",
      "[t-SNE] Iteration 700: error = 1.8518431, gradient norm = 0.0000972 (50 iterations in 2.029s)\n",
      "[t-SNE] Iteration 750: error = 1.8509140, gradient norm = 0.0000763 (50 iterations in 1.978s)\n",
      "[t-SNE] Iteration 800: error = 1.8501964, gradient norm = 0.0000773 (50 iterations in 1.891s)\n",
      "[t-SNE] Iteration 850: error = 1.8493944, gradient norm = 0.0000987 (50 iterations in 1.789s)\n",
      "[t-SNE] Iteration 900: error = 1.8483919, gradient norm = 0.0000839 (50 iterations in 1.704s)\n",
      "[t-SNE] Iteration 950: error = 1.8477602, gradient norm = 0.0000824 (50 iterations in 1.722s)\n",
      "[t-SNE] Iteration 1000: error = 1.8465160, gradient norm = 0.0000937 (50 iterations in 1.625s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.846516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:193: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1222\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1222\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1222\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1222' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1222\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1222\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1222\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1222' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1222\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"fad1fff0-ad6d-4abe-b465-70ae726840e6\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"088ba184-8ed3-44bb-bef1-f6049e0b24a2\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1233\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1238\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1233\",\"type\":\"LinearAxis\"},{\"id\":\"1237\",\"type\":\"Grid\"},{\"id\":\"1238\",\"type\":\"LinearAxis\"},{\"id\":\"1242\",\"type\":\"Grid\"},{\"id\":\"1251\",\"type\":\"BoxAnnotation\"},{\"id\":\"1261\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1283\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1249\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1225\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1229\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1227\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1231\",\"type\":\"LinearScale\"}},\"id\":\"1224\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1259\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1289\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1231\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1290\",\"type\":\"Selection\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1244\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1243\",\"type\":\"PanTool\"},{\"id\":\"1244\",\"type\":\"WheelZoomTool\"},{\"id\":\"1245\",\"type\":\"BoxZoomTool\"},{\"id\":\"1246\",\"type\":\"SaveTool\"},{\"id\":\"1247\",\"type\":\"ResetTool\"},{\"id\":\"1248\",\"type\":\"HelpTool\"},{\"id\":\"1263\",\"type\":\"HoverTool\"}]},\"id\":\"1249\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1234\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1243\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1244\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1251\",\"type\":\"BoxAnnotation\"}},\"id\":\"1245\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1246\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1247\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1239\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1248\",\"type\":\"HelpTool\"},{\"attributes\":{\"plot\":{\"id\":\"1224\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1234\",\"type\":\"BasicTicker\"}},\"id\":\"1237\",\"type\":\"Grid\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1251\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"token\":[\"?\",\"the\",\"what\",\"is\",\"a\",\"i\",\"to\",\"in\",\"how\",\"of\",\"do\",\"are\",\"and\",\"for\",\",\",\"can\",\"you\",\"why\",\"it\",\"my\",\"does\",\"best\",\"on\",\".\",\"or\",\"have\",\"if\",\"be\",\"with\",\"which\",\"that\",\"an\",\"some\",\"should\",\"'s\",\"get\",\"from\",\")\",\"your\",\"(\",\"like\",\"when\",\"at\",\"india\",\"good\",\"who\",\"there\",\"will\",\"as\",\"would\",\"people\",\"not\",\"n't\",\"about\",\"``\",\"''\",\"between\",\"one\",\"did\",\"any\",\"we\",\"me\",\"where\",\"most\",\"was\",\"by\",\"make\",\"so\",\"they\",\"this\",\"am\",\"after\",\"way\",\":\",\"has\",\"use\",\"much\",\"difference\",\"time\",\"life\",\"their\",\"know\",\"work\",\"many\",\"but\",\"than\",\"more\",\"all\",\"want\",\"quora\",\"someone\",\"learn\",\"find\",\"other\",\"think\",\"new\",\"better\",\"job\",\"indian\",\"out\",\"money\",\"mean\",\"become\",\"ever\",\"world\",\"without\",\"he\",\"start\",\"take\",\"us\",\"up\",\"first\",\"feel\",\"year\",\"into\",\"go\",\"online\",\"used\",\"engineering\",\"could\",\"love\",\"'m\",\"person\",\"were\",\"possible\",\"day\",\"buy\",\"things\",\"being\",\"need\",\"business\",\"using\",\"them\",\"really\",\"trump\",\"girl\",\"'\",\"her\",\"his\",\"years\",\"different\",\"long\",\"phone\",\"google\",\"company\",\"been\",\"old\",\"only\",\"no\",\"now\",\"just\",\"2\",\"app\",\"college\",\"facebook\",\"number\",\"free\",\"books\",\"2016\",\"movie\",\"still\",\"its\",\"account\",\"ca\",\"women\",\"book\",\"english\",\"while\",\"she\",\"had\",\"change\",\"ways\",\"computer\",\"thing\",\"examples\",\"data\",\"country\",\"over\",\"see\",\"android\",\"help\",\"science\",\"live\",\"school\",\"software\",\"before\",\"&\",\"language\",\"same\",\"going\",\"bad\",\"sex\",\"student\",\"stop\",\"university\",\"happen\",\"back\",\"made\",\"3\",\"1\",\"study\",\"our\",\"two\",\"through\",\"system\",\"name\",\"say\",\"real\",\"during\",\"prepare\",\"water\",\"iphone\",\"website\",\"top\",\"car\",\"questions\",\"important\",\"men\",\"give\",\"getting\",\"anyone\",\"companies\",\"high\",\"black\",\"card\",\"read\",\"programming\",\"war\",\"learning\",\"10\",\"5\",\"\\u2019\",\"exam\",\"[\",\"then\",\"]\",\"even\",\"movies\",\"china\",\"mobile\",\"cost\",\"donald\",\"right\",\"doing\",\"friend\",\"him\",\"working\",\"under\",\"come\",\"president\",\"own\",\"question\",\"career\",\"experience\",\"bank\",\"true\",\"friends\",\"guy\",\"word\",\"hair\",\"home\",\"video\",\"having\",\"look\",\"usa\",\"tell\",\"man\",\"social\",\"web\",\"interview\",\"very\",\"engineer\",\"write\",\"game\",\"government\",\"weight\",\"earth\",\"girls\",\"service\",\"food\",\"students\",\"play\",\"countries\",\"human\",\"place\",\"future\",\"improve\",\"off\",\"big\",\"days\",\"happens\",\"'ve\",\"done\",\"class\",\"eat\",\"tv\",\"process\",\"got\",\"state\",\"average\",\"s\",\"meaning\",\"relationship\",\"music\",\"too\",\"math\",\"create\",\"instagram\",\"every\",\"history\",\"last\",\"pay\",\"windows\",\"4\",\"white\",\"watch\",\"%\",\"salary\",\"body\",\"power\",\"safe\",\"clinton\",\"ask\",\"age\",\"laptop\",\"makes\",\"$\",\"each\",\"hard\",\"lose\",\"american\",\"delhi\",\"youtube\",\"energy\",\"worth\",\"earn\",\"states\",\"against\",\"win\",\"girlfriend\",\"great\",\"keep\",\"test\",\"god\",\"hillary\",\"compare\",\"market\",\"differences\",\"making\",\"considered\",\"something\",\"answer\",\"apply\",\"myself\",\"mba\",\"tips\",\"around\",\"never\",\"next\",\"always\",\"mechanical\",\"another\",\"united\",\"java\",\"increase\",\"c\",\"such\",\"course\",\"jobs\",\"download\",\"song\",\"parents\",\"kind\",\"internet\",\"common\",\"review\",\"woman\",\"code\",\"design\",\"per\",\"employees\",\"end\",\"development\",\"chinese\",\"series\",\"score\",\"interesting\",\"degree\",\"month\",\"travel\",\"show\",\"management\",\"months\",\"able\",\"believe\",\"open\",\"program\",\"living\",\"looking\",\"because\",\"6\",\"type\",\"bangalore\",\"light\",\"favorite\",\"america\",\"today\",\"actually\",\"major\",\"family\",\"marketing\",\"pakistan\",\"universities\",\"technology\",\"law\",\"call\",\"affect\",\"whatsapp\",\"idea\",\"{\",\"build\",\"}\",\"choose\",\"cat\",\"current\",\"support\",\"problem\",\"popular\",\"speed\",\"air\",\"rid\",\"deal\",\"visa\",\"join\",\"run\",\"games\",\"space\",\"down\",\"both\",\"well\",\"city\",\"2017\",\"house\",\"exist\",\"services\",\"available\",\"civil\",\"u.s.\",\"site\",\"culture\",\"also\",\"normal\",\"given\",\"wrong\",\"apple\",\"7\",\"small\",\"order\",\"date\",\"wear\",\"apps\",\"places\",\"songs\",\"differ\",\"project\",\"product\",\"international\",\"x\",\"behind\",\"main\",\"research\",\"happened\",\"boyfriend\",\"media\",\"public\",\"canada\",\"value\",\"jee\",\"cause\",\"reason\",\"uk\",\"education\",\"email\",\"ms\",\"sleep\",\"-\",\"amazon\",\"instead\",\"these\",\"benefits\",\"startup\",\"less\",\"iit\",\"part\",\"list\",\"based\",\"die\",\"medical\",\"websites\",\"etc\",\"physics\",\"skills\",\"child\",\"form\",\"health\",\"causes\",\"called\",\"times\",\"visit\",\"hate\",\"level\",\"worst\",\"police\",\"legal\",\"control\",\"terms\",\"stay\",\"products\",\"mumbai\",\"post\",\"facts\",\"mind\",\"face\",\"application\",\"rate\",\"sites\",\"field\",\"file\",\"required\",\"humans\",\"sell\",\"seen\",\"story\",\"machine\",\"private\",\"dog\",\"notes\",\"stock\",\"modi\",\"biggest\",\"asked\",\"invest\",\"children\",\"point\",\"writing\",\"move\",\"night\",\"problems\",\"gate\",\"put\",\"'re\",\"successful\",\"single\",\"anything\",\"indians\",\"others\",\"remove\",\"compared\",\"theory\",\"death\",\"ideas\",\"talk\",\"marks\",\"answers\",\"plan\",\"similar\",\"sentence\",\"low\",\"group\",\"institute\",\"side\",\"hours\",\"again\",\"effects\",\"/math\",\"coaching\",\"australia\",\"solve\",\"advantages\",\"correct\",\"function\",\"tax\",\"lot\",\"center\",\"famous\",\"send\",\"germany\",\"guys\",\"add\",\"set\",\"offer\",\"south\",\"force\",\"credit\",\"foreign\",\"universe\",\"information\",\"fall\",\"period\",\"daily\",\"says\",\"developer\",\"training\",\"full\",\"videos\",\"area\",\"industry\",\"oil\",\"model\",\"general\",\"studying\",\"majors\",\"star\",\"colleges\",\"graduate\",\"size\",\"yourself\",\"drive\",\"python\",\"2015\",\"blood\",\"near\",\"search\",\"enough\",\"price\",\"kill\",\"quality\",\"words\",\"8\",\"cons\",\"marriage\",\"found\",\"often\",\"\\u201d\",\"leave\",\"pros\",\"fast\",\"grow\",\"courses\",\"started\",\"week\",\"fix\",\"related\",\"purpose\",\"network\",\"types\",\"russia\",\"advice\",\"those\",\"password\",\"follow\",\"taking\",\"married\",\"mass\",\"male\",\"store\",\"turn\",\"party\",\"left\",\"brain\",\"rs\",\"\\u201c\",\"numbers\",\"100\",\"500\",\"female\",\"share\",\"digital\",\"team\",\"1000\",\"effective\",\"economy\",\"term\",\"text\",\"delete\",\"election\",\"cell\",\"pc\",\"master\",\"office\",\"matter\",\"few\",\"role\",\"since\",\"preparation\",\"fat\",\"second\",\"page\",\"dark\",\"short\",\"said\",\"happy\",\"red\",\"line\",\"away\",\"security\",\"options\",\"easy\",\"effect\",\"three\",\"view\",\"admission\",\"must\",\"chemical\",\"source\",\"lost\",\"try\",\"dream\",\"understand\",\"care\",\"exams\",\"convert\",\"americans\",\"past\",\"electrical\",\"dogs\",\"profile\",\"alcohol\",\"exactly\",\"north\",\"ios\",\"develop\",\"paper\",\"japanese\",\"investment\",\"tech\",\"difficult\",\"hotel\",\"check\",\"beautiful\",\"personal\",\"calculate\",\"japan\",\"uber\",\"letter\",\"eating\",\"religion\",\"20\",\"explain\",\"languages\",\"c++\",\"b\",\"hyderabad\",\"topics\",\"british\",\"twitter\",\"basic\",\"news\",\"california\",\"self\",\"green\",\"political\",\"transfer\",\"wife\",\"12\",\"fight\",\"rank\",\"drug\",\"let\",\"porn\",\"film\",\"scope\",\"t\",\"army\",\"pune\",\"national\",\"once\",\"contact\",\"note\",\"known\",\"avoid\",\"boy\",\"gain\",\"please\",\"address\",\"wants\",\"reasons\",\"paid\",\"obama\",\"engine\",\"europe\",\"ex\",\"currently\",\"bollywood\",\"samsung\",\"smart\",\"everyone\",\"season\",\"phd\",\"income\",\"officer\",\"chances\",\"reduce\",\"option\",\"overcome\",\"everything\",\"across\",\"reading\",\"military\",\"else\",\"users\",\"meet\",\"15\",\"solar\",\"message\",\"charge\",\"knowledge\",\"due\",\"sound\",\"balance\",\"microsoft\",\"!\",\"internship\",\"faster\",\"photos\",\"pregnant\",\"sim\",\"yes\",\"moon\",\"taken\",\"financial\",\"hindi\",\"disadvantages\",\"pass\",\"animals\",\"messages\",\"gay\",\"/\",\"hack\",\"healthy\",\"pain\",\"systems\",\"amount\",\"color\",\"interested\",\"singapore\",\"ias\",\"natural\",\"skin\",\"screen\",\"chance\",\"names\",\"special\",\"height\",\"board\",\"case\",\"structure\",\"passport\",\"break\",\"pro\",\"created\",\"professional\",\"drink\",\"already\",\"percentage\",\"useful\",\"french\",\"crush\",\"sun\",\"dating\",\"likes\",\"presidential\",\"battery\",\"interest\",\"access\",\"coming\",\"provide\",\"muslim\",\"starting\",\"modern\",\"linux\",\"recover\",\"camera\",\"german\",\"expect\",\"vote\",\"muslims\",\"blue\",\"least\",\"install\",\"train\",\"studies\",\"solution\",\"thinking\",\"following\",\"negative\",\"mother\",\"jio\",\"mac\",\"user\",\"spend\",\"prime\",\"written\",\"buying\",\"feeling\",\"running\",\"football\",\"gift\",\"cold\",\"changed\",\"pressure\",\"allowed\",\"character\",\"brand\",\"rich\",\"snapchat\",\"resources\",\"within\",\"speak\",\"impact\",\"islam\",\"yet\",\"non\",\"marry\",\"eyes\",\"society\",\"bill\",\"likely\",\"though\",\"determine\",\"shows\",\"fake\",\"save\",\"capital\",\"final\",\"gmail\",\"picture\",\"laws\",\"middle\",\"applications\",\"nuclear\",\"chemistry\",\"young\",\"kids\",\"prefer\",\"device\",\"iq\",\"father\",\"views\",\"galaxy\",\"manager\",\"doctor\",\"personality\",\"hand\",\"greatest\",\"currency\",\"inside\",\"illegal\",\"stories\",\"strategy\",\"recruit\",\"pursue\",\"cs\",\"abroad\",\"gold\",\"projects\",\"consider\",\"works\",\"blog\",\"crack\",\"memory\",\"example\",\"neet\",\"growth\",\"schools\",\"necessary\",\"husband\",\"insurance\",\"alone\",\"economics\",\"depression\",\"higher\",\"dead\",\"b.tech\",\"30\",\"cse\",\"loss\",\"among\",\"files\",\"deleted\",\"easiest\",\"macbook\",\"together\",\"art\",\"wifi\",\"vs\",\"gas\",\"suggest\",\"late\",\"intelligence\",\"method\",\"gre\",\"head\",\"minimum\",\"version\",\"tools\",\"easily\",\"chennai\",\"cars\",\"suitable\"],\"x\":{\"__ndarray__\":\"U3HEPgjHvb05saY+rTQ/vYlfRr55No0+PMu6PihmjT6pA5Y+VKB+PnTzvD3+Xhw/MSmyPpWhjT4W/tk+Tj3TPVQbjj6+xdo+rkClviErX77RX649hnoTvxoct7+U07U+e3KWPtnIdb4s0lg+2gHaOX9XOz5mEvw+8gRCPtSoML5LoS2+uyoePheUlj70ECK/7bRGPnknUD+lpI2+W61JP/OzLz+KqGA+AhAiPoHnsz+bJuG+4goHPn+87j6f+rk8cNe6Pu+9tDyHUIA/hpZ5PgNkuj4vyI49AxQSP2nlGz/xxMe9ULqZPrlxuD0DnIK+sfGWPm9gyb5Vhos+FUjwvjHtdr0iCpU+O/QVv8PZwT5nE6I+n46ePlfXSL/LIvI934T6vxnHyT4u3Yi+pLwyvzCLDT/a5q69UckhvttdK78u6VG+ycl6vopBFL9ib5M/PReIPshRf796WCk/asDFPhQzHT5HDta/mgTCvrM9VD4wDze/kNg1v+NxVr5Aqhy/Yp1Sv3cIpr6bdok/yEYAvlJKYr+m5AW+C3Uhv9532r7sUkA/mjh1PppV1L4K982+nuFtuzveiD+T5FW9VMn/vvAtzj7rQOM/VPbzPRu4YTz3ko2/r+QqPxR/4z9N3Zg8RHK3Pl6uSb+xNgq/yHF5vpCebD8HELc/w5Vgv5fPob8/DXU/f9QgPpyxJr9FWIu/OgCXvqaMkj4NYC8/sCpEvylLIT/2GXi+ZUpZvkzG1j/CXja/7yhcviqz9b8cwKi/w/Rmv71D1b5C/FK/UlmDPhVV+j5KrpY+rOt5PgY/zT/U4Nu/1TXRP32U2L+nJS49lDKPv/Xopr+F2pE/m+59P8t2jD7BFbi9YD36v7jFiD02v3I/Silkv9M8lr/+6E49LbXOvrDllL7SoRa/rzf3vyEwmb8yIBC/YpvnPiPqnL+6w1k/ShLbPeO4j75GG+O//HDQvojJvT9Epf69lv3DP2xkn79DoBk+8NKsPmVtwb/7nKg+iOdKP/q54L7w0UW+QdDZPxzlzr5TtMw/QJE1vrFtlL3CMEQ+iEbKP50lyT9IE8Y9aYz0vZWmtj+W1k8+I29xPmtIlbz7QGq+iRcSv1vLxT7uU/c9e9rIvKvg8b+wAJ+/r24dv2cAeb/fk8W/pDZlv5rZbD/Aq+a+WUaDPxxbBr/swJm/iDTnPs9+AT7F2wPAQWuMPiVb0b9yUlg/Q43Tv5+Mwj93MsE/wi3DP5ybCECZkQ9APuD3PkYlDkBbjl8+JW6Kv6mKrT/8m+G/VIQ6vRfYHD/ksC0+OfeOP9Jk27+Lcsm+bxBDv5a5fz8SAy++3rJjP9ZFvr/U+cS/+z03v093kb6fHwPAw8bBvZ5+Fb9CEEm/gW8FP4O2Sj7J/Cq/8z2kv3aZGj7OT0s9YaaMP/qvAr+XVhS/YWBpv9qGr789F7y+w+gGPfU7yb8V12m/P13Jvt36ez+Qjrs/77keP28Wcj/lr4i/DjtovdRSxD//h5q/jm6GPz7IDj8MyP6/MYWHPTxtoL585Ra8J8HJPfD/0D+WR8S9MongvkgRCr3HUglAibnvPpmeiL9vhb++31UuvxcaxT/HeNu9V3DBPza+x7wbwTI+ek6cvyKWoDy22w9ASYhJv/T/4r8aLZc/uERrP51+lj+Zt1M+niruv/v1zz/N3gY+QSSUvx2ywj8qHxi+3nhrPrvjuD51+3U/xMx9P/YdFL+tWpO7epoEwJgR/72JFsM/4hJ8P09mQ7/GI7E/O4WJPz5y0T/W06i/ZfS/PoyDTT86Fiu/EAeWP92/kz9nwmQ/8TcLvxVWnr4FOM6+Z3DvPqkbMD/mWBo/C/aPPb8/Jr+tn7e91xcsvxJbvb57d6y/w0d7vzIn5z0Yu2K+87fkP7Hps7/WiIQ+rDTMvk5isT/trhK+80fwP4XxQL5ry4g/EnXEv5RA477ALN2/qh1nvri7hL/h0B2/uA+avzdkCD/VmBm/dwuVPsFD2r8NYka/FheUvlCPSr+N+b6/mreWv/ahnD+I8Ii/Dzc+P/mGrb8yJLG+R/z7vkRFEkBPe1K/QRHPP4q1xj/h5ye++XRbvtiplL8kwtU/rOYXP02COL4hQDa/Qhk9P0e4RL+oDNK/z84iPoMXyz8nXW290+zGP/Hb5z5M6a6+9ZmeP56+wD9c1J8+JMNyv/XajjwqpH6/V+qoP9HuGr+JvDG/KBeWO98OOL8o6ai+//7nv5WpYb+vfw9A6jJSvyFgD0DvFTe/oq4EQAAh+z2YO5w+XEb/PhfsQ7+eel0++VAzPZNeKr6cFeA+t8zlP5GkkT3hADK/PBamv7Mf/D5C6+a8Ur8JP4B0Dj9mHcE/A28GQMwIl7+LlUA//wGIv9c0Jb/2s/M/iASHP1Pwpb/ANRq/F4KAvkGCKz+NdzI+onmhvrMxdL8eOMw/FYNbv2IV+z6FWwq/jOVlvwhMuL9ImP6/ZWyjv/Q/gb/HcqW/nDuTv/VSqT8Rr1k//q81Pf7eRr6kf8G/1zT0vV7XD79F1m6/Dp2ZP8WysT8NHLi9mMkGQPz30T42LeK+QC/kP12fST9MMd+/rqHSP+VU2z4H0T4/c/2ev1V0zD7gtZ8/XoDdPqQxfL+3JSs/QOnqP/wfpT7t+Ii+rFa9v87SzD6QW90/ywCsv/YKET9AWfM9DF7AvwUKL78c0o4+jF/evnCnxT5VrQ0/1CzKPzAcg71HYKE+sQMmP5TJ+b7ogqY/n/fhPk0L2b4VcXM/msfaveTYoL9D288/ZjTSv0xonr/OS3O/XDl/Owqozr9xPbU+HRerv6Q+Q74S6zi/J5tcPwRuFj+e2QO/ZNjavgSkq764zMu/jZyGv8somDt0Gak/2mBZv1PAbz9eNfa+Fc7Bv7RKK79Vr2Q/LzecvXG0wb/nEma+VOyZP4RgCD9GdwVA6wAAv6FYmr6urge/flSUvsDg1D69+4c/r1KkvrqFAr9ZK0E/ffXXPc1j2TqJWl6/cbDvvUvsEUA2PtC/HBIWvDxEqr/OTUw/4nZSv1NCh7+pZIG/DDyiPrBK0T+673S++EG2PmLjEEDNEfU/hY20P0RuWL8waNY+iUfTPm22qb0B1lI+2qy6Pkdm4j+YsUS/0PQev6Dpmz+Rn28/+bpGv9P/Mb9rICe/qfqyPxpIjD56NMK/WXadPxrcIz9+aLc/ueV3vj3dXr6WlcC+uE0GvsgXp78XQF+/ZMGoPjmepL8BItI/0qRpvwlBHL3y8Ia8J4eYP3zKiz+L9iw/+8ZcP8H10j/Lm9U/1RbuPRaJlb8ulma+1ULSv+Ynjz90mIg9tCvfP86xQL8xddw+3LuMvloKab7KTJO/LugJP2XG0j/GVwg/skZgO6v11b4khdw+b74eP5TAqb7c+9U+6yyrPtZqxr6F1r6/Rr9MvWnf9j7i0U2/M0RBP7yAq7vARZS/cw+xPhm5oT9jJsG+nxOJP72W6b/jS9C+f9yFP7rhpL6atS0+m8rAvrnNnr/qahi/MXZVP90ioz2Ogos+93e2P+9VHT94N6o/FQ/OP+4Ntz/bEOK+ggfzvrD2eb+PfYg/NwS6PzvAPr/qgnE/VzJQvXQj+r/RGI2/swhhP17M/78cQQDAlOjSP9HJfr+sAdk+92biP8NZHrtEPFc9u9MRQCXLtD/N5ko/fIm8v4eVUD5EUd++BwhqPdqSr75P/i89RdyaPtQb471zFpG/711Rv4jnS78mlCA+r52xP1amDb9LsL0/O50xvpUQmj/wN6W/54fhvSPLez65X+a+qcRnPoA+LL/n6QtAUthQvx9KhT+yPaw/BxjwP/kjVT/h7eG/Nw5NP+u7Aj/6yLA/nnPlvynJUr/oTSg/Otmzvo3ELr9sWo6/OAdov2L6rj9s0DC/8wdPv3/9Ib/qc12/JRCcP/xGP78vzD2//fhfP0dWMD9DFdU/q+KBvb+4x7+qhM+/9HcJQM+C1z/awLq/ghiDP4amzb98J1y/w6uCv/ZL0z/CPaQ/cPyXPUHra7+ZKS2/vLQrvyrU5j8MlVo/YNsQQFpzwr+GlCq9hoOAv/wMor50GwO+okXCPytTcj9ZttM/T0+kPz7OOD7e8GO/bG+jPysGmL8B8s6+zk1Nv+gDsj+LrQq/LOfZvxE44754xOG+0goLviBTNj/StoK/Xi+8P57g/L6r8vA/5paHv/E4CsDAO3a/sP3Hv3Le2D94kc8/nEI/Pv1OqD9fTzA+Ma3Qviv7A7+MN+C+m6i1v1vTgb/Nxf29qheMPyg7t79THsG/mxSPvlIf2D9lrJy/+aXwv7tVxb2OwmK/TQgNPdaZGT99m6e/YEmxv1/lOT9UjdU/X8gxP3yWfb867oe+o98IwKKuGz9xuRq9OHcSPyNqxL9Fy9++LMjfPknIAL+t4YA/ihXwv+NPsb6hAwk/xzlcv3aG9b6bvis/8VWtv8R3cz7AhtW9MWz1P6OxxT9gswFAB3a+vnAvUD58BXA8EBgwPlqTn76CuJW/fXK+P9BCCUAuUN0+IJJXv4YwA8C/y+O9j41nP+df/b1ODRu/no7YPqeypr7kBgg+uNUvv4QibD8IfOu/79wUP/knRb+bDtK+Gg+SP0GxEj/4jjw+V2s4v9SkLD8CvP6+7RhjP0USD792uTQ/jSDdv/CZjb/vBpe/vq5rPzrgPL812Bk/EGyTP41ZKT3ho/a+BRhpvyQVCr9dQsQ/A1b7viiViz85K7M+OVtCPgqmPL8+yQfAr7Ppv3Nm278HeIq+xBpyP0QFxr/I0TG/nOGDP0Lbnr6N9oA/XB+FvzK3Nz+prBO//6vaPd/PND8+ZMO+8WOQv1WvaT8+DuC/WZG2vzbZ2D4uISM+WdoNPkkqcT8Kxa4+5HQbviiFzL51OpY+4m7wP3sYDj9AYD4/RY4xPq4Tar9/2UW9Q478PRfoFL97EJY/j5XdP3x7+L8kZ9S/nTyNP1g5iD8lV7O/S3wwPzudtb8fL7e+ibwbv2aGhj6aSPG/f7xSvnXeJb9mftG/0FsKwDV7z78lmRq/f5fovvIhPb585dm+FOK0P+JWyTwjQF0/29XRvwiAV7+EWlk/yx3dPVAtzT8ggrI/dqqdP42Kob98wOy9Q/0Yv38X579f7oU+7fE5PNXDUL5sZAtAwdHuveYbyT8K4WE/vJwmv2TtP7+FJUM/MQLBP3cwgj88VzW/ZFsYP9v93j+1rr8/aKTeP25bxT6YV8c+DJoHwI9w979jDx+/v2AEwDC9xz41o4i//57rv/bRXz+Bst49PKTcvnL+Zj/hoEs+11xZv7ndB0D3ECg/CTg8P1Q5Br79T6+/m5J/Pso71D//rZy/zAjivg==\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1290\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1289\",\"type\":\"UnionRenderers\"}},\"id\":\"1223\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"1223\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1259\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1260\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1262\",\"type\":\"CDSView\"}},\"id\":\"1261\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1223\",\"type\":\"ColumnDataSource\"}},\"id\":\"1262\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1263\",\"type\":\"HoverTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1224\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1239\",\"type\":\"BasicTicker\"}},\"id\":\"1242\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1225\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1283\",\"type\":\"Title\"},{\"attributes\":{\"formatter\":{\"id\":\"1288\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1224\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1239\",\"type\":\"BasicTicker\"}},\"id\":\"1238\",\"type\":\"LinearAxis\"},{\"attributes\":{\"formatter\":{\"id\":\"1286\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1224\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1234\",\"type\":\"BasicTicker\"}},\"id\":\"1233\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1260\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1286\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1288\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"1227\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1229\",\"type\":\"LinearScale\"}],\"root_ids\":[\"1224\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.2\"}};\n",
       "  var render_items = [{\"docid\":\"088ba184-8ed3-44bb-bef1-f6049e0b24a2\",\"roots\":{\"1224\":\"fad1fff0-ad6d-4abe-b465-70ae726840e6\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1224"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    output_notebook()\n",
    "    \n",
    "    if isinstance(color, str): \n",
    "        color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: \n",
    "        pl.show(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_tsne_projection(word_vectors):\n",
    "    tsne = TSNE(n_components=2, verbose=100)\n",
    "    return scale(tsne.fit_transform(word_vectors))\n",
    "    \n",
    "    \n",
    "def visualize_embeddings(embeddings, index2word, word_count):\n",
    "    word_vectors = embeddings[1: word_count + 1]\n",
    "    words = index2word[1: word_count + 1]\n",
    "    \n",
    "    word_tsne = get_tsne_projection(word_vectors)\n",
    "    draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)\n",
    "    \n",
    "    \n",
    "visualize_embeddings(embeddings, index2word, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGfhLR6x8D3r"
   },
   "source": [
    "### Continuous Bag of Words (CBoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UuVr2IsaYhX"
   },
   "source": [
    "Альтернативный вариант модели:\n",
    "\n",
    "![](Images/CBOW.png \"CBOW\")\n",
    "\n",
    "Теперь по *сумме* контекстных векторов предсказывается вектор центрального слова.\n",
    "\n",
    "**Задание** Реализуйте часть функции для генерации батчей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NP5VmnnjtsXn"
   },
   "outputs": [],
   "source": [
    "def make_cbow_batchs_iter(contexts, window_size, batch_size):\n",
    "    data = np.array([context for word, context in contexts if len(context) == 2 * window_size and word != 0])\n",
    "    labels = np.array([word for word, context in contexts if len(context) == 2 * window_size and word != 0])\n",
    "        \n",
    "    batchs_count = int(math.ceil(len(data) / batch_size))\n",
    "    \n",
    "    print('Initializing batchs generator with {} batchs per epoch'.format(batchs_count))\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for i in range(batchs_count):\n",
    "            batch_begin, batch_end = i * batch_size, min((i + 1) * batch_size, len(data))\n",
    "            batch_indices = indices[batch_begin: batch_end]\n",
    "\n",
    "            batch_data, batch_labels = [], []\n",
    "            \n",
    "            for data_ind in batch_indices:\n",
    "                central_word, context = labels[data_ind], data[data_ind]\n",
    "                batch_data.extend(context)\n",
    "                batch_labels.extend([central_word]*len(context))\n",
    "            \n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing batchs generator with 36908 batchs per epoch\n"
     ]
    }
   ],
   "source": [
    "batch, labels = next(make_cbow_batchs_iter(contexts, window_size=2, batch_size=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  748,   748,   748,   748, 21272, 21272, 21272, 21272,    55,    55,\n",
       "           55,    55,    19,    19,    19,    19,   327,   327,   327,   327,\n",
       "          208,   208,   208,   208,   900,   900,   900,   900,    22,    22,\n",
       "           22,    22,  5448,  5448,  5448,  5448,    31,    31,    31,    31,\n",
       "            1,     1,     1,     1,    91,    91,    91,    91, 16348, 16348,\n",
       "        16348, 16348,    11,    11,    11,    11,     6,     6,     6,     6,\n",
       "           10,    10,    10,    10,    53,    53,    53,    53,    15,    15,\n",
       "           15,    15,   236,   236,   236,   236,    28,    28,    28,    28,\n",
       "         1639,  1639,  1639,  1639,    52,    52,    52,    52,  1292,  1292,\n",
       "         1292,  1292,  2464,  2464,  2464,  2464,   768,   768,   768,   768,\n",
       "         6307,  6307,  6307,  6307, 15439, 15439, 15439, 15439,  5323,  5323,\n",
       "         5323,  5323,   128,   128,   128,   128,    57,    57,    57,    57,\n",
       "          222,   222,   222,   222,  1100,  1100,  1100,  1100,    37,    37,\n",
       "           37,    37,     8,     8,     8,     8,    13,    13,    13,    13,\n",
       "          624,   624,   624,   624,     7,     7,     7,     7,    22,    22,\n",
       "           22,    22,  1502,  1502,  1502,  1502,     7,     7,     7,     7,\n",
       "           39,    39,    39,    39,   747,   747,   747,   747,    24,    24,\n",
       "           24,    24, 11565, 11565, 11565, 11565,     2,     2,     2,     2,\n",
       "            7,     7,     7,     7,    39,    39,    39,    39,    41,    41,\n",
       "           41,    41,    88,    88,    88,    88,  2787,  2787,  2787,  2787,\n",
       "           10,    10,    10,    10,     6,     6,     6,     6,     2,     2,\n",
       "            2,     2,     8,     8,     8,     8,   137,   137,   137,   137,\n",
       "           18,    18,    18,    18,     5,     5,     5,     5,   384,   384,\n",
       "          384,   384,   158,   158,   158,   158,    19,    19,    19,    19,\n",
       "           37,    37,    37,    37,   711,   711,   711,   711,    38,    38,\n",
       "           38,    38, 27432, 27432, 27432, 27432,     1,     1,     1,     1,\n",
       "           51,    51,    51,    51,  1404,  1404,  1404,  1404,    22,    22,\n",
       "           22,    22,     2,     2,     2,     2,    96,    96,    96,    96,\n",
       "          769,   769,   769,   769,     8,     8,     8,     8,  8716,  8716,\n",
       "         8716,  8716,     8,     8,     8,     8,     7,     7,     7,     7,\n",
       "           17,    17,    17,    17,     2,     2,     2,     2,    17,    17,\n",
       "           17,    17,    37,    37,    37,    37,   646,   646,   646,   646,\n",
       "         1037,  1037,  1037,  1037,     6,     6,     6,     6,   643,   643,\n",
       "          643,   643,     8,     8,     8,     8,   151,   151,   151,   151,\n",
       "          172,   172,   172,   172,    66,    66,    66,    66,   606,   606,\n",
       "          606,   606,    55,    55,    55,    55,     2,     2,     2,     2,\n",
       "         1590,  1590,  1590,  1590,   672,   672,   672,   672,   337,   337,\n",
       "          337,   337,    25,    25,    25,    25,  2433,  2433,  2433,  2433,\n",
       "           13,    13,    13,    13,  3912,  3912,  3912,  3912, 17873, 17873,\n",
       "        17873, 17873,   100,   100,   100,   100,    97,    97,    97,    97,\n",
       "           31,    31,    31,    31,     1,     1,     1,     1,   789,   789,\n",
       "          789,   789,    38,    38,    38,    38,     5,     5,     5,     5,\n",
       "           17,    17,    17,    17,    42,    42,    42,    42,     6,     6,\n",
       "            6,     6,     8,     8,     8,     8,     8,     8,     8,     8,\n",
       "            2,     2,     2,     2,    28,    28,    28,    28,   513,   513,\n",
       "          513,   513,    26,    26,    26,    26,     1,     1,     1,     1,\n",
       "           98,    98,    98,    98,    29,    29,    29,    29,     1,     1,\n",
       "            1,     1,     6,     6,     6,     6,    83,    83,    83,    83,\n",
       "         1597,  1597,  1597,  1597,    39,    39,    39,    39,   138,   138,\n",
       "          138,   138,   442,   442,   442,   442,    16,    16,    16,    16,\n",
       "          122,   122,   122,   122,   648,   648,   648,   648,     2,     2,\n",
       "            2,     2], device='cuda:0')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9HkY-VO61n3"
   },
   "source": [
    "Посмотрим на альтернативный вариант создания модели - им мы будем пользоваться чаще всего - отнаследоваться от `nn.Module`. Схематично её использование выглядит так:\n",
    "\n",
    "```python\n",
    "class MyNetModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyNetModel, self).__init__()\n",
    "        <initialize layers>\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        <apply layers>\n",
    "        return final_output\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mHKLbMwx4c5"
   },
   "outputs": [],
   "source": [
    "class CBoWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.embeddings(inputs)\n",
    "        x = self.out_layer(x)\n",
    "        return x\n",
    "      \n",
    "model = CBoWModel(vocab_size=len(word2index), embedding_dim=32).cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_children of CBoWModel(\n",
       "  (embeddings): Embedding(28634, 32)\n",
       "  (out_layer): Linear(in_features=32, out_features=28634, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xiIgaofEyyJ1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing batchs generator with 36908 batchs per epoch\n",
      "Step = 1000, Avg Loss = 6.8396, Time = 7.93s\n",
      "Step = 2000, Avg Loss = 6.7479, Time = 4.01s\n",
      "Step = 3000, Avg Loss = 6.7135, Time = 4.00s\n",
      "Step = 4000, Avg Loss = 6.6932, Time = 4.02s\n",
      "Step = 5000, Avg Loss = 6.6769, Time = 4.00s\n",
      "Step = 6000, Avg Loss = 6.6483, Time = 4.00s\n",
      "Step = 7000, Avg Loss = 6.6250, Time = 4.01s\n",
      "Step = 8000, Avg Loss = 6.6174, Time = 4.01s\n",
      "Step = 9000, Avg Loss = 6.6041, Time = 4.00s\n",
      "Step = 10000, Avg Loss = 6.5903, Time = 4.02s\n",
      "Step = 11000, Avg Loss = 6.5859, Time = 4.00s\n",
      "Step = 12000, Avg Loss = 6.5745, Time = 4.01s\n",
      "Step = 13000, Avg Loss = 6.5620, Time = 4.01s\n",
      "Step = 14000, Avg Loss = 6.5558, Time = 4.00s\n",
      "Step = 15000, Avg Loss = 6.5631, Time = 4.00s\n",
      "Step = 16000, Avg Loss = 6.5539, Time = 4.02s\n",
      "Step = 17000, Avg Loss = 6.5474, Time = 4.01s\n",
      "Step = 18000, Avg Loss = 6.5331, Time = 4.00s\n",
      "Step = 19000, Avg Loss = 6.5387, Time = 4.01s\n",
      "Step = 20000, Avg Loss = 6.5282, Time = 4.00s\n",
      "Step = 21000, Avg Loss = 6.5256, Time = 4.00s\n",
      "Step = 22000, Avg Loss = 6.5106, Time = 4.01s\n",
      "Step = 23000, Avg Loss = 6.5224, Time = 4.00s\n",
      "Step = 24000, Avg Loss = 6.5267, Time = 4.00s\n",
      "Step = 25000, Avg Loss = 6.5215, Time = 4.02s\n",
      "Step = 26000, Avg Loss = 6.5117, Time = 4.00s\n",
      "Step = 27000, Avg Loss = 6.4988, Time = 3.99s\n",
      "Step = 28000, Avg Loss = 6.4937, Time = 4.02s\n",
      "Step = 29000, Avg Loss = 6.5007, Time = 4.00s\n",
      "Step = 30000, Avg Loss = 6.4941, Time = 4.00s\n",
      "Step = 31000, Avg Loss = 6.4977, Time = 4.01s\n",
      "Step = 32000, Avg Loss = 6.4945, Time = 4.00s\n",
      "Step = 33000, Avg Loss = 6.4870, Time = 4.00s\n",
      "Step = 34000, Avg Loss = 6.4813, Time = 4.01s\n",
      "Step = 35000, Avg Loss = 6.4909, Time = 3.99s\n",
      "Step = 36000, Avg Loss = 6.4786, Time = 4.00s\n",
      "Step = 37000, Avg Loss = 6.4822, Time = 4.21s\n",
      "Step = 38000, Avg Loss = 6.4445, Time = 4.03s\n",
      "Step = 39000, Avg Loss = 6.4585, Time = 4.01s\n",
      "Step = 40000, Avg Loss = 6.4498, Time = 4.02s\n",
      "Step = 41000, Avg Loss = 6.4427, Time = 4.00s\n",
      "Step = 42000, Avg Loss = 6.4234, Time = 4.02s\n",
      "Step = 43000, Avg Loss = 6.4308, Time = 4.02s\n",
      "Step = 44000, Avg Loss = 6.4544, Time = 4.02s\n",
      "Step = 45000, Avg Loss = 6.4453, Time = 4.03s\n",
      "Step = 46000, Avg Loss = 6.4368, Time = 4.00s\n",
      "Step = 47000, Avg Loss = 6.4503, Time = 4.00s\n",
      "Step = 48000, Avg Loss = 6.4409, Time = 4.04s\n",
      "Step = 49000, Avg Loss = 6.4381, Time = 4.03s\n",
      "Step = 50000, Avg Loss = 6.4413, Time = 4.03s\n",
      "Step = 51000, Avg Loss = 6.4373, Time = 4.03s\n",
      "Step = 52000, Avg Loss = 6.4188, Time = 4.01s\n",
      "Step = 53000, Avg Loss = 6.4424, Time = 4.02s\n",
      "Step = 54000, Avg Loss = 6.4251, Time = 4.02s\n",
      "Step = 55000, Avg Loss = 6.4380, Time = 4.00s\n",
      "Step = 56000, Avg Loss = 6.4260, Time = 4.02s\n",
      "Step = 57000, Avg Loss = 6.4269, Time = 4.01s\n",
      "Step = 58000, Avg Loss = 6.4270, Time = 4.01s\n",
      "Step = 59000, Avg Loss = 6.4167, Time = 4.04s\n",
      "Step = 60000, Avg Loss = 6.4263, Time = 4.04s\n",
      "Step = 61000, Avg Loss = 6.4211, Time = 4.02s\n",
      "Step = 62000, Avg Loss = 6.4084, Time = 4.01s\n",
      "Step = 63000, Avg Loss = 6.4313, Time = 4.00s\n",
      "Step = 64000, Avg Loss = 6.4288, Time = 4.04s\n",
      "Step = 65000, Avg Loss = 6.4238, Time = 4.05s\n",
      "Step = 66000, Avg Loss = 6.4120, Time = 4.03s\n",
      "Step = 67000, Avg Loss = 6.4199, Time = 4.02s\n",
      "Step = 68000, Avg Loss = 6.4319, Time = 4.01s\n",
      "Step = 69000, Avg Loss = 6.4210, Time = 4.03s\n",
      "Step = 70000, Avg Loss = 6.4044, Time = 4.02s\n",
      "Step = 71000, Avg Loss = 6.4126, Time = 4.03s\n",
      "Step = 72000, Avg Loss = 6.4046, Time = 4.07s\n",
      "Step = 73000, Avg Loss = 6.4042, Time = 4.07s\n",
      "Step = 74000, Avg Loss = 6.4153, Time = 4.21s\n",
      "Step = 75000, Avg Loss = 6.3688, Time = 4.07s\n",
      "Step = 76000, Avg Loss = 6.3607, Time = 4.04s\n",
      "Step = 77000, Avg Loss = 6.3722, Time = 4.02s\n",
      "Step = 78000, Avg Loss = 6.3690, Time = 4.02s\n",
      "Step = 79000, Avg Loss = 6.3930, Time = 4.01s\n",
      "Step = 80000, Avg Loss = 6.3832, Time = 4.05s\n",
      "Step = 81000, Avg Loss = 6.3788, Time = 4.05s\n",
      "Step = 82000, Avg Loss = 6.3860, Time = 4.02s\n",
      "Step = 83000, Avg Loss = 6.3911, Time = 4.03s\n",
      "Step = 84000, Avg Loss = 6.3916, Time = 4.11s\n",
      "Step = 85000, Avg Loss = 6.3723, Time = 4.08s\n",
      "Step = 86000, Avg Loss = 6.3764, Time = 4.04s\n",
      "Step = 87000, Avg Loss = 6.3885, Time = 4.04s\n",
      "Step = 88000, Avg Loss = 6.3916, Time = 4.03s\n",
      "Step = 89000, Avg Loss = 6.3764, Time = 4.03s\n",
      "Step = 90000, Avg Loss = 6.3871, Time = 4.05s\n",
      "Step = 91000, Avg Loss = 6.3828, Time = 4.11s\n",
      "Step = 92000, Avg Loss = 6.3657, Time = 4.08s\n",
      "Step = 93000, Avg Loss = 6.3855, Time = 4.04s\n",
      "Step = 94000, Avg Loss = 6.3743, Time = 4.03s\n",
      "Step = 95000, Avg Loss = 6.3909, Time = 4.04s\n",
      "Step = 96000, Avg Loss = 6.3801, Time = 4.12s\n",
      "Step = 97000, Avg Loss = 6.3849, Time = 4.06s\n",
      "Step = 98000, Avg Loss = 6.3803, Time = 4.12s\n",
      "Step = 99000, Avg Loss = 6.3799, Time = 4.08s\n",
      "Step = 100000, Avg Loss = 6.3890, Time = 4.04s\n",
      "Step = 101000, Avg Loss = 6.3722, Time = 4.02s\n",
      "Step = 102000, Avg Loss = 6.3930, Time = 4.05s\n",
      "Step = 103000, Avg Loss = 6.3621, Time = 4.03s\n",
      "Step = 104000, Avg Loss = 6.3659, Time = 4.00s\n",
      "Step = 105000, Avg Loss = 6.3580, Time = 4.04s\n",
      "Step = 106000, Avg Loss = 6.3687, Time = 4.07s\n",
      "Step = 107000, Avg Loss = 6.3627, Time = 4.04s\n",
      "Step = 108000, Avg Loss = 6.3547, Time = 4.05s\n",
      "Step = 109000, Avg Loss = 6.3636, Time = 4.04s\n",
      "Step = 110000, Avg Loss = 6.3848, Time = 4.02s\n",
      "Step = 111000, Avg Loss = 6.3641, Time = 4.24s\n",
      "Step = 112000, Avg Loss = 6.3407, Time = 4.03s\n",
      "Step = 113000, Avg Loss = 6.3377, Time = 4.06s\n",
      "Step = 114000, Avg Loss = 6.3226, Time = 4.12s\n",
      "Step = 115000, Avg Loss = 6.3494, Time = 4.09s\n",
      "Step = 116000, Avg Loss = 6.3348, Time = 4.10s\n",
      "Step = 117000, Avg Loss = 6.3453, Time = 4.09s\n",
      "Step = 118000, Avg Loss = 6.3508, Time = 4.06s\n",
      "Step = 119000, Avg Loss = 6.3436, Time = 4.06s\n",
      "Step = 120000, Avg Loss = 6.3637, Time = 4.07s\n",
      "Step = 121000, Avg Loss = 6.3482, Time = 4.07s\n",
      "Step = 122000, Avg Loss = 6.3556, Time = 4.06s\n",
      "Step = 123000, Avg Loss = 6.3433, Time = 4.07s\n",
      "Step = 124000, Avg Loss = 6.3426, Time = 4.07s\n",
      "Step = 125000, Avg Loss = 6.3483, Time = 4.06s\n",
      "Step = 126000, Avg Loss = 6.3466, Time = 4.04s\n",
      "Step = 127000, Avg Loss = 6.3510, Time = 4.03s\n",
      "Step = 128000, Avg Loss = 6.3513, Time = 4.03s\n",
      "Step = 129000, Avg Loss = 6.3429, Time = 4.03s\n",
      "Step = 130000, Avg Loss = 6.3378, Time = 4.08s\n",
      "Step = 131000, Avg Loss = 6.3479, Time = 4.08s\n",
      "Step = 132000, Avg Loss = 6.3478, Time = 4.06s\n",
      "Step = 133000, Avg Loss = 6.3526, Time = 4.06s\n",
      "Step = 134000, Avg Loss = 6.3517, Time = 4.05s\n",
      "Step = 135000, Avg Loss = 6.3455, Time = 4.05s\n",
      "Step = 136000, Avg Loss = 6.3411, Time = 4.09s\n",
      "Step = 137000, Avg Loss = 6.3517, Time = 4.06s\n",
      "Step = 138000, Avg Loss = 6.3374, Time = 4.05s\n",
      "Step = 139000, Avg Loss = 6.3378, Time = 4.07s\n",
      "Step = 140000, Avg Loss = 6.3320, Time = 4.05s\n",
      "Step = 141000, Avg Loss = 6.3492, Time = 4.05s\n",
      "Step = 142000, Avg Loss = 6.3383, Time = 4.05s\n",
      "Step = 143000, Avg Loss = 6.3302, Time = 4.05s\n",
      "Step = 144000, Avg Loss = 6.3390, Time = 4.04s\n",
      "Step = 145000, Avg Loss = 6.3427, Time = 4.06s\n",
      "Step = 146000, Avg Loss = 6.3325, Time = 4.14s\n",
      "Step = 147000, Avg Loss = 6.3483, Time = 4.12s\n",
      "Step = 148000, Avg Loss = 6.3290, Time = 4.27s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-6f0c940c97e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mloss_every_nsteps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_every_nsteps = 1000\n",
    "total_loss = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for step, (batch, labels) in enumerate(make_cbow_batchs_iter(contexts, window_size=2, batch_size=128)):\n",
    "    batch = torch.Tensor(batch).long().cuda()\n",
    "    labels = torch.Tensor(labels).long().cuda()\n",
    "    output = model(batch)\n",
    "    \n",
    "    loss = loss_function(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    if step != 0 and step % loss_every_nsteps == 0:\n",
    "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
    "                                                                    time.time() - start_time))\n",
    "        total_loss = 0\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTEWcyYmvips"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1000 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1000 samples in 0.063s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1000\n",
      "[t-SNE] Mean sigma: 2.208509\n",
      "[t-SNE] Computed conditional probabilities in 0.038s\n",
      "[t-SNE] Iteration 50: error = 77.4725113, gradient norm = 0.3115606 (50 iterations in 2.744s)\n",
      "[t-SNE] Iteration 100: error = 78.3826065, gradient norm = 0.3003487 (50 iterations in 3.539s)\n",
      "[t-SNE] Iteration 150: error = 78.6078491, gradient norm = 0.2981708 (50 iterations in 3.719s)\n",
      "[t-SNE] Iteration 200: error = 78.5082626, gradient norm = 0.3117209 (50 iterations in 3.502s)\n",
      "[t-SNE] Iteration 250: error = 79.5092926, gradient norm = 0.2885616 (50 iterations in 3.764s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 79.509293\n",
      "[t-SNE] Iteration 300: error = 2.0193722, gradient norm = 0.0029071 (50 iterations in 2.267s)\n",
      "[t-SNE] Iteration 350: error = 1.9039630, gradient norm = 0.0009596 (50 iterations in 2.143s)\n",
      "[t-SNE] Iteration 400: error = 1.8575881, gradient norm = 0.0004319 (50 iterations in 2.180s)\n",
      "[t-SNE] Iteration 450: error = 1.8256199, gradient norm = 0.0007264 (50 iterations in 2.006s)\n",
      "[t-SNE] Iteration 500: error = 1.8056674, gradient norm = 0.0003352 (50 iterations in 2.076s)\n",
      "[t-SNE] Iteration 550: error = 1.7915881, gradient norm = 0.0002281 (50 iterations in 1.924s)\n",
      "[t-SNE] Iteration 600: error = 1.7812657, gradient norm = 0.0002443 (50 iterations in 1.985s)\n",
      "[t-SNE] Iteration 650: error = 1.7758313, gradient norm = 0.0001739 (50 iterations in 2.443s)\n",
      "[t-SNE] Iteration 700: error = 1.7708966, gradient norm = 0.0002209 (50 iterations in 2.470s)\n",
      "[t-SNE] Iteration 750: error = 1.7620553, gradient norm = 0.0002105 (50 iterations in 2.205s)\n",
      "[t-SNE] Iteration 800: error = 1.7569951, gradient norm = 0.0001724 (50 iterations in 2.163s)\n",
      "[t-SNE] Iteration 850: error = 1.7544248, gradient norm = 0.0001757 (50 iterations in 1.980s)\n",
      "[t-SNE] Iteration 900: error = 1.7525299, gradient norm = 0.0001091 (50 iterations in 1.939s)\n",
      "[t-SNE] Iteration 950: error = 1.7510453, gradient norm = 0.0000802 (50 iterations in 1.837s)\n",
      "[t-SNE] Iteration 1000: error = 1.7507833, gradient norm = 0.0000600 (50 iterations in 1.802s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.750783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:193: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1479\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1479\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1479\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1479' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1479\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1479\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1479\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1479' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1479\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"11a8a55b-c97f-491f-b566-c099b2af0c65\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"dbb3cf2a-b597-48c6-94b2-74b3dbccc7d8\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1490\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1495\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1490\",\"type\":\"LinearAxis\"},{\"id\":\"1494\",\"type\":\"Grid\"},{\"id\":\"1495\",\"type\":\"LinearAxis\"},{\"id\":\"1499\",\"type\":\"Grid\"},{\"id\":\"1508\",\"type\":\"BoxAnnotation\"},{\"id\":\"1518\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1558\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1506\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1482\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1486\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1484\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1488\",\"type\":\"LinearScale\"}},\"id\":\"1481\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1501\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"plot\":{\"id\":\"1481\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1491\",\"type\":\"BasicTicker\"}},\"id\":\"1494\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1491\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1500\",\"type\":\"PanTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1480\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1516\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1517\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1519\",\"type\":\"CDSView\"}},\"id\":\"1518\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1503\",\"type\":\"SaveTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1508\",\"type\":\"BoxAnnotation\"}},\"id\":\"1502\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1504\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1517\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1516\",\"type\":\"Scatter\"},{\"attributes\":{\"callback\":null},\"id\":\"1482\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"1561\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1481\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1491\",\"type\":\"BasicTicker\"}},\"id\":\"1490\",\"type\":\"LinearAxis\"},{\"attributes\":{\"formatter\":{\"id\":\"1563\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1481\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1496\",\"type\":\"BasicTicker\"}},\"id\":\"1495\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1561\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1481\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1496\",\"type\":\"BasicTicker\"}},\"id\":\"1499\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1520\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1484\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1558\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1486\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1496\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1501\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1500\",\"type\":\"PanTool\"},{\"id\":\"1501\",\"type\":\"WheelZoomTool\"},{\"id\":\"1502\",\"type\":\"BoxZoomTool\"},{\"id\":\"1503\",\"type\":\"SaveTool\"},{\"id\":\"1504\",\"type\":\"ResetTool\"},{\"id\":\"1505\",\"type\":\"HelpTool\"},{\"id\":\"1520\",\"type\":\"HoverTool\"}]},\"id\":\"1506\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1565\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1564\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"token\":[\"?\",\"the\",\"what\",\"is\",\"a\",\"i\",\"to\",\"in\",\"how\",\"of\",\"do\",\"are\",\"and\",\"for\",\",\",\"can\",\"you\",\"why\",\"it\",\"my\",\"does\",\"best\",\"on\",\".\",\"or\",\"have\",\"if\",\"be\",\"with\",\"which\",\"that\",\"an\",\"some\",\"should\",\"'s\",\"get\",\"from\",\")\",\"your\",\"(\",\"like\",\"when\",\"at\",\"india\",\"good\",\"who\",\"there\",\"will\",\"as\",\"would\",\"people\",\"not\",\"n't\",\"about\",\"``\",\"''\",\"between\",\"one\",\"did\",\"any\",\"we\",\"me\",\"where\",\"most\",\"was\",\"by\",\"make\",\"so\",\"they\",\"this\",\"am\",\"after\",\"way\",\":\",\"has\",\"use\",\"much\",\"difference\",\"time\",\"life\",\"their\",\"know\",\"work\",\"many\",\"but\",\"than\",\"more\",\"all\",\"want\",\"quora\",\"someone\",\"learn\",\"find\",\"other\",\"think\",\"new\",\"better\",\"job\",\"indian\",\"out\",\"money\",\"mean\",\"become\",\"ever\",\"world\",\"without\",\"he\",\"start\",\"take\",\"us\",\"up\",\"first\",\"feel\",\"year\",\"into\",\"go\",\"online\",\"used\",\"engineering\",\"could\",\"love\",\"'m\",\"person\",\"were\",\"possible\",\"day\",\"buy\",\"things\",\"being\",\"need\",\"business\",\"using\",\"them\",\"really\",\"trump\",\"girl\",\"'\",\"her\",\"his\",\"years\",\"different\",\"long\",\"phone\",\"google\",\"company\",\"been\",\"old\",\"only\",\"no\",\"now\",\"just\",\"2\",\"app\",\"college\",\"facebook\",\"number\",\"free\",\"books\",\"2016\",\"movie\",\"still\",\"its\",\"account\",\"ca\",\"women\",\"book\",\"english\",\"while\",\"she\",\"had\",\"change\",\"ways\",\"computer\",\"thing\",\"examples\",\"data\",\"country\",\"over\",\"see\",\"android\",\"help\",\"science\",\"live\",\"school\",\"software\",\"before\",\"&\",\"language\",\"same\",\"going\",\"bad\",\"sex\",\"student\",\"stop\",\"university\",\"happen\",\"back\",\"made\",\"3\",\"1\",\"study\",\"our\",\"two\",\"through\",\"system\",\"name\",\"say\",\"real\",\"during\",\"prepare\",\"water\",\"iphone\",\"website\",\"top\",\"car\",\"questions\",\"important\",\"men\",\"give\",\"getting\",\"anyone\",\"companies\",\"high\",\"black\",\"card\",\"read\",\"programming\",\"war\",\"learning\",\"10\",\"5\",\"\\u2019\",\"exam\",\"[\",\"then\",\"]\",\"even\",\"movies\",\"china\",\"mobile\",\"cost\",\"donald\",\"right\",\"doing\",\"friend\",\"him\",\"working\",\"under\",\"come\",\"president\",\"own\",\"question\",\"career\",\"experience\",\"bank\",\"true\",\"friends\",\"guy\",\"word\",\"hair\",\"home\",\"video\",\"having\",\"look\",\"usa\",\"tell\",\"man\",\"social\",\"web\",\"interview\",\"very\",\"engineer\",\"write\",\"game\",\"government\",\"weight\",\"earth\",\"girls\",\"service\",\"food\",\"students\",\"play\",\"countries\",\"human\",\"place\",\"future\",\"improve\",\"off\",\"big\",\"days\",\"happens\",\"'ve\",\"done\",\"class\",\"eat\",\"tv\",\"process\",\"got\",\"state\",\"average\",\"s\",\"meaning\",\"relationship\",\"music\",\"too\",\"math\",\"create\",\"instagram\",\"every\",\"history\",\"last\",\"pay\",\"windows\",\"4\",\"white\",\"watch\",\"%\",\"salary\",\"body\",\"power\",\"safe\",\"clinton\",\"ask\",\"age\",\"laptop\",\"makes\",\"$\",\"each\",\"hard\",\"lose\",\"american\",\"delhi\",\"youtube\",\"energy\",\"worth\",\"earn\",\"states\",\"against\",\"win\",\"girlfriend\",\"great\",\"keep\",\"test\",\"god\",\"hillary\",\"compare\",\"market\",\"differences\",\"making\",\"considered\",\"something\",\"answer\",\"apply\",\"myself\",\"mba\",\"tips\",\"around\",\"never\",\"next\",\"always\",\"mechanical\",\"another\",\"united\",\"java\",\"increase\",\"c\",\"such\",\"course\",\"jobs\",\"download\",\"song\",\"parents\",\"kind\",\"internet\",\"common\",\"review\",\"woman\",\"code\",\"design\",\"per\",\"employees\",\"end\",\"development\",\"chinese\",\"series\",\"score\",\"interesting\",\"degree\",\"month\",\"travel\",\"show\",\"management\",\"months\",\"able\",\"believe\",\"open\",\"program\",\"living\",\"looking\",\"because\",\"6\",\"type\",\"bangalore\",\"light\",\"favorite\",\"america\",\"today\",\"actually\",\"major\",\"family\",\"marketing\",\"pakistan\",\"universities\",\"technology\",\"law\",\"call\",\"affect\",\"whatsapp\",\"idea\",\"{\",\"build\",\"}\",\"choose\",\"cat\",\"current\",\"support\",\"problem\",\"popular\",\"speed\",\"air\",\"rid\",\"deal\",\"visa\",\"join\",\"run\",\"games\",\"space\",\"down\",\"both\",\"well\",\"city\",\"2017\",\"house\",\"exist\",\"services\",\"available\",\"civil\",\"u.s.\",\"site\",\"culture\",\"also\",\"normal\",\"given\",\"wrong\",\"apple\",\"7\",\"small\",\"order\",\"date\",\"wear\",\"apps\",\"places\",\"songs\",\"differ\",\"project\",\"product\",\"international\",\"x\",\"behind\",\"main\",\"research\",\"happened\",\"boyfriend\",\"media\",\"public\",\"canada\",\"value\",\"jee\",\"cause\",\"reason\",\"uk\",\"education\",\"email\",\"ms\",\"sleep\",\"-\",\"amazon\",\"instead\",\"these\",\"benefits\",\"startup\",\"less\",\"iit\",\"part\",\"list\",\"based\",\"die\",\"medical\",\"websites\",\"etc\",\"physics\",\"skills\",\"child\",\"form\",\"health\",\"causes\",\"called\",\"times\",\"visit\",\"hate\",\"level\",\"worst\",\"police\",\"legal\",\"control\",\"terms\",\"stay\",\"products\",\"mumbai\",\"post\",\"facts\",\"mind\",\"face\",\"application\",\"rate\",\"sites\",\"field\",\"file\",\"required\",\"humans\",\"sell\",\"seen\",\"story\",\"machine\",\"private\",\"dog\",\"notes\",\"stock\",\"modi\",\"biggest\",\"asked\",\"invest\",\"children\",\"point\",\"writing\",\"move\",\"night\",\"problems\",\"gate\",\"put\",\"'re\",\"successful\",\"single\",\"anything\",\"indians\",\"others\",\"remove\",\"compared\",\"theory\",\"death\",\"ideas\",\"talk\",\"marks\",\"answers\",\"plan\",\"similar\",\"sentence\",\"low\",\"group\",\"institute\",\"side\",\"hours\",\"again\",\"effects\",\"/math\",\"coaching\",\"australia\",\"solve\",\"advantages\",\"correct\",\"function\",\"tax\",\"lot\",\"center\",\"famous\",\"send\",\"germany\",\"guys\",\"add\",\"set\",\"offer\",\"south\",\"force\",\"credit\",\"foreign\",\"universe\",\"information\",\"fall\",\"period\",\"daily\",\"says\",\"developer\",\"training\",\"full\",\"videos\",\"area\",\"industry\",\"oil\",\"model\",\"general\",\"studying\",\"majors\",\"star\",\"colleges\",\"graduate\",\"size\",\"yourself\",\"drive\",\"python\",\"2015\",\"blood\",\"near\",\"search\",\"enough\",\"price\",\"kill\",\"quality\",\"words\",\"8\",\"cons\",\"marriage\",\"found\",\"often\",\"\\u201d\",\"leave\",\"pros\",\"fast\",\"grow\",\"courses\",\"started\",\"week\",\"fix\",\"related\",\"purpose\",\"network\",\"types\",\"russia\",\"advice\",\"those\",\"password\",\"follow\",\"taking\",\"married\",\"mass\",\"male\",\"store\",\"turn\",\"party\",\"left\",\"brain\",\"rs\",\"\\u201c\",\"numbers\",\"100\",\"500\",\"female\",\"share\",\"digital\",\"team\",\"1000\",\"effective\",\"economy\",\"term\",\"text\",\"delete\",\"election\",\"cell\",\"pc\",\"master\",\"office\",\"matter\",\"few\",\"role\",\"since\",\"preparation\",\"fat\",\"second\",\"page\",\"dark\",\"short\",\"said\",\"happy\",\"red\",\"line\",\"away\",\"security\",\"options\",\"easy\",\"effect\",\"three\",\"view\",\"admission\",\"must\",\"chemical\",\"source\",\"lost\",\"try\",\"dream\",\"understand\",\"care\",\"exams\",\"convert\",\"americans\",\"past\",\"electrical\",\"dogs\",\"profile\",\"alcohol\",\"exactly\",\"north\",\"ios\",\"develop\",\"paper\",\"japanese\",\"investment\",\"tech\",\"difficult\",\"hotel\",\"check\",\"beautiful\",\"personal\",\"calculate\",\"japan\",\"uber\",\"letter\",\"eating\",\"religion\",\"20\",\"explain\",\"languages\",\"c++\",\"b\",\"hyderabad\",\"topics\",\"british\",\"twitter\",\"basic\",\"news\",\"california\",\"self\",\"green\",\"political\",\"transfer\",\"wife\",\"12\",\"fight\",\"rank\",\"drug\",\"let\",\"porn\",\"film\",\"scope\",\"t\",\"army\",\"pune\",\"national\",\"once\",\"contact\",\"note\",\"known\",\"avoid\",\"boy\",\"gain\",\"please\",\"address\",\"wants\",\"reasons\",\"paid\",\"obama\",\"engine\",\"europe\",\"ex\",\"currently\",\"bollywood\",\"samsung\",\"smart\",\"everyone\",\"season\",\"phd\",\"income\",\"officer\",\"chances\",\"reduce\",\"option\",\"overcome\",\"everything\",\"across\",\"reading\",\"military\",\"else\",\"users\",\"meet\",\"15\",\"solar\",\"message\",\"charge\",\"knowledge\",\"due\",\"sound\",\"balance\",\"microsoft\",\"!\",\"internship\",\"faster\",\"photos\",\"pregnant\",\"sim\",\"yes\",\"moon\",\"taken\",\"financial\",\"hindi\",\"disadvantages\",\"pass\",\"animals\",\"messages\",\"gay\",\"/\",\"hack\",\"healthy\",\"pain\",\"systems\",\"amount\",\"color\",\"interested\",\"singapore\",\"ias\",\"natural\",\"skin\",\"screen\",\"chance\",\"names\",\"special\",\"height\",\"board\",\"case\",\"structure\",\"passport\",\"break\",\"pro\",\"created\",\"professional\",\"drink\",\"already\",\"percentage\",\"useful\",\"french\",\"crush\",\"sun\",\"dating\",\"likes\",\"presidential\",\"battery\",\"interest\",\"access\",\"coming\",\"provide\",\"muslim\",\"starting\",\"modern\",\"linux\",\"recover\",\"camera\",\"german\",\"expect\",\"vote\",\"muslims\",\"blue\",\"least\",\"install\",\"train\",\"studies\",\"solution\",\"thinking\",\"following\",\"negative\",\"mother\",\"jio\",\"mac\",\"user\",\"spend\",\"prime\",\"written\",\"buying\",\"feeling\",\"running\",\"football\",\"gift\",\"cold\",\"changed\",\"pressure\",\"allowed\",\"character\",\"brand\",\"rich\",\"snapchat\",\"resources\",\"within\",\"speak\",\"impact\",\"islam\",\"yet\",\"non\",\"marry\",\"eyes\",\"society\",\"bill\",\"likely\",\"though\",\"determine\",\"shows\",\"fake\",\"save\",\"capital\",\"final\",\"gmail\",\"picture\",\"laws\",\"middle\",\"applications\",\"nuclear\",\"chemistry\",\"young\",\"kids\",\"prefer\",\"device\",\"iq\",\"father\",\"views\",\"galaxy\",\"manager\",\"doctor\",\"personality\",\"hand\",\"greatest\",\"currency\",\"inside\",\"illegal\",\"stories\",\"strategy\",\"recruit\",\"pursue\",\"cs\",\"abroad\",\"gold\",\"projects\",\"consider\",\"works\",\"blog\",\"crack\",\"memory\",\"example\",\"neet\",\"growth\",\"schools\",\"necessary\",\"husband\",\"insurance\",\"alone\",\"economics\",\"depression\",\"higher\",\"dead\",\"b.tech\",\"30\",\"cse\",\"loss\",\"among\",\"files\",\"deleted\",\"easiest\",\"macbook\",\"together\",\"art\",\"wifi\",\"vs\",\"gas\",\"suggest\",\"late\",\"intelligence\",\"method\",\"gre\",\"head\",\"minimum\",\"version\",\"tools\",\"easily\",\"chennai\",\"cars\",\"suitable\"],\"x\":{\"__ndarray__\":\"o4m8PpAiE7/Ep0W+QOoMPyHTLL/ricK/o9UtPiltAD4Zy1C+2jSbPpL24b3NpxI/0kHxPvxiuz4m9PU+DkBlvsDovL8WW1i+qf3TvtmKNL9KLqm8FKOCP6NEMT06KgM/ty7MPkF8gz0EUoA+Kux4PlmQKj8Hsiq+h92SPjhCPL94NJY/PfeAvjovCT8+Hy4/v4gMPiTqOD/4hDq/4J4NPyJbf75Tq4I+T7O9PaV+07+N+hy/twElvvM4OjssdiG+RVW0v+dfDL7gwVy/7AGnPmm98T9L3ig/F95aP5X9DD5vXCc/uNAiPxTXnb0t2g2/dVm+v/7KPb+LyUy+C1C4PtU+Cj8i4Co+8/b7Po8LWD+CR7i/1YT7vq3MsT82fXg+rMywP2akFj9mSRM+5kmdPqv0dT9whec/BUaLPw41Jb5qASS/x3KGPpjVBz+/nd0/OgXSPsM0xT9IZbs/uPcGPyeqxj8bQli9Hncpv4D8SL/bkyU/04osP+aiMj/hWja/kC53vtoToL+8zYy/tmbCPlvmzj+b/Ug//9wlPyeqgr3jiau/ou0RP9MGe78Glww/aCl6P9lW0L9TDLA+ioeKP4FbsD+FiuS/k4ZWPmunNz64a5C+gihQP2EAyb8KTzq+80wzvizIsT+U1Yy/ZagHPyHznz+SVvY/pGzhPkDpI78DrSQ/QAnGPzbAS7/Vg/Y+WF8bv8r3cj4vmNy/UVaTv9sIMD8MMTq/5Vgyvwx6DkDw5io//4Z4P/dDnL7Tpr291uA7vyf0cr01eOG+JFYSP07YCr+r9LQ+vF7APr26iD8gXt2+VDG/v8DW1zxZh6c//q+JvhZkEb9EGBPA+LEvv2Z7oT6NZhW/5x2SPSmCSL1YpF6/zusMvyW0WL+XDJQ+qGp7v/L5fD2+2bk+DMawP624p781lA+/ggumP7/Wer/Wrpu/NvV3PmpytD7qmne+2SQOP+Knr78Tbyk+mma5v7otaL/fdYQ+Pjb8PjE9mL94Y5Q/4eWsPxoPHT9YT42+zpTJv9qfKz+V3LG/rPe4PibHvz7ZHAI+yAqLP74AhT+rj/C/GlEhv/YwNz/sWa09q0sWQHYa8r3oDVM+3p+Mv8HZGT55C/y/WoSEP71gBr5mAfC+qoKTPwuHlL7CbxK+ytGBPzv9Xr+Nzq69hrAyP80woL5Q3Cm/4GqvvkmEj755ih+/OSMUvnD2bb9cL62/Ey+rvwlPmz+AspE/fh/QPmoWCMDkyl0/Wfj9PrVoZD+7Qwc/j3Aov25yub9cqnO+4PCBP/Bs3L8ISpU/BsnDv521jr8ESzy/HdD8Pl9rLD84j3Y/6bPfvyKSaj9wHu+90ASfv5EZs75jdx+/T1o/Pkiau75ez5G/54CtPXE0ST9bdzI9OpCCvmHXIj9Sxg0/3CTQv0bggz4B/46/ePEqvsJ8Wb9ZG8O/y5hDP1bYx7/0NkS+tj9Jv/muxb+yVfk/ZoOIP6xJaL+IlIC/yYOxviM1zb/1xZc+GyGPv02rhz8RCHG/wpeUvz5rCb9lSd8+7moRP9rwDkD9mNI+YIYGPMUb1btezwLAqIdDPxT2pr4TAlq/HMr1vM76mb9+Ut0/vmoKP39UqT829cc/rn+cviJtSj/esHg/9kINP0ofVj1A9SI/vU51vywPQz8ZXCM+4U+lvlotkT+ubqW+DQmYPl25EcDCSNM/G8iRP1iNsD+MRac/PN3cvzfxHL7AbOM/YsQ5vSadkz4mSZI/zn87vxwMpT/+4FQ/V5WKv9b23b8S1oG+RAa8P1iQBD8gKAs/XhiePzy7hL8nZ6c+2NuHv1SsG7+9e+0+WyqRv+aXa76xV9y/B6YHQD+X9T5Chuc/0FfQPqrqSD+4uN++CyvOvdLo8r8fICS/I1rUvyzsBb9iWiI/GBJWuSQzSD888o0+EXTkv5owL7/9/se/qlxdv9GePz9edWS/hlO1v+C0lr9YnM09LLKiPs83ej2AOXa/0eqcP+JmCb6dVoY/5QrWP0rxjb+PtO++DXRgv/2yeD+3Q1W+zlaDPwJqZL+aoHa/zgWZvUXJDMACm24/QYqtv4Lg+j8w6a0+vJ3pPOFOj79a0Q9AhCm2P++7AD8UE6c+R72fvzoIxb7YHwM/oL0gP+UWlj91SqM/fovYvz+Crz8Fd9U/jFiwv7DXIT5h9lg+jKCQv42COb6qkmu/2pK6v8uipL9Q0mW/hUiiv9+OZD5lnc0/IF/OPTmtCb8oRYM/WlQHP2iegj/Nq6M8UYYFwDWczz5FdMQ+MDW/P3SEH786ULU/qcv8P3lejj66CTG+2n/yv4u8JjwHvMg+XgjJviRzhj+Kg8k+Sw7oPijBtL9Kf3e+ZOgQwLMvVj49BwE/ReKAv02QXz9/9ei/68HPvzbw774Jc3q/FGPbPrHjUj9pFuo9DHDlvkLvGb6IVpo/IIojv/0LrL9hv0A+QzP8u/QJ3r7g93G/oDwjvwluBkDPdWK/3/RGv95+yr9n+1w/AzLiPig4Cb8sMGq/HAhbPYRGhL/ceDi/276Nv5A9y78Qxb8/wtsLwDScmj+AcWQ/X4XQvwvWn78tlyo+W8LUv/sAHD9zwDY/9q8yvhL+oT8gYfy+vkHaP5zcRr8Jsbs/Dcrpv9/ilD/E7NG9AuwTv5Iuxj6wfMW/x3PkvhR87j4mTLe/YjAav7W8fr6ePZI/o2esvy0Doj/DjHc+EGsIQNFZcz5+6mS/gengP2ZWuz/bFZa/WkeEPyTG0T5OgOG/dpCHPgg22L4ba9i/AouSPmHDOb8/9ni9sP2lPuMbQr/p0Nc/GivkvnlizT+4JLY+dg+YP85XNb8YLOU+7sC9vZYGAb+stke/E3CSvyRNZzyOywy/Lnc+v2ZKA7/tTbU/BvRDvtRm3z7zNvk+emCdP3iPxr0qnrM+cC/oP/7CwD+2XwXAXnLVPihd8z7zlvS+498SP5NZ4L40fmi/Cmogv075JT8+I2o//lKtP0KxSr/JO0C/IlEMPkGpEMA7lLy9vTQPvwzCcD+8c7s/gMY6PzKIhL4Lce2/k8TJP1GZCEAHx8M+gSvUP4HDeT982fG/DabKv5y0ij5yu729WkNTPx33qz8RQqM+cGeMPxr4ar9+Lx+/sWrdPg7mwr9dymm/srHSPvQfdT9er5K/ZcaxvwEMkT8NRFQ/K+rSv7+5qr+L0Wy/Dsj5vMlvaD+Yguw8vsVlPa9abb/+iVq/7tN3Pk6YgL4mDMo/XlVqv4orrj/a/Dy/jHG9v2NOvr9L1O2/Q2csv2mSo7/vUsa/y8q9P4M6Ir+Wqis/BLpav0p2EsB1B6U/8qtLv0iuYz41Dpo/DHXEPxfylT7ZjBO/Y1EWv4HSlT+Af4a9bTKFvpAhMT6+k6I+0XdvP/JIFj71ciq+pbFgP7MEGD/kbZO/X2tRPlZf+j+omgk/ztiAP6ysqz/bgSq/NxCuPyjCt78+rQO/ywpCvzrVyj3CaLI+v1otP+KDKD6EILc/fXf+vp3CLz5/oRg/nAOSvzu3Mz/nP5I/HlH1vl/7ZD8NPok9xkaQP5x2BL9h8vm+iJ+cPp8tKr8rokq/fKz/vo/rjD9HqqO/Tx6HPyFJJz4Gzho/6/3bv0O3bL6ccvu8JZqpv0pcLT70D7k/SXdMP6kcnT+Nnt4+/ssIwE47+T96jTc+RiYAvQjfvj89gjA/pMV/PYjupb7wXGg/FrMPPweX3j5zJTm/Ky6Cv86ElT8KtsE/IiM+P90xaz7LQM2/+rKGvp/mBUCU058/c/nqPlrPqr7kZXG+A6moPrtlAD+PtQfATwD5PpqSY78RCVQ/qNPkvwTCPr+COrS8AKg0v9WNGz/I57G/hJOLvvEzCz9bSD6/oHZzv/4GMr8foF2/i3+cP4PMiL/ddm0+rUEdvzo5470GmA5ARa28v6hDbT9jAR6+ZihHP+rDL77t5I4/N8egPhk6mL8htmC/eMhGP1T+078gRju/TBqBvwxC7jrKivy+aAeovgTQ07+3lEK9M5hjP5Nbkb/qJwU/zT50vwT2B8DbKq2/fGcLwElsqb8f9aY/yqGGv0EVO79Whs4/UiALP69Bmb+p49i/eaCYv8098T5a4AU+By1PP1o0fz8Dxys/SCSZv/PJUz+1lJS+RuuZPzRF1D8nZ2Q/K8vrPTqK2b/OwSM/2JTLvyStd78Ax7c+Xls6v+pCbL47UIU9Elv7vo+BmT83ycK/oQDVP0lvmr9lGOE/pWhDP11TIr+ji9I/bwP5vjMk2b7B0qG9ptaYv9aVxL4QuNO95+G8PUixkD/+3TC//opNPp8kiD7MWCO/Mw2SP3oPHD8iIaQ/u9sgvjq2LD9fEMm/wMGzP+iIMj7+2yQ+1lr1vvVrDT+oSYg/KSSZPVvof79Fg1W/50mWvUIqQz/Wy0O/cwdpPhM6v748Xgc/5zNwPqCLbD+BVbQ+qEwWQHqPxj/kYKU/qLnSvzmrzL/BeQPA+s/mviEESD/Czem8K6XkP9BL076CJ8O/dTC+P3UaBsA3Phi+CJnaPy1K9z9I4Xs/PQr/P+4bEj45mPm+SXdDP0ClM7s5+cs/0lmEP4S5Z7+vzYy/3+yHP5dpMr6ALSS8apjdv0+kHrx0jcY+WcFFPuZOeD/+bvA91p3UvhbRyj7XAwu/FvnavriuJT97Yba9PyRuv28kSD5XH8e/FCNxvwmdaD/qGcg9hKjAPmCD+T4Uara/rUTgvqMywj9zfgw/RvTGP+aCeb9V3/a+3rCyvql2Sb3qXAQ/512bPkssFb6v0tc+tLbDP75N5j5580S/wB1WvmiLeT+Wm+I9yqikP5cwsT/IaRK/ZgSZvj60tL6eYqU95K3pvlTkND+YRH2/VejBP7ZJeL9rI7w+kir8vgObrz3uGH8/+PScvwy0nT92DJU/i3wIP46wDkDQLB+95VkxPde/5j6MKeI/8F+Dv3IQpD1/lKm8xZKgv1Qoqb8656s/c0+RP+A+uL/aVee+F/jFviSQhLyvuqK+dynxP2gQab97nnU/trplvtvEUL/vDIC+GdGwviVtUj7Zbrc/jAwNv37bOj/SQqY/Tp8Ev5LlHb8V79I+rWegv03E1L8hH9W/HM1/Pzx7XL/h3co9MYkMPw5Vy77m8wTABcbrPt928T8+WwjAYcTDP6aZor81G6E/MaSAv+HTg7/Noac+DRO3v8Xsxz/dKzc/SBsSP+jKyL+EyIw/XSHkv0FzzD/dcDC/UjZwPleYkD5KjIQ/dxUBQJGW0T4qmia/ghq+vWTV/D6FbrU/ru6RvYi+1j4cYsU/3rXfvnjXBMDngX4+GDrVPy56sT9gyO++lkAHP/2O0r/vXfu+o02Ovw==\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"Ew2Qv83lyr8R28m/UInavwDB3L8m+LG/T9lJv1ey574VHtK/DkA4vireDcACGu6/40WTv2vIHL6QlYe/BVcHwJl1rr9Qs9q/eWKBv7+hwr9muQnAfUCbP3yTnL5Y0Yy/pgeLvynrp79v3De/U184P2dvsb4j/L2/nblpv51+4L+v/eo+Wd8FwKpq1796ToQ/mU4Nv/DAob/ozcS/OLWjv9lszD4moiq/hdvUvvG/Fj0GJV8+BfK3vxQqb78V4wXAVO7SPzTNBcCcgkS/4W9Mv6bbhT9tesQ/nPDZv+nX47+mmMa/Go0+v/5XDMDouea/Nmmwv++sqL+II9C/hCSqv4sH3L9V6CC/bRBHP4ob/z2hb7C/3EqyvxiKBsBLlP++7avwP5+Dkb+jTaq/TYiDP/Lg6T4dOJC/JbSSPhPDyL5d6bq/fKzWv4cg7j4sVFY/xeJ0v8ArYz+ddF0/HcQqv9jhrz9yhYI/n2+kv1lQmj42wYc/SNznP9B/br/1F+S+cV3gPsqqmz8dq4m+fbW5vlFaij8wCNS/nJeOPx/xmr9laSe/XBCrviGKwL9GXpY/rUgXP7Rfcr4nGMG+yIxJP3WNO78bfcE/RrjVvhiaAz/8+JI/DaSEv1n+YT9NmAbAOYsRv+iJBsCXnmy/hhXsvw+ztj+KlBk/0VyOP/3mD793yk2+KEawPznZgD+mW2O9mvaDv4efVb/6sCK/WJGCv9vesL+f0bK/EQu7v5VKLD8Jwd4/+8INP+4e1D+JAbo/itqJP3vQjr9itT6+f0MtvxA+57/tYja/3c5Jv8gfhL+qa7Q/ZS4iP4t9vD+XGw+/vSmWP57dGb8C3S0/o2Zuvh+PVL+8c8S/Oj2hPxXSD8B/51W/GRMev/5N2L5v4gy/+nzAv/jBpr8JKQk/MLjwP6ZQPz9P4Tq/NEwFPwDXVD9yoim/3linvnEvRD9BeOk/nI3gvkzPWj+i5yE/DowmP67AIj/ljAy/dZ+Yv0eH8r/6+mw/df+WP3P/lL2tQxK/h/s3P25Ypj/YExU/8sj8vxKr8b6aXYS/SxWCv3fwhb9/VwU/Pf7Dv5l2Q78ytwu/vREUvhVJYb5DrN+/NGKSP1SF6b6FMQ0/9jytvL2h7j8G1Kc/HO8iPxzQPT9GRGs/37TPPz+gWb+VdVS/FZxOvhDEp7+25I0/rtKPPjO4rzzj2tg/m6J3v7Ip8D5KCv6+YRTMv4UWar8yeXS/lGLdv9JmIT83zbG/GcGBv7mXp79m3VK/RbOhvuidD761VuI/8MkhP1/oNb9U94k//O3KPgvdp78IVKq/mPgEvm4q/L4GVhO/hpDavhzedT+Vfm4/ejaaP0YYpL557NE/H+2av8wtCL9huIK/sBnrv6HLoz4m8bg9GtikP2EgJb6pPfE+KxYpvs5qzL/0x3K//r2BPoxppz+cDZI/YtMMPgiidz8OQkS/h8BDvDxCvL7VVH4+CagAwPvSUb8sNbU/WTUhPwmvJT+tyow/A1IRv0+s9b1AwVY+KJazPrczGT94hr++vGNFPYmuJT9xk/K/5Nepv+Bvh7+7/qY+tssBPz5dcD92FNg/7hbrvlIuj70OQSU+c424v6cSlj6Dsoi/WJeCP9svED7NNrW/oJyHP6mLvD9/2ie/79OSvDf9Jr/l6VY/us7uP2lsg78UwA48LOWTP/ho5T57ZGw+zVI5vbFOjrwO3r8/1n8fv5bCUL/w5tg+VoP3Px4Mm7+VdDO/hMp7v0WqyD+nnzA/ZZuHvtk0JT4i7oc/a1hlvVrvjr5vQ00/alncvwEaB77udAHA3Dyiv4x0OD7Ymjc/nGBAP03pj7/hMzq/2Oe7vlvPxz6YPZC/Rm7FPPILhL+JG42/Xit3P6jeBj+t5ZG/3NRIP4k6vT/x1Ae/w46Xv7k8Gb+9zFC/xEBoPxwV3L/fOoi+LyvoPk1ZST9/sMs+ynDVP/UIND8eEqI+aCyXP8+O7b8YB5O/Dm3VPmAa3D/2f8k/Y5O6v6pQe7/6Jf4+OvGUP4FyCT7EjR4/kNrkvt1Xnz9fUJW+6wDNPqZ8Aj8+4tc/hTE7P8W8Hz8Hyy4/p4DqPrt19T6NGyU/B46xPxA1BsA0YW8/W8U+P9cDFD66bDa+3fBlv81bgb8h7cM+2LcsPgKmBT5K6bq/4z0NvnD0Yb/CtF+/q1NPPs6L+L5nhIY/STQuvqknFz81HV0/sr+ePu3PuT5xV4++JWS8P7mSVz9+2qe/NqCHP/yMp79ONTo/rtpaPyqikT5uHeo++A34vlVtTD1yDzw+digiv37JjL74FSO/tf7IvS2nQT9FgjM/KQ2WP29hqj3hBcy+PeAvv4Jx0z90/y0/dggsPwaiCj5AMgbA+B61PzZWwj8avXA/oCuRvh/2oz+xsNM/gjRmv4nCPL2BMIi/PfOXvyvJtT/gtnq/h8KZP2S4ZT1YROU86RAQP79Dtz8xK08+asKnvipZ0r6rIEI/74aHP5ybCj+zW6q/b5HIv+frwz6fkkg/DtO5vxhLor+txbc/T4CNP7I0qT2gAgE+EKZbP41bvzwU+wBA8RoCvrCk2T4Ab84/GTpRP4Ux2z4EW6C/Ia68P51nuD4uXL+/4BzQvunLgT9Bbl0/bNU2P82Hnr75nt+9kXWMPyim6r8iCxw/F6mZP5LAd789A1w/amQYP4777r5wUHo+i1GvP/nOj71r75W/OJcWP34cHD8Prkq+zNWLPbwBwb9QB+w/0Jm7P12lGT9jF6+6PGgcPxXivz83aAw+GS7vPmyJG78pOD4+WDkCPuIokz9hsYg+LzebP+GkIT9rO3c/dzasP8jjX78a/oQ/xUuYv3h13b721Oc+qDl5P26MGL3hDB7Am05lP/Ernr9Gg8K/f6dtv+D1nT+yF8k//nXWPZe9JT1z+zE/WbPvPuVb7b539GQ/9046P8eN8b9lS9E91TWMPa3KkL9MHy+/CFN9v13BVj+2Naw/MvbTvh8Dk7/gQDU/UBz4PugB7j7oQYE/8RN1P9E9rz8FIZS/XBgxvMifRD4y2Jg/Ftobv8mWGD/9yRW//MvKvmtpsr89hpU/N53XPDqJu7/2CSzAUpTfv+I+m76MM6U+7keovgCnXT1vrjY9/+NnP3ycyzyuIVS/NFNtPxfQ576uXnY/14qJvnmYCj4qvpE/X+bjPhg6O79+pFc/7IEhvyL9Sb8DVTc93ZrKv5cinz+f8W8/voq1vV+rpT8+6Bw9UzrQPxlDyL0/JZ8/VsoPPxdX3j6yZ9A9vjGsvQ92DT+PATU/sVQ+PtjzkL+JjCA/wobgPkNcLT/bbv+9edsRPhbLhz+xx6c/9KC8PYnv57/Zxjw/rJ7gvhIyer91tizAGh2wvhUrgb8ZsX6/xXHYvw3tLD+4RyrAVxrIvAGfDD8GQjA/QzagvofSHj8Cwng/0+asP93yl77mwq0/Wn3XPg6qD77wjiK/86xwvyye0j9BDFU/re8nvh4jjb60seE8P90EvmBYkz9qwTM/DpRJvdjrLr9j73+9QjsjwM7a2L9F1ju/g6pCv3hZIMC1Qd29IDj4PnMdfj8iGsW9jYkhwBUwxz8jKbO+1I2gPsyhuT8cAGc/AaGkvqEd2j+Q0/c/McvDPj6/Bz5LBR6+VsZPv8c6p76M8VK/LpMsPzivfT6WlPq9/wWjP2rvZb6zG/o9IsTIv530Ab75xVC+zrEIPin1Ab91ebc/cK03PzK+uj+by66+pG9Ev1oujz5v/Ig/BHL4v63ymDxHX0Q/idlDvx5ZXL99mfC+bfC/v0FvsT9vdR0/Hz9zP/xANL9XqzC/DVRqP220Tb9+o6E/VRLLPu2aiL9jp4m+ggDoP/Ddij/k6xw/AL+ivj6sWj8PBn0/jYDCP7arbD0i4HA/0GG+uqRiND7CfYE+/k9ivS82kD6DR+u9I5Qkvpeym77VaFa/5ejEv0uV8r+vVd0+Fpmav6ESbT5yXSE/ovlxvrMRuD+ytdM+MG6CP2UZVL1CRHw95A2HvrLSTz6CHF0/AhSev763kz4JXfm+n24JP/35fT9hMIg/vWw9v8YigL6NthY/wDC7v3+0cL7rfUE+M5gAvkXGFb+My4Y/hXD0vpzn2j9Tk6Y/08V8v4ctMT/NUqm/fOkIv4aVpz8bzgBA74eWPopN777Le5w+6gpVvDXYp7/Rvy2/n2uZvixz+D/DtB2++Y6Gv5RukL+VEj4/sDicPtwXvz8+EeO+5yhFP3eTWj+xxk6/98+Nv8GER789DOs8ZRAkvtyim785aYg/uXEFP9CzXb8YjEw/QLXBP4uyXz/DpRc/1SaOPwUnuz2SbkC+6Iu1PxT8nL+gBok/6TJWP9N2sT8oaYW+Z/wCQCYyf78zc/+/ZlGEv6VXcD/GQNa+C4AswI8oXT9LZVu/00zBP/Jglr39aKm/Tx53P1DBjL2dkRQ+VL4TvreuFj7kpL285zOqP0J4eT2bBG4/NJS6Pkkwoz5Fauk/arkBv8m1sb7yH22/mQaIPtERoz6u7IG+tMzSu0HahL5jJey+zgUvv3vZi7+jlgU+MR0CP2ofkL93HUQ+4CbFPwz+ub5C2p2/0bT9v+HkAD4cydC/cbuzvmqY5j+q6Yw+c8OBP0TPFL9DfXA/p/UAvX3I2b3KnJo9eI/kP3dzaz/R/PY/fZC4vmmXST+jJue+iQQlv5PvZb7AtP28CRWLP1JLIj/P++c+9qpXP8r7V79YPT2/ouAev2cMor+rDANAeEfpPxWDmD8f2js/QbxPvSmjeb/DvoC8v8VTv5MauL1hR+S91keUP+aTn73aVGS/2KiHPU1osj+3OBS+Urg8PxiiurqeDr4/rkE9P6L8DL/I7Nm+w1mnvt0fHb8EMWy/k0pJPi9dGz+rCHG+bbPJvgPwUj6mLck/ywhlv3EpgT6Bx9I+ElpxvpmXWj8GsDa+lQsbPxJdyj8yLKc/dITnPDuHgT5TEA0/VLpLvtY6YT9ypyy92XP2vr32Lj/atNI/uvk8O1eJnL9xbnM//uD8PysRjD9d62y+BZEovx7pzD0sAMK/5todwEE2sr55tbU/Nk7bvlCeej9YsPA/oLFRP/dUNz/G3hU/7ZXyPWQgPj+75TM/YthtPukEqj+xUgM/VmYqPip51jodfmI/td3SPgtB/T7xvbc/Jtqev/l6jD9i2wS/Q+NNP8V4R7+xehC94LUXv4H4VD8aTFe/YFI4P+mqAb7Q36I9srCtPxEowD/y8Z8/fSZBv26iC7/Vj/w+uP/bP8+4p78G2Ci9hqVev8sWh74N2OU+/p1XPyIOVj8/TPI9ZMUUPnHmGz9s+o4/g1/1vpvRMT6X7pm+iINQPw==\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1565\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1564\",\"type\":\"UnionRenderers\"}},\"id\":\"1480\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1505\",\"type\":\"HelpTool\"},{\"attributes\":{\"source\":{\"id\":\"1480\",\"type\":\"ColumnDataSource\"}},\"id\":\"1519\",\"type\":\"CDSView\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1508\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1563\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1488\",\"type\":\"LinearScale\"}],\"root_ids\":[\"1481\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.2\"}};\n",
       "  var render_items = [{\"docid\":\"dbb3cf2a-b597-48c6-94b2-74b3dbccc7d8\",\"roots\":{\"1481\":\"11a8a55b-c97f-491f-b566-c099b2af0c65\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1481"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_embeddings(model.embeddings.weight.data.cpu().numpy(), index2word, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CON4VOyG3iET"
   },
   "source": [
    "### Negative Sampling\n",
    "\n",
    "Что сейчас самое тяжелое? Вычисление softmax и применение градиентов ко всем словам в $V$.\n",
    "\n",
    "Один из способов справиться с этим - использовать *Negative Sampling*.\n",
    "\n",
    "По сути, вместо предсказания индекса слова по контексту предсказывается вероятность того, что такое слово $w$ может быть в таком контексте $c$: $P(D=1|w,c)$.\n",
    "\n",
    "Можно использовать обычную сигмоиду для получения данной вероятности: \n",
    "$$P(D=1|w, c) = \\sigma(v_w^T u_c) = \\frac 1 {1 + \\exp(-v^T_w u_c)}.$$\n",
    "\n",
    "Процесс обучения тогда выглядит так: для каждой пары слово и его контекст генерируем набор отрицательных примеров:\n",
    "\n",
    "![Negative Sampling](Images/Negative_Sampling.png \"Neg sampling\")\n",
    "\n",
    "Для CBoW функция потерь будет выглядеть так:\n",
    "$$-\\log \\sigma(v_c^T u_c) - \\sum_{k=1}^K \\log \\sigma(-\\tilde v_k^T u_c),$$\n",
    "где $v_c$ - вектор центрального слова, $u_c$ - вектор контекста (сумма контекстных векторов), $\\tilde v_1, \\ldots, \\tilde v_K$ - сэмплированные негативные примеры.\n",
    "\n",
    "Сравните эту формулу с обычным CBoW:\n",
    "$$-v_c^T u_c + \\log \\sum_{i=1}^{|V|} \\exp(v_i^T u_c).$$\n",
    "\n",
    "Обычно слова сэмплируются из $U^{3/4}$, где $U$ - униграмное распределение, т.е частоты появления слова делённые на суммарое число слов. \n",
    "\n",
    "Частотности мы уже считали: они получаются в `Counter(words)`. Достаточно просто преобразовать их в вероятности и домножить эти вероятности на $\\frac 3 4$. Почему $\\frac 3 4$? Некоторую интуицию можно найти в следующем примере:\n",
    "\n",
    "$$P(\\text{is}) = 0.9, \\ P(\\text{is})^{3/4} = 0.92$$\n",
    "$$P(\\text{Constitution}) = 0.09, \\ P(\\text{Constitution})^{3/4} = 0.16$$\n",
    "$$P(\\text{bombastic}) = 0.01, \\ P(\\text{bombastic})^{3/4} = 0.032$$\n",
    "\n",
    "Вероятность для высокочастотных слов особо не увеличилась (относительно), зато низкочастотные будут выпадать с заметно большей вероятностей.\n",
    "\n",
    "**Задание** Реализуйте свой Negative Sampling.\n",
    "\n",
    "Для начала зададим распределение для сэмплирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcX4vRBLlXy6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  102,   725,  2367,  5161,   187],\n",
       "       [ 2212, 15392,  1323,  3208,  6519],\n",
       "       [  963, 17045,   997,  7174,   122],\n",
       "       [  619, 12050,  1453,  3553,  5779],\n",
       "       [  968,  2204,  2928,   819,   126],\n",
       "       [16060,  7116,    21,   414,     7],\n",
       "       [  565, 18048,    74,  5255,  5126],\n",
       "       [14871,  1911,   800,  6081,  4265],\n",
       "       [12335,  1094,   559,    12,    14],\n",
       "       [ 3625, 20606,  8365,   549,     6],\n",
       "       [   16,   299,    11,   828,   318],\n",
       "       [27567,   140,     8,     7,     1],\n",
       "       [    6,   137,   220,  6572,  3153],\n",
       "       [  297,    34,  6697,  5177,  1574],\n",
       "       [  801,     9,  3673,   538,   532],\n",
       "       [ 2056,  5916, 16651,  1676,  4299],\n",
       "       [ 4154,     4,  2071,     9,    50],\n",
       "       [ 3320,     8,   340,     1,   754],\n",
       "       [ 4229,     8,  3356,   725, 10346],\n",
       "       [ 1011,   376,   142,   619,    54],\n",
       "       [    3,  1031,   357, 14494,  1911],\n",
       "       [19425,   542,    12,    81,  4622],\n",
       "       [    2,   467,    99,  6642,  3036],\n",
       "       [   70,    25,    75,  6243,    71],\n",
       "       [ 6476,  6929,  3033,   151,   124],\n",
       "       [  186,     6,  1054,    58,     1],\n",
       "       [ 1026,  5349,  7388,   184,    18],\n",
       "       [   45,  3350,  5320,  1807,   605],\n",
       "       [10671,  3097,   138, 16919,   771],\n",
       "       [ 7682, 19383,   566,  3260,   156],\n",
       "       [  339,     1,   495,   488,    11],\n",
       "       [ 1264,  6992, 27754,    51,   842]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_sum_count = sum(words_counter.values())\n",
    "word_distribution = np.array([(words_counter[word] / words_sum_count) ** (3 / 4) for word in index2word])\n",
    "# Вообще-то, тут нечестно сделанно, можно лучше\n",
    "word_distribution /= word_distribution.sum()\n",
    "\n",
    "indices = np.arange(len(word_distribution))\n",
    "\n",
    "np.random.choice(indices, p=word_distribution, size=(32, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_o2pzsue16Lu"
   },
   "outputs": [],
   "source": [
    "class NegativeSamplingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.indices = np.arange(len(word_distribution))\n",
    "\n",
    "    def forward(self, inputs, targets, num_samples):\n",
    "        '''\n",
    "        inputs: (batch_size, context_size)\n",
    "        targets: (batch_size)\n",
    "        num_samples: int\n",
    "        '''\n",
    "        #u_c = self.embeddings(inputs)\n",
    "        #out = self.out_layer(u_c)\n",
    "        \n",
    "        #print(self.embeddings.weight.shape)\n",
    "        #print(self.out_layer.weight.shape)\n",
    "        #x = self.embeddings(inputs)\n",
    "        #out = self.out_layer(x)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        u_c = self.embeddings.weight[inputs]\n",
    "        v_c = self.out_layer.weight[targets]\n",
    "        #print(u_c.shape)\n",
    "        #print(v_c.shape)\n",
    "        out = torch.matmul(v_c, u_c.t()).diag()\n",
    "        #print(out.shape)\n",
    "        \n",
    "        indices = torch.Tensor(\n",
    "            np.random.choice(self.indices, p=word_distribution, size=num_samples)\n",
    "        ).long().cuda()\n",
    "        \n",
    "        neg_v_c = self.out_layer.weight[indices]\n",
    "        #print(neg_v_c.shape)\n",
    "        \n",
    "        #<apply F.logsigmoid to v_c * u_c and to -v'_c * u_c>\n",
    "#         loss1 = torch.gather(\n",
    "#             F.logsigmoid(\n",
    "#                 out\n",
    "#             ),\n",
    "#             dim = 1, \n",
    "#             index = targets.unsqueeze(0).reshape((-1,1))\n",
    "#         )\n",
    "        #loss1 = loss_function(out, targets)\n",
    "        loss1 = F.logsigmoid(out).sum()\n",
    "        loss2 = F.logsigmoid(-torch.matmul(neg_v_c, u_c.t()).diag()).sum()\n",
    "        #print(loss1)\n",
    "        #print(loss2)\n",
    "        #return \" wdfv\"\n",
    "        return -(loss1 + loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wz2iRanqzlq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing batchs generator with 36908 batchs per epoch\n",
      "Step = 1000, Avg Loss = 707.0231, Time = 6.82s\n",
      "Step = 2000, Avg Loss = 679.8234, Time = 2.78s\n",
      "Step = 3000, Avg Loss = 663.1999, Time = 2.79s\n",
      "Step = 4000, Avg Loss = 649.3353, Time = 2.78s\n",
      "Step = 5000, Avg Loss = 636.9621, Time = 2.79s\n",
      "Step = 6000, Avg Loss = 627.6693, Time = 2.81s\n",
      "Step = 7000, Avg Loss = 620.0260, Time = 2.77s\n",
      "Step = 8000, Avg Loss = 614.4061, Time = 2.78s\n",
      "Step = 9000, Avg Loss = 607.2678, Time = 2.81s\n",
      "Step = 10000, Avg Loss = 604.8136, Time = 2.78s\n",
      "Step = 11000, Avg Loss = 600.8858, Time = 2.76s\n",
      "Step = 12000, Avg Loss = 596.9040, Time = 2.80s\n",
      "Step = 13000, Avg Loss = 594.2725, Time = 2.80s\n",
      "Step = 14000, Avg Loss = 591.8701, Time = 2.78s\n",
      "Step = 15000, Avg Loss = 588.6842, Time = 2.80s\n",
      "Step = 16000, Avg Loss = 586.8760, Time = 2.79s\n",
      "Step = 17000, Avg Loss = 584.7739, Time = 2.76s\n",
      "Step = 18000, Avg Loss = 583.6758, Time = 2.79s\n",
      "Step = 19000, Avg Loss = 580.9975, Time = 2.80s\n",
      "Step = 20000, Avg Loss = 579.2083, Time = 2.77s\n",
      "Step = 21000, Avg Loss = 578.0397, Time = 2.79s\n",
      "Step = 22000, Avg Loss = 576.7969, Time = 2.80s\n",
      "Step = 23000, Avg Loss = 575.9121, Time = 2.78s\n",
      "Step = 24000, Avg Loss = 573.7853, Time = 2.80s\n",
      "Step = 25000, Avg Loss = 572.8472, Time = 2.82s\n",
      "Step = 26000, Avg Loss = 571.7849, Time = 2.79s\n",
      "Step = 27000, Avg Loss = 571.9147, Time = 2.79s\n",
      "Step = 28000, Avg Loss = 570.6792, Time = 2.78s\n",
      "Step = 29000, Avg Loss = 568.6638, Time = 2.78s\n",
      "Step = 30000, Avg Loss = 568.8528, Time = 2.79s\n",
      "Step = 31000, Avg Loss = 568.0589, Time = 2.78s\n",
      "Step = 32000, Avg Loss = 566.7570, Time = 2.78s\n",
      "Step = 33000, Avg Loss = 565.5003, Time = 2.77s\n",
      "Step = 34000, Avg Loss = 565.6675, Time = 2.79s\n",
      "Step = 35000, Avg Loss = 563.5086, Time = 2.78s\n",
      "Step = 36000, Avg Loss = 564.2761, Time = 2.79s\n",
      "Step = 37000, Avg Loss = 561.7334, Time = 2.96s\n",
      "Step = 38000, Avg Loss = 553.8803, Time = 2.81s\n",
      "Step = 39000, Avg Loss = 554.0283, Time = 2.78s\n",
      "Step = 40000, Avg Loss = 552.4018, Time = 2.79s\n",
      "Step = 41000, Avg Loss = 552.8385, Time = 2.80s\n",
      "Step = 42000, Avg Loss = 554.1514, Time = 2.76s\n",
      "Step = 43000, Avg Loss = 552.5774, Time = 2.79s\n",
      "Step = 44000, Avg Loss = 553.2413, Time = 2.78s\n",
      "Step = 45000, Avg Loss = 552.7749, Time = 2.77s\n",
      "Step = 46000, Avg Loss = 553.1454, Time = 2.79s\n",
      "Step = 47000, Avg Loss = 551.8399, Time = 2.81s\n",
      "Step = 48000, Avg Loss = 551.6693, Time = 2.78s\n",
      "Step = 49000, Avg Loss = 551.5130, Time = 2.79s\n",
      "Step = 50000, Avg Loss = 550.9795, Time = 2.78s\n",
      "Step = 51000, Avg Loss = 550.9012, Time = 2.80s\n",
      "Step = 52000, Avg Loss = 549.4017, Time = 2.78s\n",
      "Step = 53000, Avg Loss = 549.9590, Time = 2.77s\n",
      "Step = 54000, Avg Loss = 549.9355, Time = 2.79s\n",
      "Step = 55000, Avg Loss = 549.1157, Time = 2.76s\n",
      "Step = 56000, Avg Loss = 550.7741, Time = 2.79s\n",
      "Step = 57000, Avg Loss = 549.2868, Time = 2.81s\n",
      "Step = 58000, Avg Loss = 549.2968, Time = 2.77s\n",
      "Step = 59000, Avg Loss = 549.3060, Time = 2.79s\n",
      "Step = 60000, Avg Loss = 547.8540, Time = 2.79s\n",
      "Step = 61000, Avg Loss = 548.5695, Time = 2.79s\n",
      "Step = 62000, Avg Loss = 548.2236, Time = 2.79s\n",
      "Step = 63000, Avg Loss = 548.5666, Time = 2.79s\n",
      "Step = 64000, Avg Loss = 546.8865, Time = 2.79s\n",
      "Step = 65000, Avg Loss = 547.2235, Time = 2.75s\n",
      "Step = 66000, Avg Loss = 547.1340, Time = 2.80s\n",
      "Step = 67000, Avg Loss = 548.1245, Time = 2.77s\n",
      "Step = 68000, Avg Loss = 545.6728, Time = 2.79s\n",
      "Step = 69000, Avg Loss = 546.4628, Time = 2.80s\n",
      "Step = 70000, Avg Loss = 544.8417, Time = 2.79s\n",
      "Step = 71000, Avg Loss = 545.1901, Time = 2.79s\n",
      "Step = 72000, Avg Loss = 545.9138, Time = 2.78s\n",
      "Step = 73000, Avg Loss = 545.3978, Time = 2.81s\n",
      "Step = 74000, Avg Loss = 544.1154, Time = 2.94s\n",
      "Step = 75000, Avg Loss = 535.3944, Time = 2.78s\n",
      "Step = 76000, Avg Loss = 533.8605, Time = 2.79s\n",
      "Step = 77000, Avg Loss = 535.8221, Time = 2.83s\n",
      "Step = 78000, Avg Loss = 537.3189, Time = 2.79s\n",
      "Step = 79000, Avg Loss = 536.9901, Time = 2.77s\n",
      "Step = 80000, Avg Loss = 538.1577, Time = 2.80s\n",
      "Step = 81000, Avg Loss = 536.8025, Time = 2.78s\n",
      "Step = 82000, Avg Loss = 537.5664, Time = 2.79s\n",
      "Step = 83000, Avg Loss = 536.7785, Time = 2.81s\n",
      "Step = 84000, Avg Loss = 536.0772, Time = 2.80s\n",
      "Step = 85000, Avg Loss = 537.3235, Time = 2.74s\n",
      "Step = 86000, Avg Loss = 537.6767, Time = 2.79s\n",
      "Step = 87000, Avg Loss = 538.3292, Time = 2.79s\n",
      "Step = 88000, Avg Loss = 536.7275, Time = 2.77s\n",
      "Step = 89000, Avg Loss = 537.3818, Time = 2.79s\n",
      "Step = 90000, Avg Loss = 538.2765, Time = 2.79s\n",
      "Step = 91000, Avg Loss = 536.3079, Time = 2.77s\n",
      "Step = 92000, Avg Loss = 536.5900, Time = 2.79s\n",
      "Step = 93000, Avg Loss = 538.0001, Time = 2.77s\n",
      "Step = 94000, Avg Loss = 538.3505, Time = 2.79s\n",
      "Step = 95000, Avg Loss = 536.7883, Time = 2.77s\n",
      "Step = 96000, Avg Loss = 536.0442, Time = 2.77s\n",
      "Step = 97000, Avg Loss = 537.7758, Time = 2.77s\n",
      "Step = 98000, Avg Loss = 538.3170, Time = 2.77s\n",
      "Step = 99000, Avg Loss = 537.3464, Time = 2.81s\n",
      "Step = 100000, Avg Loss = 536.4778, Time = 2.81s\n",
      "Step = 101000, Avg Loss = 536.8430, Time = 2.78s\n",
      "Step = 102000, Avg Loss = 535.4505, Time = 2.79s\n",
      "Step = 103000, Avg Loss = 536.4213, Time = 2.79s\n",
      "Step = 104000, Avg Loss = 536.0431, Time = 2.78s\n",
      "Step = 105000, Avg Loss = 534.7937, Time = 2.80s\n",
      "Step = 106000, Avg Loss = 535.7400, Time = 2.76s\n",
      "Step = 107000, Avg Loss = 536.9339, Time = 2.80s\n",
      "Step = 108000, Avg Loss = 535.0234, Time = 2.78s\n",
      "Step = 109000, Avg Loss = 535.4477, Time = 2.77s\n",
      "Step = 110000, Avg Loss = 535.9294, Time = 2.80s\n",
      "Step = 111000, Avg Loss = 534.1973, Time = 2.96s\n",
      "Step = 112000, Avg Loss = 526.4232, Time = 2.81s\n",
      "Step = 113000, Avg Loss = 528.3977, Time = 2.79s\n",
      "Step = 114000, Avg Loss = 527.7796, Time = 2.77s\n",
      "Step = 115000, Avg Loss = 528.3132, Time = 2.80s\n",
      "Step = 116000, Avg Loss = 528.3859, Time = 2.78s\n",
      "Step = 117000, Avg Loss = 528.2457, Time = 2.78s\n",
      "Step = 118000, Avg Loss = 529.5274, Time = 2.78s\n",
      "Step = 119000, Avg Loss = 528.8759, Time = 2.79s\n",
      "Step = 120000, Avg Loss = 529.0486, Time = 2.76s\n",
      "Step = 121000, Avg Loss = 529.9434, Time = 2.75s\n",
      "Step = 122000, Avg Loss = 530.0152, Time = 2.77s\n",
      "Step = 123000, Avg Loss = 530.7334, Time = 2.80s\n",
      "Step = 124000, Avg Loss = 530.2906, Time = 2.79s\n",
      "Step = 125000, Avg Loss = 530.3788, Time = 2.81s\n",
      "Step = 126000, Avg Loss = 530.6412, Time = 2.77s\n",
      "Step = 127000, Avg Loss = 530.1794, Time = 2.78s\n",
      "Step = 128000, Avg Loss = 531.0142, Time = 2.79s\n",
      "Step = 129000, Avg Loss = 530.7409, Time = 2.81s\n",
      "Step = 130000, Avg Loss = 531.0964, Time = 2.80s\n",
      "Step = 131000, Avg Loss = 531.2085, Time = 2.79s\n",
      "Step = 132000, Avg Loss = 531.7251, Time = 2.78s\n",
      "Step = 133000, Avg Loss = 530.5761, Time = 2.77s\n",
      "Step = 134000, Avg Loss = 531.0584, Time = 2.78s\n",
      "Step = 135000, Avg Loss = 531.2154, Time = 2.79s\n",
      "Step = 136000, Avg Loss = 530.3645, Time = 2.78s\n",
      "Step = 137000, Avg Loss = 531.2623, Time = 2.79s\n",
      "Step = 138000, Avg Loss = 530.5299, Time = 2.78s\n",
      "Step = 139000, Avg Loss = 531.6777, Time = 2.78s\n",
      "Step = 140000, Avg Loss = 529.8536, Time = 2.78s\n",
      "Step = 141000, Avg Loss = 530.5539, Time = 2.78s\n",
      "Step = 142000, Avg Loss = 529.3426, Time = 2.80s\n",
      "Step = 143000, Avg Loss = 530.7122, Time = 2.78s\n",
      "Step = 144000, Avg Loss = 529.8336, Time = 2.78s\n",
      "Step = 145000, Avg Loss = 531.6565, Time = 2.79s\n",
      "Step = 146000, Avg Loss = 530.5521, Time = 2.78s\n",
      "Step = 147000, Avg Loss = 530.8325, Time = 2.78s\n",
      "Step = 148000, Avg Loss = 526.6063, Time = 2.95s\n",
      "Step = 149000, Avg Loss = 522.2087, Time = 2.79s\n",
      "Step = 150000, Avg Loss = 522.3719, Time = 2.80s\n",
      "Step = 151000, Avg Loss = 523.9262, Time = 2.78s\n",
      "Step = 152000, Avg Loss = 522.5542, Time = 2.78s\n",
      "Step = 153000, Avg Loss = 523.9253, Time = 2.76s\n",
      "Step = 154000, Avg Loss = 523.5576, Time = 2.77s\n",
      "Step = 155000, Avg Loss = 524.1792, Time = 2.80s\n",
      "Step = 156000, Avg Loss = 525.2593, Time = 2.79s\n",
      "Step = 157000, Avg Loss = 525.8684, Time = 2.79s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-a30ed1eab696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/temp3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-455-e2fe1cbf963b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets, num_samples)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         indices = torch.Tensor(\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         ).long().cuda()\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2478\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2479\u001b[0m     \"\"\"\n\u001b[1;32m   2480\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0mof\u001b[0m \u001b[0marray\u001b[0m \u001b[0melements\u001b[0m \u001b[0mover\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NegativeSamplingModel(vocab_size=len(word2index), embedding_dim=32).cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "loss_every_nsteps = 1000\n",
    "total_loss = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for step, (batch, labels) in enumerate(make_cbow_batchs_iter(contexts, window_size=2, batch_size=128)):\n",
    "    batch = torch.Tensor(batch).long().cuda()\n",
    "    labels = torch.Tensor(labels).long().cuda()\n",
    "    loss = model(batch, labels, 500)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    if step != 0 and step % loss_every_nsteps == 0:\n",
    "        print(\"Step = {}, Avg Loss = {:.4f}, Time = {:.2f}s\".format(step, total_loss / loss_every_nsteps, \n",
    "                                                                    time.time() - start_time))\n",
    "        total_loss = 0\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFik_6djvg3F",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1000 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1000 samples in 0.064s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1000\n",
      "[t-SNE] Mean sigma: 1.850932\n",
      "[t-SNE] Computed conditional probabilities in 0.037s\n",
      "[t-SNE] Iteration 50: error = 74.2301407, gradient norm = 0.2860864 (50 iterations in 2.528s)\n",
      "[t-SNE] Iteration 100: error = 75.7904282, gradient norm = 0.2790874 (50 iterations in 2.689s)\n",
      "[t-SNE] Iteration 150: error = 75.6745911, gradient norm = 0.2861003 (50 iterations in 2.688s)\n",
      "[t-SNE] Iteration 200: error = 75.6588898, gradient norm = 0.2850049 (50 iterations in 2.689s)\n",
      "[t-SNE] Iteration 250: error = 75.1265335, gradient norm = 0.2587326 (50 iterations in 2.631s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 75.126534\n",
      "[t-SNE] Iteration 300: error = 1.7313004, gradient norm = 0.0024411 (50 iterations in 1.841s)\n",
      "[t-SNE] Iteration 350: error = 1.6233114, gradient norm = 0.0004612 (50 iterations in 1.567s)\n",
      "[t-SNE] Iteration 400: error = 1.5870479, gradient norm = 0.0002801 (50 iterations in 1.548s)\n",
      "[t-SNE] Iteration 450: error = 1.5736842, gradient norm = 0.0002058 (50 iterations in 1.575s)\n",
      "[t-SNE] Iteration 500: error = 1.5662351, gradient norm = 0.0002034 (50 iterations in 1.561s)\n",
      "[t-SNE] Iteration 550: error = 1.5599288, gradient norm = 0.0001871 (50 iterations in 2.225s)\n",
      "[t-SNE] Iteration 600: error = 1.5558140, gradient norm = 0.0001393 (50 iterations in 3.381s)\n",
      "[t-SNE] Iteration 650: error = 1.5500510, gradient norm = 0.0001784 (50 iterations in 2.664s)\n",
      "[t-SNE] Iteration 700: error = 1.5452924, gradient norm = 0.0001678 (50 iterations in 2.332s)\n",
      "[t-SNE] Iteration 750: error = 1.5405418, gradient norm = 0.0001556 (50 iterations in 2.249s)\n",
      "[t-SNE] Iteration 800: error = 1.5363246, gradient norm = 0.0001252 (50 iterations in 2.058s)\n",
      "[t-SNE] Iteration 850: error = 1.5340286, gradient norm = 0.0001256 (50 iterations in 1.973s)\n",
      "[t-SNE] Iteration 900: error = 1.5323526, gradient norm = 0.0001294 (50 iterations in 1.814s)\n",
      "[t-SNE] Iteration 950: error = 1.5307992, gradient norm = 0.0001127 (50 iterations in 1.823s)\n",
      "[t-SNE] Iteration 1000: error = 1.5284863, gradient norm = 0.0001307 (50 iterations in 1.703s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.528486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:193: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"3304\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"3304\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"3304\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '3304' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"3304\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"3304\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"3304\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '3304' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"3304\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"d32e9ae8-9e87-454b-ad28-c525d6c65eb2\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"b245cd91-7252-4d81-a534-044db4dfa5b3\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"3315\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"3320\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"3315\",\"type\":\"LinearAxis\"},{\"id\":\"3319\",\"type\":\"Grid\"},{\"id\":\"3320\",\"type\":\"LinearAxis\"},{\"id\":\"3324\",\"type\":\"Grid\"},{\"id\":\"3333\",\"type\":\"BoxAnnotation\"},{\"id\":\"3343\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"3473\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"3331\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"3307\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"3311\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"3309\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"3313\",\"type\":\"LinearScale\"}},\"id\":\"3306\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"3478\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"token\":[\"?\",\"the\",\"what\",\"is\",\"a\",\"i\",\"to\",\"in\",\"how\",\"of\",\"do\",\"are\",\"and\",\"for\",\",\",\"can\",\"you\",\"why\",\"it\",\"my\",\"does\",\"best\",\"on\",\".\",\"or\",\"have\",\"if\",\"be\",\"with\",\"which\",\"that\",\"an\",\"some\",\"should\",\"'s\",\"get\",\"from\",\")\",\"your\",\"(\",\"like\",\"when\",\"at\",\"india\",\"good\",\"who\",\"there\",\"will\",\"as\",\"would\",\"people\",\"not\",\"n't\",\"about\",\"``\",\"''\",\"between\",\"one\",\"did\",\"any\",\"we\",\"me\",\"where\",\"most\",\"was\",\"by\",\"make\",\"so\",\"they\",\"this\",\"am\",\"after\",\"way\",\":\",\"has\",\"use\",\"much\",\"difference\",\"time\",\"life\",\"their\",\"know\",\"work\",\"many\",\"but\",\"than\",\"more\",\"all\",\"want\",\"quora\",\"someone\",\"learn\",\"find\",\"other\",\"think\",\"new\",\"better\",\"job\",\"indian\",\"out\",\"money\",\"mean\",\"become\",\"ever\",\"world\",\"without\",\"he\",\"start\",\"take\",\"us\",\"up\",\"first\",\"feel\",\"year\",\"into\",\"go\",\"online\",\"used\",\"engineering\",\"could\",\"love\",\"'m\",\"person\",\"were\",\"possible\",\"day\",\"buy\",\"things\",\"being\",\"need\",\"business\",\"using\",\"them\",\"really\",\"trump\",\"girl\",\"'\",\"her\",\"his\",\"years\",\"different\",\"long\",\"phone\",\"google\",\"company\",\"been\",\"old\",\"only\",\"no\",\"now\",\"just\",\"2\",\"app\",\"college\",\"facebook\",\"number\",\"free\",\"books\",\"2016\",\"movie\",\"still\",\"its\",\"account\",\"ca\",\"women\",\"book\",\"english\",\"while\",\"she\",\"had\",\"change\",\"ways\",\"computer\",\"thing\",\"examples\",\"data\",\"country\",\"over\",\"see\",\"android\",\"help\",\"science\",\"live\",\"school\",\"software\",\"before\",\"&\",\"language\",\"same\",\"going\",\"bad\",\"sex\",\"student\",\"stop\",\"university\",\"happen\",\"back\",\"made\",\"3\",\"1\",\"study\",\"our\",\"two\",\"through\",\"system\",\"name\",\"say\",\"real\",\"during\",\"prepare\",\"water\",\"iphone\",\"website\",\"top\",\"car\",\"questions\",\"important\",\"men\",\"give\",\"getting\",\"anyone\",\"companies\",\"high\",\"black\",\"card\",\"read\",\"programming\",\"war\",\"learning\",\"10\",\"5\",\"\\u2019\",\"exam\",\"[\",\"then\",\"]\",\"even\",\"movies\",\"china\",\"mobile\",\"cost\",\"donald\",\"right\",\"doing\",\"friend\",\"him\",\"working\",\"under\",\"come\",\"president\",\"own\",\"question\",\"career\",\"experience\",\"bank\",\"true\",\"friends\",\"guy\",\"word\",\"hair\",\"home\",\"video\",\"having\",\"look\",\"usa\",\"tell\",\"man\",\"social\",\"web\",\"interview\",\"very\",\"engineer\",\"write\",\"game\",\"government\",\"weight\",\"earth\",\"girls\",\"service\",\"food\",\"students\",\"play\",\"countries\",\"human\",\"place\",\"future\",\"improve\",\"off\",\"big\",\"days\",\"happens\",\"'ve\",\"done\",\"class\",\"eat\",\"tv\",\"process\",\"got\",\"state\",\"average\",\"s\",\"meaning\",\"relationship\",\"music\",\"too\",\"math\",\"create\",\"instagram\",\"every\",\"history\",\"last\",\"pay\",\"windows\",\"4\",\"white\",\"watch\",\"%\",\"salary\",\"body\",\"power\",\"safe\",\"clinton\",\"ask\",\"age\",\"laptop\",\"makes\",\"$\",\"each\",\"hard\",\"lose\",\"american\",\"delhi\",\"youtube\",\"energy\",\"worth\",\"earn\",\"states\",\"against\",\"win\",\"girlfriend\",\"great\",\"keep\",\"test\",\"god\",\"hillary\",\"compare\",\"market\",\"differences\",\"making\",\"considered\",\"something\",\"answer\",\"apply\",\"myself\",\"mba\",\"tips\",\"around\",\"never\",\"next\",\"always\",\"mechanical\",\"another\",\"united\",\"java\",\"increase\",\"c\",\"such\",\"course\",\"jobs\",\"download\",\"song\",\"parents\",\"kind\",\"internet\",\"common\",\"review\",\"woman\",\"code\",\"design\",\"per\",\"employees\",\"end\",\"development\",\"chinese\",\"series\",\"score\",\"interesting\",\"degree\",\"month\",\"travel\",\"show\",\"management\",\"months\",\"able\",\"believe\",\"open\",\"program\",\"living\",\"looking\",\"because\",\"6\",\"type\",\"bangalore\",\"light\",\"favorite\",\"america\",\"today\",\"actually\",\"major\",\"family\",\"marketing\",\"pakistan\",\"universities\",\"technology\",\"law\",\"call\",\"affect\",\"whatsapp\",\"idea\",\"{\",\"build\",\"}\",\"choose\",\"cat\",\"current\",\"support\",\"problem\",\"popular\",\"speed\",\"air\",\"rid\",\"deal\",\"visa\",\"join\",\"run\",\"games\",\"space\",\"down\",\"both\",\"well\",\"city\",\"2017\",\"house\",\"exist\",\"services\",\"available\",\"civil\",\"u.s.\",\"site\",\"culture\",\"also\",\"normal\",\"given\",\"wrong\",\"apple\",\"7\",\"small\",\"order\",\"date\",\"wear\",\"apps\",\"places\",\"songs\",\"differ\",\"project\",\"product\",\"international\",\"x\",\"behind\",\"main\",\"research\",\"happened\",\"boyfriend\",\"media\",\"public\",\"canada\",\"value\",\"jee\",\"cause\",\"reason\",\"uk\",\"education\",\"email\",\"ms\",\"sleep\",\"-\",\"amazon\",\"instead\",\"these\",\"benefits\",\"startup\",\"less\",\"iit\",\"part\",\"list\",\"based\",\"die\",\"medical\",\"websites\",\"etc\",\"physics\",\"skills\",\"child\",\"form\",\"health\",\"causes\",\"called\",\"times\",\"visit\",\"hate\",\"level\",\"worst\",\"police\",\"legal\",\"control\",\"terms\",\"stay\",\"products\",\"mumbai\",\"post\",\"facts\",\"mind\",\"face\",\"application\",\"rate\",\"sites\",\"field\",\"file\",\"required\",\"humans\",\"sell\",\"seen\",\"story\",\"machine\",\"private\",\"dog\",\"notes\",\"stock\",\"modi\",\"biggest\",\"asked\",\"invest\",\"children\",\"point\",\"writing\",\"move\",\"night\",\"problems\",\"gate\",\"put\",\"'re\",\"successful\",\"single\",\"anything\",\"indians\",\"others\",\"remove\",\"compared\",\"theory\",\"death\",\"ideas\",\"talk\",\"marks\",\"answers\",\"plan\",\"similar\",\"sentence\",\"low\",\"group\",\"institute\",\"side\",\"hours\",\"again\",\"effects\",\"/math\",\"coaching\",\"australia\",\"solve\",\"advantages\",\"correct\",\"function\",\"tax\",\"lot\",\"center\",\"famous\",\"send\",\"germany\",\"guys\",\"add\",\"set\",\"offer\",\"south\",\"force\",\"credit\",\"foreign\",\"universe\",\"information\",\"fall\",\"period\",\"daily\",\"says\",\"developer\",\"training\",\"full\",\"videos\",\"area\",\"industry\",\"oil\",\"model\",\"general\",\"studying\",\"majors\",\"star\",\"colleges\",\"graduate\",\"size\",\"yourself\",\"drive\",\"python\",\"2015\",\"blood\",\"near\",\"search\",\"enough\",\"price\",\"kill\",\"quality\",\"words\",\"8\",\"cons\",\"marriage\",\"found\",\"often\",\"\\u201d\",\"leave\",\"pros\",\"fast\",\"grow\",\"courses\",\"started\",\"week\",\"fix\",\"related\",\"purpose\",\"network\",\"types\",\"russia\",\"advice\",\"those\",\"password\",\"follow\",\"taking\",\"married\",\"mass\",\"male\",\"store\",\"turn\",\"party\",\"left\",\"brain\",\"rs\",\"\\u201c\",\"numbers\",\"100\",\"500\",\"female\",\"share\",\"digital\",\"team\",\"1000\",\"effective\",\"economy\",\"term\",\"text\",\"delete\",\"election\",\"cell\",\"pc\",\"master\",\"office\",\"matter\",\"few\",\"role\",\"since\",\"preparation\",\"fat\",\"second\",\"page\",\"dark\",\"short\",\"said\",\"happy\",\"red\",\"line\",\"away\",\"security\",\"options\",\"easy\",\"effect\",\"three\",\"view\",\"admission\",\"must\",\"chemical\",\"source\",\"lost\",\"try\",\"dream\",\"understand\",\"care\",\"exams\",\"convert\",\"americans\",\"past\",\"electrical\",\"dogs\",\"profile\",\"alcohol\",\"exactly\",\"north\",\"ios\",\"develop\",\"paper\",\"japanese\",\"investment\",\"tech\",\"difficult\",\"hotel\",\"check\",\"beautiful\",\"personal\",\"calculate\",\"japan\",\"uber\",\"letter\",\"eating\",\"religion\",\"20\",\"explain\",\"languages\",\"c++\",\"b\",\"hyderabad\",\"topics\",\"british\",\"twitter\",\"basic\",\"news\",\"california\",\"self\",\"green\",\"political\",\"transfer\",\"wife\",\"12\",\"fight\",\"rank\",\"drug\",\"let\",\"porn\",\"film\",\"scope\",\"t\",\"army\",\"pune\",\"national\",\"once\",\"contact\",\"note\",\"known\",\"avoid\",\"boy\",\"gain\",\"please\",\"address\",\"wants\",\"reasons\",\"paid\",\"obama\",\"engine\",\"europe\",\"ex\",\"currently\",\"bollywood\",\"samsung\",\"smart\",\"everyone\",\"season\",\"phd\",\"income\",\"officer\",\"chances\",\"reduce\",\"option\",\"overcome\",\"everything\",\"across\",\"reading\",\"military\",\"else\",\"users\",\"meet\",\"15\",\"solar\",\"message\",\"charge\",\"knowledge\",\"due\",\"sound\",\"balance\",\"microsoft\",\"!\",\"internship\",\"faster\",\"photos\",\"pregnant\",\"sim\",\"yes\",\"moon\",\"taken\",\"financial\",\"hindi\",\"disadvantages\",\"pass\",\"animals\",\"messages\",\"gay\",\"/\",\"hack\",\"healthy\",\"pain\",\"systems\",\"amount\",\"color\",\"interested\",\"singapore\",\"ias\",\"natural\",\"skin\",\"screen\",\"chance\",\"names\",\"special\",\"height\",\"board\",\"case\",\"structure\",\"passport\",\"break\",\"pro\",\"created\",\"professional\",\"drink\",\"already\",\"percentage\",\"useful\",\"french\",\"crush\",\"sun\",\"dating\",\"likes\",\"presidential\",\"battery\",\"interest\",\"access\",\"coming\",\"provide\",\"muslim\",\"starting\",\"modern\",\"linux\",\"recover\",\"camera\",\"german\",\"expect\",\"vote\",\"muslims\",\"blue\",\"least\",\"install\",\"train\",\"studies\",\"solution\",\"thinking\",\"following\",\"negative\",\"mother\",\"jio\",\"mac\",\"user\",\"spend\",\"prime\",\"written\",\"buying\",\"feeling\",\"running\",\"football\",\"gift\",\"cold\",\"changed\",\"pressure\",\"allowed\",\"character\",\"brand\",\"rich\",\"snapchat\",\"resources\",\"within\",\"speak\",\"impact\",\"islam\",\"yet\",\"non\",\"marry\",\"eyes\",\"society\",\"bill\",\"likely\",\"though\",\"determine\",\"shows\",\"fake\",\"save\",\"capital\",\"final\",\"gmail\",\"picture\",\"laws\",\"middle\",\"applications\",\"nuclear\",\"chemistry\",\"young\",\"kids\",\"prefer\",\"device\",\"iq\",\"father\",\"views\",\"galaxy\",\"manager\",\"doctor\",\"personality\",\"hand\",\"greatest\",\"currency\",\"inside\",\"illegal\",\"stories\",\"strategy\",\"recruit\",\"pursue\",\"cs\",\"abroad\",\"gold\",\"projects\",\"consider\",\"works\",\"blog\",\"crack\",\"memory\",\"example\",\"neet\",\"growth\",\"schools\",\"necessary\",\"husband\",\"insurance\",\"alone\",\"economics\",\"depression\",\"higher\",\"dead\",\"b.tech\",\"30\",\"cse\",\"loss\",\"among\",\"files\",\"deleted\",\"easiest\",\"macbook\",\"together\",\"art\",\"wifi\",\"vs\",\"gas\",\"suggest\",\"late\",\"intelligence\",\"method\",\"gre\",\"head\",\"minimum\",\"version\",\"tools\",\"easily\",\"chennai\",\"cars\",\"suitable\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"3480\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"3479\",\"type\":\"UnionRenderers\"}},\"id\":\"3305\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"3326\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"3333\",\"type\":\"BoxAnnotation\"}},\"id\":\"3327\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"3306\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"3321\",\"type\":\"BasicTicker\"}},\"id\":\"3324\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"3479\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"3480\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"3329\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"3325\",\"type\":\"PanTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"3333\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"3330\",\"type\":\"HelpTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"3345\",\"type\":\"HoverTool\"},{\"attributes\":{\"data_source\":{\"id\":\"3305\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"3341\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"3342\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"3344\",\"type\":\"CDSView\"}},\"id\":\"3343\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"3311\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"3476\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"3313\",\"type\":\"LinearScale\"},{\"attributes\":{\"formatter\":{\"id\":\"3476\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"3306\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"3316\",\"type\":\"BasicTicker\"}},\"id\":\"3315\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"3342\",\"type\":\"Scatter\"},{\"attributes\":{\"callback\":null},\"id\":\"3309\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"3473\",\"type\":\"Title\"},{\"attributes\":{\"source\":{\"id\":\"3305\",\"type\":\"ColumnDataSource\"}},\"id\":\"3344\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"3328\",\"type\":\"SaveTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"3341\",\"type\":\"Scatter\"},{\"attributes\":{\"formatter\":{\"id\":\"3478\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"3306\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"3321\",\"type\":\"BasicTicker\"}},\"id\":\"3320\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"3316\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"3326\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"3325\",\"type\":\"PanTool\"},{\"id\":\"3326\",\"type\":\"WheelZoomTool\"},{\"id\":\"3327\",\"type\":\"BoxZoomTool\"},{\"id\":\"3328\",\"type\":\"SaveTool\"},{\"id\":\"3329\",\"type\":\"ResetTool\"},{\"id\":\"3330\",\"type\":\"HelpTool\"},{\"id\":\"3345\",\"type\":\"HoverTool\"}]},\"id\":\"3331\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"3321\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"3307\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":{\"id\":\"3306\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"3316\",\"type\":\"BasicTicker\"}},\"id\":\"3319\",\"type\":\"Grid\"}],\"root_ids\":[\"3306\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.2\"}};\n",
       "  var render_items = [{\"docid\":\"b245cd91-7252-4d81-a534-044db4dfa5b3\",\"roots\":{\"3306\":\"d32e9ae8-9e87-454b-ad28-c525d6c65eb2\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "3306"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_embeddings(model.embeddings.weight.data.cpu().numpy(), index2word, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4G2X-TTpzwz"
   },
   "source": [
    "### Structured Word2Vec\n",
    "\n",
    "**Задание** В статье [Two/Too Simple Adaptations of Word2Vec for Syntax Problems (2015), Ling, Wang, et al.](https://www.aclweb.org/anthology/N/N15/N15-1142.pdf) рассматриваются два варианта улучшения эмбеддингов - *Structured Skip-gram Model* и *Continuous Window Model*:   \n",
    "![](https://github.com/DanAnastasyev/DeepNLP-Course/raw/master/Week%2003/Images/StructuredWord2vec.png =600x)  \n",
    "*From Two/Too Simple Adaptations of Word2Vec for Syntax Problems*\n",
    "\n",
    "Отличие - матрицы для каждого слова контекста учатся свои. Это хорошо на больших корпусах, но на нашем маленьком зайдет не слишком хорошо - многовато параметров придется выучить.\n",
    "\n",
    "Идея этого в том, что порядок слов в предложении очень важен (особенно в английском, на котором они как всегда тестируются). Задавая порядок, они лучше учатся синтаксису.\n",
    "\n",
    "Почитайте статью и попробуйте реализовать один из них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqDmuu7m_PB5"
   },
   "source": [
    "# Дополнительные материалы\n",
    "## Почитать\n",
    "### Блоги\n",
    "[On word embeddings - Part 1, Sebastian Ruder](http://ruder.io/word-embeddings-1/)  \n",
    "[On word embeddings - Part 2: Approximating the Softmax, Sebastian Ruder](http://ruder.io/word-embeddings-softmax/index.html)  \n",
    "[Word2Vec Tutorial - The Skip-Gram Model, Chris McCormick](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)  \n",
    "[Word2Vec Tutorial Part 2 - Negative Sampling, Chris McCormick](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/) \n",
    "\n",
    "### Статьи\n",
    "[Word2vec Parameter Learning Explained (2014), Xin Rong](https://arxiv.org/abs/1411.2738)  \n",
    "[Neural word embedding as implicit matrix factorization (2014), Levy, Omer, and Yoav Goldberg](http://u.cs.biu.ac.il/~nlp/wp-content/uploads/Neural-Word-Embeddings-as-Implicit-Matrix-Factorization-NIPS-2014.pdf)  \n",
    "\n",
    "### Улучшение эмбеддингов\n",
    "[Two/Too Simple Adaptations of Word2Vec for Syntax Problems (2015), Ling, Wang, et al.](https://www.aclweb.org/anthology/N/N15/N15-1142.pdf)  \n",
    "[Not All Neural Embeddings are Born Equal (2014)](https://arxiv.org/pdf/1410.0718.pdf)  \n",
    "[Retrofitting Word Vectors to Semantic Lexicons (2014), M. Faruqui, et al.](https://arxiv.org/pdf/1411.4166.pdf)  \n",
    "[All-but-the-top: Simple and Effective Postprocessing for Word Representations (2017), Mu, et al.](https://arxiv.org/pdf/1702.01417.pdf)  \n",
    "\n",
    "### Эмбеддинги предложений\n",
    "[Skip-Thought Vectors (2015), Kiros, et al.](https://arxiv.org/pdf/1506.06726)  \n",
    "\n",
    "### Backpropagation\n",
    "[Backpropagation, Intuitions, cs231n + next parts in the Module 1](http://cs231n.github.io/optimization-2/)   \n",
    "[Calculus on Computational Graphs: Backpropagation, Christopher Olah](http://colah.github.io/posts/2015-08-Backprop/)\n",
    "\n",
    "## Посмотреть\n",
    "[cs224n \"Lecture 2 - Word Vector Representations: word2vec\"](https://www.youtube.com/watch?v=ERibwqs9p38&index=2&list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja&t=0s)  \n",
    "[cs224n \"Lecture 5 - Backpropagation\"](https://www.youtube.com/watch?v=isPiE-DBagM&index=5&list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja&t=0s)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aM9C1i3Y-6kv"
   },
   "source": [
    "# Сдача задания\n",
    "\n",
    "[Сдача](https://goo.gl/forms/rzWjQQsGpqYNz5yt1)  \n",
    "[Опрос](https://goo.gl/forms/as640TWE058bFTpy2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 03 - Word Embeddings (Part 2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
