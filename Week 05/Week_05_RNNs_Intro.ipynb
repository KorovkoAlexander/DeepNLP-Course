{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfeVtEQwRmsR"
   },
   "outputs": [],
   "source": [
    "#!pip3 -qq install torch==0.4.1\n",
    "#!pip install -qq bokeh==0.13.0\n",
    "!wget -O surnames.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ji7dhr9FojPeV51dDlKRERIqr3vdZfhu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKoTq9xW-PdW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Q5wMjxQMeQS"
   },
   "source": [
    "# Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NY5-j_RsRzxa"
   },
   "source": [
    "## Классификация фамилий\n",
    "\n",
    "Теперь - по языкам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPPJoWEpSN_B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mikhnev Russian\n",
      "Morcos Arabic\n",
      "Morrow English\n",
      "Berezinsky Russian\n",
      "Badyaev Russian\n",
      "Teale English\n",
      "Prigorodov Russian\n",
      "Greening English\n",
      "Jankevich Russian\n",
      "Bahin Russian\n"
     ]
    }
   ],
   "source": [
    "data, labels = [], []\n",
    "with open('surnames.txt') as f:\n",
    "    for line in f:\n",
    "        surname, lang = line.strip().split('\\t')\n",
    "        data.append(surname)\n",
    "        labels.append(lang)\n",
    "\n",
    "for i in np.random.randint(0, len(data), 10):\n",
    "    print(data[i], labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6bVJlxzYhWuf"
   },
   "source": [
    "### Разминка\n",
    "\n",
    "Проверьте свои знания - попробуйте самостоятельно предсказать, к какому языку относится фамилия :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7JquuckaAGb"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def test_generator():\n",
    "    classes = np.unique(labels)\n",
    "    weights = compute_class_weight('balanced', classes, labels)\n",
    "    classes = {label: ind for ind, label in enumerate(classes)}\n",
    "\n",
    "    probs = np.array([weights[classes[label]] for label in labels])\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    ind = np.random.choice(np.arange(len(data)), p=probs)\n",
    "    yield data[ind]\n",
    "    \n",
    "    while True:\n",
    "        new_ind = np.random.choice(np.arange(len(data)), p=probs)\n",
    "        yield labels[ind], data[new_ind]\n",
    "        ind = new_ind\n",
    "        \n",
    "gen = test_generator()\n",
    "question = next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KNeNxm1hsKs"
   },
   "source": [
    "Запускайте, смотрите на фамилию, которая выведется - и выбирайте язык в выпадающем списке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "-Q3OSXpAY8BS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, it's Korean (0 / 1)\n",
      "Next surname: Bao\n"
     ]
    }
   ],
   "source": [
    "#@title Проверим себя (или адекватность данных) { run: \"auto\" }\n",
    "answer = \"Vietnamese\" #@param [\"Arabic\", \"Chinese\", \"Czech\", \"Dutch\", \"English\", \"French\", \"German\", \"Greek\", \"Irish\", \"Italian\", \"Japanese\", \"Korean\", \"Polish\", \"Portuguese\", \"Russian\", \"Scottish\", \"Spanish\", \"Vietnamese\"]\n",
    "\n",
    "correct_answer, question = next(gen)\n",
    "\n",
    "if 'correct_count' not in globals():\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "else:\n",
    "    if answer == correct_answer:\n",
    "        print('You are correct', end=' ')\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        print(\"No, it's\", correct_answer, end=' ')\n",
    "\n",
    "    total_count += 1\n",
    "    print('({} / {})'.format(correct_count, total_count))\n",
    "    \n",
    "print('Next surname:', question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Yz20u6dhll0"
   },
   "source": [
    "### Разбиение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LfP4Sb68TWlY"
   },
   "source": [
    "Для начала нужно построить сплит данных на трейн/тест. Сложность в том, что классы распределены неравномерны, а отрезать нужно от каждого класса пропорциональное количество данных на тест. Для этого нужно использовать `stratify` параметр функции `train_test_split` (либо `StratifiedShuffleSplit`, либо, при большом желании, `GroupShuffleSplit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1eE-s7q7RmAM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(\n",
    "    data, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uzX5zHobUHc0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "langs = set(labels)\n",
    "\n",
    "train_distribution = Counter(labels_train)\n",
    "train_distribution = [train_distribution[lang] for lang in langs]\n",
    "\n",
    "test_distribution = Counter(labels_test)\n",
    "test_distribution = [test_distribution[lang] for lang in langs]\n",
    "\n",
    "plt.figure(figsize=(17, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(langs)), train_distribution, bar_width, align='center', alpha=0.5, label='train')\n",
    "plt.bar(np.arange(len(langs)) + bar_width, test_distribution, bar_width, align='center', alpha=0.5, label='test')\n",
    "plt.xticks(np.arange(len(langs)) + bar_width / 2, langs)\n",
    "plt.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgmDagAq5-mm"
   },
   "source": [
    "### Бейзлайн"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDgB4iVCWbNE"
   },
   "source": [
    "Всегда надо начинать с бейзлайна - воспользуемся нашей любимой парой vectorizer-logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLxUE4thXyV2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
       "       ...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer='char', ngram_range=(1, 4))),\n",
    "    ('log_regression', LogisticRegression())\n",
    "])\n",
    "\n",
    "model.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wz9ngs_lWn3p"
   },
   "source": [
    "Какие метрики будем считать? Тут многоклассовая классификация, поэтому всё очень неоднозначно.\n",
    "\n",
    "Имеет смысл посмотреть на accuracy и на F1-score'ы для каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJZt8sKM6zEA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 83.45%\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       0.90      1.00      0.95       600\n",
      "     Chinese       0.65      0.57      0.61        80\n",
      "       Czech       0.58      0.28      0.38       156\n",
      "       Dutch       0.85      0.49      0.62        89\n",
      "     English       0.72      0.84      0.78      1101\n",
      "      French       0.52      0.19      0.28        83\n",
      "      German       0.61      0.51      0.55       217\n",
      "       Greek       0.93      0.64      0.76        61\n",
      "       Irish       0.65      0.44      0.53        70\n",
      "     Italian       0.74      0.72      0.73       213\n",
      "    Japanese       0.91      0.90      0.90       297\n",
      "      Korean       0.25      0.14      0.18        28\n",
      "      Polish       0.61      0.33      0.43        42\n",
      "  Portuguese       0.27      0.14      0.18        22\n",
      "     Russian       0.92      0.96      0.94      2823\n",
      "    Scottish       0.00      0.00      0.00        30\n",
      "     Spanish       0.48      0.28      0.35        89\n",
      "  Vietnamese       0.50      0.18      0.27        22\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6023\n",
      "   macro avg       0.61      0.48      0.52      6023\n",
      "weighted avg       0.82      0.83      0.82      6023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "preds = model.predict(data_test)\n",
    "\n",
    "print('Accuracy = {:.2%}'.format(accuracy_score(labels_test, preds)))\n",
    "print('Classification report:')\n",
    "print(classification_report(labels_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VNRhUTNaW45M"
   },
   "source": [
    "F1-score'ы можно агрегировать разными способами:\n",
    "- weighted - это как посчитал classification_report - если нам важнее предсказывать хорошо более частотные фамилии\n",
    "- macro - простое усреднение - если важно предсказывать все, независимо от того, сколько каждого класса в тестовой выборке\n",
    "- micro - обычный подсчет F1-score по суммам всех true positive, false positive и false negative\n",
    "\n",
    "Weighted и micro - две метрики, учитывающие дисбаланс классов. Но в нашем случае неочевидно, есть ли дисбаланс, да?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0SwCbWN8ZQd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "label_names = list(set(labels_test))\n",
    "confusion = confusion_matrix(labels_test, preds, labels=label_names).astype(np.float)\n",
    "confusion /= confusion.sum(axis=-1, keepdims=True)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion, cmap='Reds')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels([''] + label_names, rotation=45)\n",
    "ax.set_yticklabels([''] + label_names)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qo0lsnzV-i-P"
   },
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hb4_VaBIMVFD"
   },
   "source": [
    "Основная прелесть RNN - расшаренные параметры. Посмотрите на картинку:\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg \" \")\n",
    "\n",
    "*From [(The Unreasonable Effectiveness of Recurrent Neural Networks)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Первый пример - это обычная полносвязная сеть. Каждый следующий демонстрирует обработку некоторой последовательности произвольной длины (красные прямоугольнички) и генерацию выходной последовательности, также произвольной длины (синие прямоугольники).\n",
    "\n",
    "При этом зеленые прямоугольники в каждом рисунке - это одни и те же веса. Получается, мы, с одной стороны, обучаем очень-очень глубокую сеть (если посмотреть на неё перевернутую), а с другой - строго ограниченное количество параметров.\n",
    "\n",
    "---\n",
    "Напишем сразу простую RNN!\n",
    "\n",
    "Напомню, делает она примерно вот это:\n",
    "\n",
    "![rnn-unrolled](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png \" \")\n",
    "\n",
    "*From [(Understanding LSTM Networks)](http://colah.github.io/posts/2015-08-Understanding-LSTMs)*\n",
    "\n",
    "Вообще говоря, можно придумать много вариаций на тему такой реализации. В нашем случае, обработка будет такой:\n",
    "$$h_t = tanh(W_h [h_{t-1}; x_t] + b_h)$$\n",
    "\n",
    "$h_{t-1}$ - скрытое состояние, полученное на предыдущем шаге, $x_t$ - входной вектор. $[h_{t-1}; x_t]$ - простая конкатенация векторов. Всё как на картинке!\n",
    "\n",
    "Проверим нашу сеть на очень простой задаче: заставим её говорить индекс первого элемента в последовательности.\n",
    "\n",
    "Т.е. для последовательности `[1, 2, 1, 3]` сеть должна предсказывать `1`.\n",
    "\n",
    "Начнем с генерации батча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOI4JGgHT-z3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 8, 9, 1, 1, 8, 5, 5, 5, 5, 1, 9, 8, 7, 2, 1, 1, 1, 1, 8, 9, 8, 3, 1,\n",
       "          3, 1, 1, 3, 7, 7, 6, 6, 5, 4, 0, 9, 9, 6, 3, 7, 5, 6, 6, 5, 0, 6, 5, 5,\n",
       "          7, 3, 8, 6, 7, 4, 5, 1, 7, 8, 6, 0, 2, 0, 6, 5, 5, 2, 6, 2, 6, 9, 9, 8,\n",
       "          7, 4, 6, 1, 1, 2, 0, 4, 3, 1, 2, 4, 9, 3, 0, 4, 1, 7, 5, 6, 2, 3, 8, 0,\n",
       "          4, 0, 8, 3, 9, 4, 6, 9, 6, 2, 1, 7, 0, 1, 3, 0, 8, 8, 0, 4, 5, 7, 4, 2,\n",
       "          2, 4, 7, 4, 0, 1, 8, 3],\n",
       "         [3, 2, 3, 9, 2, 1, 0, 9, 0, 7, 9, 3, 3, 5, 5, 5, 9, 5, 5, 6, 3, 4, 7, 0,\n",
       "          6, 7, 8, 4, 6, 3, 5, 1, 3, 4, 6, 9, 6, 6, 9, 0, 5, 0, 0, 5, 8, 7, 1, 0,\n",
       "          0, 9, 4, 2, 7, 5, 6, 8, 7, 1, 7, 0, 5, 0, 9, 1, 5, 6, 5, 4, 9, 8, 9, 8,\n",
       "          3, 8, 1, 0, 6, 4, 2, 8, 5, 4, 0, 1, 7, 5, 9, 3, 2, 3, 1, 8, 5, 9, 8, 1,\n",
       "          1, 7, 1, 5, 2, 1, 6, 0, 5, 0, 1, 0, 5, 9, 3, 4, 5, 8, 2, 9, 5, 4, 2, 2,\n",
       "          9, 2, 5, 0, 0, 2, 8, 1],\n",
       "         [5, 2, 7, 8, 4, 5, 2, 3, 4, 5, 5, 8, 2, 1, 4, 1, 9, 8, 2, 7, 4, 3, 6, 0,\n",
       "          6, 0, 5, 8, 1, 2, 7, 0, 0, 0, 5, 3, 9, 1, 8, 7, 3, 8, 3, 9, 2, 0, 9, 4,\n",
       "          7, 4, 4, 6, 3, 1, 4, 8, 9, 0, 9, 0, 9, 5, 1, 0, 1, 6, 9, 9, 0, 0, 3, 9,\n",
       "          0, 9, 1, 8, 5, 5, 3, 5, 0, 7, 7, 0, 5, 1, 6, 9, 9, 5, 1, 1, 6, 5, 1, 2,\n",
       "          2, 3, 3, 8, 0, 4, 6, 9, 7, 5, 9, 0, 8, 9, 0, 4, 7, 9, 7, 4, 4, 1, 6, 9,\n",
       "          3, 4, 3, 8, 2, 7, 9, 0],\n",
       "         [0, 0, 4, 8, 0, 2, 9, 5, 8, 0, 8, 0, 8, 4, 4, 9, 1, 2, 1, 2, 8, 2, 1, 7,\n",
       "          7, 3, 8, 7, 3, 9, 1, 9, 8, 3, 3, 0, 2, 8, 5, 6, 1, 2, 0, 0, 3, 9, 3, 1,\n",
       "          0, 8, 8, 2, 1, 5, 0, 0, 5, 3, 5, 8, 5, 3, 1, 0, 4, 4, 4, 4, 2, 8, 3, 4,\n",
       "          3, 0, 5, 6, 3, 1, 1, 2, 8, 8, 8, 4, 3, 6, 6, 4, 8, 0, 3, 6, 6, 4, 9, 7,\n",
       "          1, 2, 1, 7, 0, 3, 1, 1, 4, 3, 0, 6, 2, 7, 0, 3, 2, 7, 0, 2, 0, 9, 1, 1,\n",
       "          5, 9, 9, 4, 6, 6, 7, 5],\n",
       "         [4, 2, 3, 2, 5, 3, 3, 5, 2, 7, 5, 5, 2, 2, 6, 6, 7, 6, 0, 5, 2, 8, 9, 4,\n",
       "          2, 0, 1, 7, 0, 4, 6, 3, 0, 9, 4, 9, 2, 7, 6, 5, 6, 0, 9, 1, 9, 9, 2, 7,\n",
       "          4, 2, 0, 1, 4, 4, 3, 1, 2, 8, 9, 6, 4, 6, 4, 3, 2, 4, 6, 6, 2, 4, 2, 3,\n",
       "          9, 4, 2, 7, 1, 8, 2, 6, 7, 0, 1, 3, 7, 8, 0, 5, 5, 0, 5, 4, 2, 3, 0, 1,\n",
       "          4, 7, 3, 6, 8, 3, 7, 8, 0, 5, 0, 6, 3, 8, 4, 5, 2, 5, 5, 6, 2, 1, 2, 5,\n",
       "          4, 3, 3, 2, 3, 4, 0, 3]]),\n",
       " tensor([4, 8, 9, 1, 1, 8, 5, 5, 5, 5, 1, 9, 8, 7, 2, 1, 1, 1, 1, 8, 9, 8, 3, 1,\n",
       "         3, 1, 1, 3, 7, 7, 6, 6, 5, 4, 0, 9, 9, 6, 3, 7, 5, 6, 6, 5, 0, 6, 5, 5,\n",
       "         7, 3, 8, 6, 7, 4, 5, 1, 7, 8, 6, 0, 2, 0, 6, 5, 5, 2, 6, 2, 6, 9, 9, 8,\n",
       "         7, 4, 6, 1, 1, 2, 0, 4, 3, 1, 2, 4, 9, 3, 0, 4, 1, 7, 5, 6, 2, 3, 8, 0,\n",
       "         4, 0, 8, 3, 9, 4, 6, 9, 6, 2, 1, 7, 0, 1, 3, 0, 8, 8, 0, 4, 5, 7, 4, 2,\n",
       "         2, 4, 7, 4, 0, 1, 8, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_data(batch_size=128, seq_len=5):\n",
    "    data = torch.randint(0, 10, size=(seq_len, batch_size), dtype=torch.long)\n",
    "    return data, data[0]\n",
    "\n",
    "X_val, y_val = generate_data()\n",
    "X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQ0Gsr4SFNtB"
   },
   "source": [
    "Обратите внимание, что батч имеет размерность `(sequence_length, batch_size, input_size)`. Все `RNN` в pytorch работают с таким форматом по умолчанию.\n",
    "\n",
    "Сделано это из соображений производительности, но при желании можно поменять такое поведение с помощью аргумента `batch_first`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PqS7HPRhZSBC"
   },
   "source": [
    "**Задание** Реализуйте класс `SimpleRNN`, выполняющий рассчеты по формуле выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ed1b2TUvZRs0"
   },
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self._hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size +  hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        seq_len, batch_size = inputs.shape[:2]\n",
    "        if hidden is None:\n",
    "            hidden = inputs.new_zeros((batch_size, self._hidden_size))\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            x = torch.cat([hidden, inputs[i]], dim = 1)\n",
    "            hidden = F.relu(self.linear(x))\n",
    "            #<apply linear layer to concatenation of current input (inputs[i]) and hidden>\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KS2xw2YIZ_EU"
   },
   "source": [
    "Должно стать понятно, почему полезно иметь первой размерностью seq_len - нужно уметь брать `inputs[i]` - подбатч, относящийся к данному таймстемпу. Если бы данные были расположены по-другому, эта операция была бы сильно дороже.\n",
    "\n",
    "**Задание** Реализуйте класс `MemorizerModel`, с последовательностью операций `Embedding -> SimpleRNN -> Linear`. Можно использовать `nn.Sequential`\n",
    "\n",
    "Чтобы сделать эмбеддинги, можно воспользоваться `nn.Embedding.from_pretrained`. Для простоты будем делать one-hot-encoding представление - для этого нужно просто инициализировать сеть единичной матрицей `torch.eye(N)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aEUr4Xa9Z81I"
   },
   "outputs": [],
   "source": [
    "# u can use nn.Sequential too\n",
    "class MemorizerModel(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Embedding.from_pretrained(torch.eye(40)),\n",
    "            SimpleRNN(40, hidden_size),\n",
    "            nn.Linear(hidden_size, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.seq(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiDRoQWDawaW"
   },
   "source": [
    "Запустим обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbVk7zUjUQ_v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/1000] Train: 3.381 Val: 2.966\n",
      "[200/1000] Train: 2.310 Val: 2.934\n",
      "[300/1000] Train: 2.305 Val: 2.873\n",
      "[400/1000] Train: 2.292 Val: 2.858\n",
      "[500/1000] Train: 2.207 Val: 3.029\n",
      "[600/1000] Train: 1.947 Val: 3.173\n",
      "[700/1000] Train: 1.504 Val: 3.099\n",
      "[800/1000] Train: 0.681 Val: 3.464\n",
      "[900/1000] Train: 0.190 Val: 3.873\n",
      "[1000/1000] Train: 0.355 Val: 3.349\n"
     ]
    }
   ],
   "source": [
    "rnn = MemorizerModel(hidden_size=32)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters())\n",
    "\n",
    "total_loss = 0\n",
    "epochs_count = 1000\n",
    "for epoch_ind in range(epochs_count):\n",
    "    X_train, y_train = generate_data(seq_len=10)\n",
    "    optimizer.zero_grad()\n",
    "    rnn.train()\n",
    "    \n",
    "    logits = rnn(X_train)\n",
    "\n",
    "    loss = criterion(logits, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    if (epoch_ind + 1) % 100 == 0:\n",
    "        rnn.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = rnn(X_val)\n",
    "            val_loss = criterion(logits, y_val)\n",
    "            print('[{}/{}] Train: {:.3f} Val: {:.3f}'.format(epoch_ind + 1, epochs_count, \n",
    "                                                             total_loss / 100, val_loss.item()))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQJg3FROIq4v"
   },
   "source": [
    "**Задание** Посмотрите на то, как влияет длина последовательности на работу сети. \n",
    "\n",
    "Во-первых, посмотрите, с какой длиной сеть в состоянии учиться. Во-вторых, попробуйте обучить сеть с небольшой длиной последовательности, а потом применять её к более длинным.\n",
    "\n",
    "**Задание** Утверждается, что `relu` подходит для RNN лучше. Попробуйте и её."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSHNuT5b61Ky"
   },
   "source": [
    "## Обучение RNN'ок\n",
    "\n",
    "![bptt](https://image.ibb.co/cEYkw9/rnn_bptt_with_gradients.png \" \")  \n",
    "*From [Recurrent Neural Networks Tutorial, Part 3 – Backpropagation Through Time and Vanishing Gradients](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/)*\n",
    "\n",
    "Если всё пошло по плану, мы должны были посмотреть на то, как RNN'ки забывают. \n",
    "\n",
    "Чтобы понять причину, стоит вспомнить, как именно происходит обучение RNN, например, здесь: [Backpropagation Through Time and Vanishing Gradients](http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/ \" \") или здесь - [Vanishing Gradients & LSTMs](http://harinisuresh.com/2016/10/09/lstms/).\n",
    "\n",
    "Если кратко, одна из проблем обучения рекуррентных сетей - *взрыв градиентов*. Она проявляется, когда матрица весов такова, что увеличивает норму вектора градиента при обратном проходе. В результате норма градиента экспоненциально растет и он \"взрывается\". \n",
    "\n",
    "Эту проблему можно решить с помощью клипинга градиентов: `nn.utils.clip_grad_norm_(rnn.parameters(), 1.)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13x5erUgTjDC"
   },
   "source": [
    "## LSTM и GRU\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAjZh9YkYAMH"
   },
   "source": [
    "\n",
    "\n",
    "Другая проблема - *затухание градиентов*. Она связана наоборот - с экспоненциальным затуханием градиентов. И вот её решают уже более сложными способами. \n",
    "\n",
    "А именно - используют gate'овые архитектуры.\n",
    "\n",
    "Идея gate'а простая, но важная, используются они далеко не только в рекуррентных сетях.\n",
    "\n",
    "Если посмотреть на то, как работает наша SimpleRNN, можно заметить, что каждый раз память (т.е. $h_t$) перезаписывается. Хочется иметь возможность сделать эту перезапись контролируемой: не отбрасывать какую-то важную инфомацию из вектора.\n",
    "\n",
    "Заведем для этого вектор $g \\in \\{0,1\\}^n$, который будет говорить, какие ячейки $h_{t-1}$ хорошие, а вместо каких стоит подставить новые значения:\n",
    "$$h_t = g \\odot f(x_t, h_{t-1}) + (1 - g) \\odot h_{t-1}.$$\n",
    "\n",
    "Например:\n",
    "$$\n",
    " \\begin{bmatrix}\n",
    "  8 \\\\\n",
    "  11 \\\\\n",
    "  3 \\\\\n",
    "  7\n",
    " \\end{bmatrix} =\n",
    " \\begin{bmatrix}\n",
    "  0 \\\\\n",
    "  1 \\\\\n",
    "  0 \\\\\n",
    "  0\n",
    " \\end{bmatrix}\n",
    " \\odot\n",
    "  \\begin{bmatrix}\n",
    "  7 \\\\\n",
    "  11 \\\\\n",
    "  6 \\\\\n",
    "  5\n",
    " \\end{bmatrix}\n",
    " +\n",
    "  \\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  0 \\\\\n",
    "  1 \\\\\n",
    "  1\n",
    " \\end{bmatrix}\n",
    " \\odot\n",
    "  \\begin{bmatrix}\n",
    "  8 \\\\\n",
    "  5 \\\\\n",
    "  3 \\\\\n",
    "  7\n",
    " \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Чтобы добиться дифференцируемости, будем использовать сигмоиду: $\\sigma(f(x_t, h_{t-1}))$.\n",
    "\n",
    "В результате сеть будет сама, глядя на входы, решать, какие ячейки своей памяти и насколько стоит перезаписывать.\n",
    "\n",
    "### LSTM\n",
    "\n",
    "Кажется, первой архитектурой, применившей данной механизм, стал LSTM (Long Short-Term Memory).\n",
    "\n",
    "В ней у нас к $h_{t-1}$ добавляется ещё и $c_{t-1}$: $h_{t-1}$ - это всё то же скрытое состояния полученное на предыдущем шаге, а $c_{t-1}$ - это вектор памяти.\n",
    "\n",
    "Схематично - как-то так:\n",
    "![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png \" \")  \n",
    "*From [(Understanding LSTM Networks)](http://colah.github.io/posts/2015-08-Understanding-LSTMs)*\n",
    "\n",
    "\n",
    "Для начала мы можем точно так же, как и раньше посчитать новое скрытое состояние (обозначим его $\\tilde c_{t}$):\n",
    "$$\\tilde c_{t} = tanh(W_h [h_{t-1}; x_t] + b_h)$$\n",
    "\n",
    "В обычных RNN мы бы просто перезаписали этим значением сторое скрытое состояние. А теперь мы хотим понять, насколько нам нужна информация из $c_{t-1}$ и из $\\tilde c_{t}$. \n",
    "\n",
    "Оценим её сигмоидами:\n",
    "$$f = \\sigma(W_f [h_{t-1}; x_t] + b_f),$$\n",
    "$$i = \\sigma(W_i [h_{t-1}; x_t] + b_i).$$\n",
    "\n",
    "Первая - про то, насколько хочется забыть старую информацию. Вторая - насколько интересна новая. Тогда\n",
    "$$c_t = f \\odot c_{t-1} + i \\odot \\tilde c_t.$$\n",
    "\n",
    "Новое скрытое состояние мы также взвесим:\n",
    "$$o = \\sigma(W_o [h_{t-1}; x_t] + b_o),$$\n",
    "$$h_t = o \\odot tanh(c_t).$$\n",
    "\n",
    "Еще одна картинка:\n",
    "![](https://image.ibb.co/e6HQUU/details.png)  \n",
    "*From [Vanishing Gradients & LSTMs](http://harinisuresh.com/2016/10/09/lstms/)*\n",
    "\n",
    "Почему проблема затухающих градиентов решается? Потому что посмотрите на производную $\\frac{\\partial c_t}{\\partial c_{t-1}}$. Она пропорциональна гейту $f$. Если $f=1$ - градиенты текут без изменений. Иначе - ну, сеть сама учится, когда ей хочется что-то забыть.\n",
    "\n",
    "Настоятельно рекомендуется почитать статью: [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) для более подробного ознакомления и прикольных картинок.\n",
    "\n",
    "Зачем я выписал эти формулы? Главное - чтобы показать, насколько больше параметров нужно учить в LSTM по сравнению с обычным RNN. В четыре раза больше!\n",
    "\n",
    "Для тех, кто заснул - [видео, как забывает RNN (нижняя часть)](https://www.youtube.com/watch?v=mLxsbWAYIpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_9KWgbwQMatn"
   },
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q7-fQPwJUKtV"
   },
   "outputs": [],
   "source": [
    "symbols = set(symb for word in data_train for symb in word)\n",
    "char2ind = {symb: ind + 1 for ind, symb in enumerate(symbols)}\n",
    "char2ind[''] = 0\n",
    "\n",
    "lang2ind = {lang: ind for ind, lang in enumerate(set(labels_train))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcFgEy7YeFw0"
   },
   "source": [
    "Сконвертируем датасет.\n",
    "\n",
    "**Задание** Напишите генератор батчей, который будет на лету выбирать случайный набор слов и конвертировать их в матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(data, labels, char2ind, lang2ind, batch_size):\n",
    "    # let's do the conversion part first\n",
    "    labels = np.array([lang2ind[label] for label in labels])\n",
    "    data = [[char2ind.get(symb, 0) for symb in word] for word in data]\n",
    "    \n",
    "    indices = np.arange(len(data))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, len(data), batch_size):\n",
    "        end = min(start + batch_size, len(data))\n",
    "        \n",
    "        batch_indices = indices[start: end]\n",
    "        \n",
    "        max_word_len = max(len(data[ind]) for ind in batch_indices)\n",
    "        X = np.zeros((max_word_len, len(batch_indices)))\n",
    "        for i, bi in enumerate(batch_indices):\n",
    "            word = data[bi]\n",
    "            for j, c in enumerate(word):\n",
    "                if j < max_word_len:\n",
    "                    X[j,i] = c\n",
    "        \n",
    "            \n",
    "        yield X, labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfeR4B_hbH9P"
   },
   "source": [
    "Лень передавать `char2ind, lang2ind`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uA-_jRNdaCM3"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "iterate_batches = partial(iterate_batches, char2ind=char2ind, lang2ind=lang2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HD5i7WmTVlGk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[50., 71., 71., 69., 46., 36., 56., 35.],\n",
       "        [74., 30., 77., 70., 79., 70., 74., 70.],\n",
       "        [85., 74.,  2., 67., 79., 79., 17., 39.],\n",
       "        [73.,  2., 26., 67., 70., 85., 26.,  3.],\n",
       "        [70., 17., 67.,  0., 38., 26., 80., 85.],\n",
       "        [ 0.,  0., 57.,  0., 29., 85., 26., 79.],\n",
       "        [ 0.,  0., 70.,  0.,  0.,  0.,  0., 30.],\n",
       "        [ 0.,  0., 38.,  0.,  0.,  0.,  0., 70.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 70.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 80.]]),\n",
       " array([13,  9, 16,  9,  4,  3,  4,  3]))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterate_batches(data, labels, batch_size=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnkAUetgs6Tr"
   },
   "source": [
    "**Задание** Реализуйте простую модель на `SimpleRNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zk3OSidVS_px"
   },
   "outputs": [],
   "source": [
    "class SurnamesClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_hidden_dim, classes_count):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = SimpleRNN(emb_dim, lstm_hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim, classes_count)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        x = self.embed(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x = self.rnn(x)\n",
    "        return self.lin(x)\n",
    "    \n",
    "    def embed(self, inputs):\n",
    "        return self.embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vXN-QIrZs95"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None):  \n",
    "    epoch_loss = 0.\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    model.train(is_train)\n",
    "    \n",
    "    data, labels = data\n",
    "    batchs_count = math.ceil(len(data) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        for i, (X_batch, y_batch) in enumerate(iterate_batches(data, labels, batch_size=batch_size)):\n",
    "            X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "                optimizer.step()\n",
    "\n",
    "            print('\\r[{} / {}]: Loss = {:.4f}'.format(i, batchs_count, loss.item()), end='')\n",
    "                \n",
    "    return epoch_loss / batchs_count\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, \n",
    "        batch_size=32, val_data=None, val_batch_size=None):\n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        start_time = time.time()\n",
    "        train_loss = do_epoch(model, criterion, train_data, batch_size, optimizer)\n",
    "        \n",
    "        output_info = '\\rEpoch {} / {}, Epoch Time = {:.2f}s: Train Loss = {:.4f}'\n",
    "        if not val_data is None:\n",
    "            val_loss = do_epoch(model, criterion, val_data, val_batch_size, None)\n",
    "            \n",
    "            epoch_time = time.time() - start_time\n",
    "            output_info += ', Val Loss = {:.4f}'\n",
    "            print(output_info.format(epoch+1, epochs_count, epoch_time, train_loss, val_loss))\n",
    "        else:\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(output_info.format(epoch+1, epochs_count, epoch_time, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9vBDF2gbypR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 300, Epoch Time = 0.75s: Train Loss = 1.9860, Val Loss = 1.6616\n",
      "Epoch 2 / 300, Epoch Time = 0.76s: Train Loss = 1.6365, Val Loss = 1.6408\n",
      "Epoch 3 / 300, Epoch Time = 0.72s: Train Loss = 1.5519, Val Loss = 1.7229\n",
      "Epoch 4 / 300, Epoch Time = 0.75s: Train Loss = 1.5136, Val Loss = 1.4909\n",
      "Epoch 5 / 300, Epoch Time = 0.80s: Train Loss = 1.4814, Val Loss = 1.4366\n",
      "Epoch 6 / 300, Epoch Time = 0.76s: Train Loss = 1.4764, Val Loss = 1.4678\n",
      "Epoch 7 / 300, Epoch Time = 0.74s: Train Loss = 1.4473, Val Loss = 1.4493\n",
      "Epoch 8 / 300, Epoch Time = 0.75s: Train Loss = 1.4258, Val Loss = 1.4413\n",
      "Epoch 9 / 300, Epoch Time = 0.72s: Train Loss = 1.4223, Val Loss = 1.3678\n",
      "Epoch 10 / 300, Epoch Time = 0.79s: Train Loss = 1.3984, Val Loss = 1.4117\n",
      "Epoch 11 / 300, Epoch Time = 0.74s: Train Loss = 1.3750, Val Loss = 1.3325\n",
      "Epoch 12 / 300, Epoch Time = 0.75s: Train Loss = 1.3415, Val Loss = 1.3142\n",
      "Epoch 13 / 300, Epoch Time = 0.73s: Train Loss = 1.3148, Val Loss = 1.3281\n",
      "Epoch 14 / 300, Epoch Time = 0.74s: Train Loss = 1.3066, Val Loss = 1.2170\n",
      "Epoch 15 / 300, Epoch Time = 0.81s: Train Loss = 1.2814, Val Loss = 1.2226\n",
      "Epoch 16 / 300, Epoch Time = 0.73s: Train Loss = 1.2557, Val Loss = 1.2265\n",
      "Epoch 17 / 300, Epoch Time = 0.74s: Train Loss = 1.2350, Val Loss = 1.1626\n",
      "Epoch 18 / 300, Epoch Time = 0.75s: Train Loss = 1.2268, Val Loss = 1.1422\n",
      "Epoch 19 / 300, Epoch Time = 0.74s: Train Loss = 1.1972, Val Loss = 1.2250\n",
      "Epoch 20 / 300, Epoch Time = 0.81s: Train Loss = 1.1913, Val Loss = 1.1907\n",
      "Epoch 21 / 300, Epoch Time = 0.74s: Train Loss = 1.1804, Val Loss = 1.2076\n",
      "Epoch 22 / 300, Epoch Time = 0.76s: Train Loss = 1.1805, Val Loss = 1.2397\n",
      "Epoch 23 / 300, Epoch Time = 0.75s: Train Loss = 1.1593, Val Loss = 1.1242\n",
      "Epoch 24 / 300, Epoch Time = 0.80s: Train Loss = 1.1508, Val Loss = 1.1084\n",
      "Epoch 25 / 300, Epoch Time = 0.75s: Train Loss = 1.1380, Val Loss = 1.1573\n",
      "Epoch 26 / 300, Epoch Time = 0.75s: Train Loss = 1.1325, Val Loss = 1.0996\n",
      "Epoch 27 / 300, Epoch Time = 0.73s: Train Loss = 1.1231, Val Loss = 1.1732\n",
      "Epoch 28 / 300, Epoch Time = 0.75s: Train Loss = 1.1166, Val Loss = 1.1102\n",
      "Epoch 29 / 300, Epoch Time = 0.80s: Train Loss = 1.1004, Val Loss = 1.0683\n",
      "Epoch 30 / 300, Epoch Time = 0.75s: Train Loss = 1.0974, Val Loss = 1.0514\n",
      "Epoch 31 / 300, Epoch Time = 0.74s: Train Loss = 1.1001, Val Loss = 1.0521\n",
      "Epoch 32 / 300, Epoch Time = 0.74s: Train Loss = 1.0847, Val Loss = 1.0881\n",
      "Epoch 33 / 300, Epoch Time = 0.74s: Train Loss = 1.0746, Val Loss = 1.1614\n",
      "Epoch 34 / 300, Epoch Time = 0.79s: Train Loss = 1.0709, Val Loss = 1.0225\n",
      "Epoch 35 / 300, Epoch Time = 0.73s: Train Loss = 1.0524, Val Loss = 1.0916\n",
      "Epoch 36 / 300, Epoch Time = 0.75s: Train Loss = 1.0341, Val Loss = 1.0299\n",
      "Epoch 37 / 300, Epoch Time = 0.75s: Train Loss = 1.0405, Val Loss = 1.0117\n",
      "Epoch 38 / 300, Epoch Time = 0.76s: Train Loss = 1.0405, Val Loss = 0.9863\n",
      "Epoch 39 / 300, Epoch Time = 0.79s: Train Loss = 1.0294, Val Loss = 1.0145\n",
      "Epoch 40 / 300, Epoch Time = 0.75s: Train Loss = 1.0125, Val Loss = 1.0609\n",
      "Epoch 41 / 300, Epoch Time = 0.75s: Train Loss = 1.0153, Val Loss = 0.9748\n",
      "Epoch 42 / 300, Epoch Time = 0.74s: Train Loss = 1.0041, Val Loss = 0.9660\n",
      "Epoch 43 / 300, Epoch Time = 0.77s: Train Loss = 0.9894, Val Loss = 0.9945\n",
      "Epoch 44 / 300, Epoch Time = 0.74s: Train Loss = 0.9951, Val Loss = 1.0496\n",
      "Epoch 45 / 300, Epoch Time = 0.76s: Train Loss = 0.9931, Val Loss = 1.0027\n",
      "Epoch 46 / 300, Epoch Time = 0.75s: Train Loss = 0.9721, Val Loss = 0.9139\n",
      "Epoch 47 / 300, Epoch Time = 0.74s: Train Loss = 0.9743, Val Loss = 0.9367\n",
      "Epoch 48 / 300, Epoch Time = 0.80s: Train Loss = 0.9781, Val Loss = 0.9088\n",
      "Epoch 49 / 300, Epoch Time = 0.75s: Train Loss = 0.9600, Val Loss = 0.9727\n",
      "Epoch 50 / 300, Epoch Time = 0.75s: Train Loss = 0.9606, Val Loss = 0.8927\n",
      "Epoch 51 / 300, Epoch Time = 0.74s: Train Loss = 0.9460, Val Loss = 0.9158\n",
      "Epoch 52 / 300, Epoch Time = 0.75s: Train Loss = 0.9442, Val Loss = 0.9610\n",
      "Epoch 53 / 300, Epoch Time = 0.79s: Train Loss = 0.9399, Val Loss = 0.9521\n",
      "Epoch 54 / 300, Epoch Time = 0.74s: Train Loss = 0.9398, Val Loss = 0.9141\n",
      "Epoch 55 / 300, Epoch Time = 0.76s: Train Loss = 0.9402, Val Loss = 0.9775\n",
      "Epoch 56 / 300, Epoch Time = 0.74s: Train Loss = 0.9346, Val Loss = 0.9477\n",
      "Epoch 57 / 300, Epoch Time = 0.75s: Train Loss = 0.9243, Val Loss = 0.8958\n",
      "Epoch 58 / 300, Epoch Time = 0.80s: Train Loss = 0.9261, Val Loss = 0.8874\n",
      "Epoch 59 / 300, Epoch Time = 0.75s: Train Loss = 0.9359, Val Loss = 0.8904\n",
      "Epoch 60 / 300, Epoch Time = 0.75s: Train Loss = 0.9151, Val Loss = 0.9482\n",
      "Epoch 61 / 300, Epoch Time = 0.75s: Train Loss = 0.9060, Val Loss = 0.8800\n",
      "Epoch 62 / 300, Epoch Time = 0.80s: Train Loss = 0.9135, Val Loss = 0.8661\n",
      "Epoch 63 / 300, Epoch Time = 0.75s: Train Loss = 0.9059, Val Loss = 0.8847\n",
      "Epoch 64 / 300, Epoch Time = 0.75s: Train Loss = 0.9057, Val Loss = 0.8416\n",
      "Epoch 65 / 300, Epoch Time = 0.74s: Train Loss = 0.8925, Val Loss = 0.8542\n",
      "Epoch 66 / 300, Epoch Time = 0.75s: Train Loss = 0.8943, Val Loss = 0.9368\n",
      "Epoch 67 / 300, Epoch Time = 0.79s: Train Loss = 0.8979, Val Loss = 0.9168\n",
      "Epoch 68 / 300, Epoch Time = 0.76s: Train Loss = 0.8908, Val Loss = 0.9121\n",
      "Epoch 69 / 300, Epoch Time = 0.75s: Train Loss = 0.8977, Val Loss = 0.9979\n",
      "Epoch 70 / 300, Epoch Time = 0.75s: Train Loss = 0.8835, Val Loss = 0.8745\n",
      "Epoch 71 / 300, Epoch Time = 0.76s: Train Loss = 0.8930, Val Loss = 0.8417\n",
      "Epoch 72 / 300, Epoch Time = 0.80s: Train Loss = 0.8765, Val Loss = 0.8664\n",
      "Epoch 73 / 300, Epoch Time = 0.73s: Train Loss = 0.8753, Val Loss = 0.8114\n",
      "Epoch 74 / 300, Epoch Time = 0.75s: Train Loss = 0.8758, Val Loss = 0.8274\n",
      "Epoch 75 / 300, Epoch Time = 0.75s: Train Loss = 0.8651, Val Loss = 0.8534\n",
      "Epoch 76 / 300, Epoch Time = 0.75s: Train Loss = 0.8672, Val Loss = 0.8607\n",
      "Epoch 77 / 300, Epoch Time = 0.79s: Train Loss = 0.8559, Val Loss = 0.9138\n",
      "Epoch 78 / 300, Epoch Time = 0.70s: Train Loss = 0.8577, Val Loss = 0.9108\n",
      "Epoch 79 / 300, Epoch Time = 0.75s: Train Loss = 0.8614, Val Loss = 0.8265\n",
      "Epoch 80 / 300, Epoch Time = 0.75s: Train Loss = 0.8570, Val Loss = 0.8417\n",
      "Epoch 81 / 300, Epoch Time = 0.81s: Train Loss = 0.8509, Val Loss = 0.8307\n",
      "Epoch 82 / 300, Epoch Time = 0.75s: Train Loss = 0.8453, Val Loss = 0.8111\n",
      "Epoch 83 / 300, Epoch Time = 0.76s: Train Loss = 0.8452, Val Loss = 0.8901\n",
      "Epoch 84 / 300, Epoch Time = 0.75s: Train Loss = 0.8389, Val Loss = 0.8864\n",
      "Epoch 85 / 300, Epoch Time = 0.72s: Train Loss = 0.8382, Val Loss = 0.8230\n",
      "Epoch 86 / 300, Epoch Time = 0.79s: Train Loss = 0.8412, Val Loss = 0.8171\n",
      "Epoch 87 / 300, Epoch Time = 0.75s: Train Loss = 0.8335, Val Loss = 0.8067\n",
      "Epoch 88 / 300, Epoch Time = 0.74s: Train Loss = 0.8311, Val Loss = 0.8555\n",
      "Epoch 89 / 300, Epoch Time = 0.74s: Train Loss = 0.8333, Val Loss = 0.8296\n",
      "Epoch 90 / 300, Epoch Time = 0.76s: Train Loss = 0.8304, Val Loss = 0.8220\n",
      "Epoch 91 / 300, Epoch Time = 0.79s: Train Loss = 0.8325, Val Loss = 0.8101\n",
      "Epoch 92 / 300, Epoch Time = 0.75s: Train Loss = 0.8177, Val Loss = 0.8557\n",
      "Epoch 93 / 300, Epoch Time = 0.75s: Train Loss = 0.8355, Val Loss = 0.8624\n",
      "Epoch 94 / 300, Epoch Time = 0.75s: Train Loss = 0.8127, Val Loss = 0.7868\n",
      "Epoch 95 / 300, Epoch Time = 0.75s: Train Loss = 0.8312, Val Loss = 0.8153\n",
      "Epoch 96 / 300, Epoch Time = 0.80s: Train Loss = 0.8204, Val Loss = 0.8233\n",
      "Epoch 97 / 300, Epoch Time = 0.75s: Train Loss = 0.8265, Val Loss = 0.8607\n",
      "Epoch 98 / 300, Epoch Time = 0.74s: Train Loss = 0.8222, Val Loss = 0.8146\n",
      "Epoch 99 / 300, Epoch Time = 0.75s: Train Loss = 0.8144, Val Loss = 0.7868\n",
      "Epoch 100 / 300, Epoch Time = 0.81s: Train Loss = 0.8180, Val Loss = 0.7957\n",
      "Epoch 101 / 300, Epoch Time = 0.74s: Train Loss = 0.8144, Val Loss = 0.8477\n",
      "Epoch 102 / 300, Epoch Time = 0.75s: Train Loss = 0.8054, Val Loss = 0.7799\n",
      "Epoch 103 / 300, Epoch Time = 0.75s: Train Loss = 0.8104, Val Loss = 0.7739\n",
      "Epoch 104 / 300, Epoch Time = 0.74s: Train Loss = 0.8081, Val Loss = 0.8095\n",
      "Epoch 105 / 300, Epoch Time = 0.80s: Train Loss = 0.8038, Val Loss = 0.8169\n",
      "Epoch 106 / 300, Epoch Time = 0.74s: Train Loss = 0.7938, Val Loss = 0.8262\n",
      "Epoch 107 / 300, Epoch Time = 0.75s: Train Loss = 0.7947, Val Loss = 0.8711\n",
      "Epoch 108 / 300, Epoch Time = 0.76s: Train Loss = 0.8000, Val Loss = 0.8442\n",
      "Epoch 109 / 300, Epoch Time = 0.75s: Train Loss = 0.8011, Val Loss = 0.8144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 / 300, Epoch Time = 0.79s: Train Loss = 0.7969, Val Loss = 0.8338\n",
      "Epoch 111 / 300, Epoch Time = 0.74s: Train Loss = 0.7975, Val Loss = 0.7814\n",
      "Epoch 112 / 300, Epoch Time = 0.74s: Train Loss = 0.7943, Val Loss = 0.8040\n",
      "Epoch 113 / 300, Epoch Time = 0.75s: Train Loss = 0.7946, Val Loss = 0.7665\n",
      "Epoch 114 / 300, Epoch Time = 0.75s: Train Loss = 0.7862, Val Loss = 0.8153\n",
      "Epoch 115 / 300, Epoch Time = 0.80s: Train Loss = 0.7885, Val Loss = 0.8104\n",
      "Epoch 116 / 300, Epoch Time = 0.74s: Train Loss = 0.7830, Val Loss = 0.7932\n",
      "Epoch 117 / 300, Epoch Time = 0.70s: Train Loss = 0.7924, Val Loss = 0.8401\n",
      "Epoch 118 / 300, Epoch Time = 0.75s: Train Loss = 0.7890, Val Loss = 0.7753\n",
      "Epoch 119 / 300, Epoch Time = 0.79s: Train Loss = 0.7854, Val Loss = 0.8186\n",
      "Epoch 120 / 300, Epoch Time = 0.72s: Train Loss = 0.7842, Val Loss = 0.8227\n",
      "Epoch 121 / 300, Epoch Time = 0.74s: Train Loss = 0.7842, Val Loss = 0.8163\n",
      "Epoch 122 / 300, Epoch Time = 0.74s: Train Loss = 0.7863, Val Loss = 0.7735\n",
      "Epoch 123 / 300, Epoch Time = 0.69s: Train Loss = 0.7772, Val Loss = 0.7526\n",
      "Epoch 124 / 300, Epoch Time = 0.79s: Train Loss = 0.7738, Val Loss = 0.8084\n",
      "Epoch 125 / 300, Epoch Time = 0.74s: Train Loss = 0.7801, Val Loss = 0.7895\n",
      "Epoch 126 / 300, Epoch Time = 0.75s: Train Loss = 0.7729, Val Loss = 0.7693\n",
      "Epoch 127 / 300, Epoch Time = 0.73s: Train Loss = 0.7804, Val Loss = 0.8456\n",
      "Epoch 128 / 300, Epoch Time = 0.75s: Train Loss = 0.7771, Val Loss = 0.7902\n",
      "Epoch 129 / 300, Epoch Time = 0.80s: Train Loss = 0.7594, Val Loss = 0.7934\n",
      "Epoch 130 / 300, Epoch Time = 0.74s: Train Loss = 0.7723, Val Loss = 0.7929\n",
      "Epoch 131 / 300, Epoch Time = 0.69s: Train Loss = 0.7646, Val Loss = 0.7571\n",
      "Epoch 132 / 300, Epoch Time = 0.70s: Train Loss = 0.7615, Val Loss = 0.8084\n",
      "Epoch 133 / 300, Epoch Time = 0.70s: Train Loss = 0.7675, Val Loss = 0.7891\n",
      "Epoch 134 / 300, Epoch Time = 0.81s: Train Loss = 0.7612, Val Loss = 0.7816\n",
      "Epoch 135 / 300, Epoch Time = 0.75s: Train Loss = 0.7638, Val Loss = 0.7722\n",
      "Epoch 136 / 300, Epoch Time = 0.72s: Train Loss = 0.7607, Val Loss = 0.7645\n",
      "Epoch 137 / 300, Epoch Time = 0.75s: Train Loss = 0.7558, Val Loss = 0.7740\n",
      "Epoch 138 / 300, Epoch Time = 0.80s: Train Loss = 0.7604, Val Loss = 0.7755\n",
      "Epoch 139 / 300, Epoch Time = 0.66s: Train Loss = 0.7561, Val Loss = 0.7763\n",
      "Epoch 140 / 300, Epoch Time = 0.75s: Train Loss = 0.7627, Val Loss = 0.8688\n",
      "Epoch 141 / 300, Epoch Time = 0.75s: Train Loss = 0.7625, Val Loss = 0.7603\n",
      "Epoch 142 / 300, Epoch Time = 0.74s: Train Loss = 0.7579, Val Loss = 0.7606\n",
      "Epoch 143 / 300, Epoch Time = 0.79s: Train Loss = 0.7549, Val Loss = 0.7871\n",
      "Epoch 144 / 300, Epoch Time = 0.75s: Train Loss = 0.7553, Val Loss = 0.7636\n",
      "Epoch 145 / 300, Epoch Time = 0.71s: Train Loss = 0.7436, Val Loss = 0.7673\n",
      "Epoch 146 / 300, Epoch Time = 0.74s: Train Loss = 0.7503, Val Loss = 0.7808\n",
      "Epoch 147 / 300, Epoch Time = 0.74s: Train Loss = 0.7454, Val Loss = 0.7886\n",
      "Epoch 148 / 300, Epoch Time = 0.78s: Train Loss = 0.7549, Val Loss = 0.7392\n",
      "Epoch 149 / 300, Epoch Time = 0.75s: Train Loss = 0.7529, Val Loss = 0.7938\n",
      "Epoch 150 / 300, Epoch Time = 0.68s: Train Loss = 0.7403, Val Loss = 0.8235\n",
      "Epoch 151 / 300, Epoch Time = 0.75s: Train Loss = 0.7410, Val Loss = 0.7797\n",
      "Epoch 152 / 300, Epoch Time = 0.74s: Train Loss = 0.7451, Val Loss = 0.7772\n",
      "Epoch 153 / 300, Epoch Time = 0.80s: Train Loss = 0.7506, Val Loss = 0.7563\n",
      "Epoch 154 / 300, Epoch Time = 0.74s: Train Loss = 0.7381, Val Loss = 0.7615\n",
      "Epoch 155 / 300, Epoch Time = 0.71s: Train Loss = 0.7420, Val Loss = 0.7589\n",
      "Epoch 156 / 300, Epoch Time = 0.75s: Train Loss = 0.7425, Val Loss = 0.7694\n",
      "Epoch 157 / 300, Epoch Time = 0.77s: Train Loss = 0.7373, Val Loss = 0.7817\n",
      "Epoch 158 / 300, Epoch Time = 0.74s: Train Loss = 0.7477, Val Loss = 0.7750\n",
      "Epoch 159 / 300, Epoch Time = 0.72s: Train Loss = 0.7423, Val Loss = 0.7470\n",
      "Epoch 160 / 300, Epoch Time = 0.76s: Train Loss = 0.7377, Val Loss = 0.7783\n",
      "Epoch 161 / 300, Epoch Time = 0.75s: Train Loss = 0.7441, Val Loss = 0.7879\n",
      "Epoch 162 / 300, Epoch Time = 0.80s: Train Loss = 0.7370, Val Loss = 0.8506\n",
      "Epoch 163 / 300, Epoch Time = 0.73s: Train Loss = 0.7407, Val Loss = 0.7485\n",
      "Epoch 164 / 300, Epoch Time = 0.75s: Train Loss = 0.7292, Val Loss = 0.7471\n",
      "Epoch 165 / 300, Epoch Time = 0.75s: Train Loss = 0.7337, Val Loss = 0.7586\n",
      "Epoch 166 / 300, Epoch Time = 0.72s: Train Loss = 0.7335, Val Loss = 0.7946\n",
      "Epoch 167 / 300, Epoch Time = 0.81s: Train Loss = 0.7277, Val Loss = 0.7411\n",
      "Epoch 168 / 300, Epoch Time = 0.75s: Train Loss = 0.7400, Val Loss = 0.7859\n",
      "Epoch 169 / 300, Epoch Time = 0.72s: Train Loss = 0.7324, Val Loss = 0.8110\n",
      "Epoch 170 / 300, Epoch Time = 0.76s: Train Loss = 0.7340, Val Loss = 0.7347\n",
      "Epoch 171 / 300, Epoch Time = 0.74s: Train Loss = 0.7353, Val Loss = 0.8028\n",
      "Epoch 172 / 300, Epoch Time = 0.79s: Train Loss = 0.7230, Val Loss = 0.7660\n",
      "Epoch 173 / 300, Epoch Time = 0.74s: Train Loss = 0.7341, Val Loss = 0.7663\n",
      "Epoch 174 / 300, Epoch Time = 0.75s: Train Loss = 0.7314, Val Loss = 0.7567\n",
      "Epoch 175 / 300, Epoch Time = 0.74s: Train Loss = 0.7204, Val Loss = 0.7276\n",
      "Epoch 176 / 300, Epoch Time = 0.78s: Train Loss = 0.7320, Val Loss = 0.7414\n",
      "Epoch 177 / 300, Epoch Time = 0.71s: Train Loss = 0.7345, Val Loss = 0.7954\n",
      "Epoch 178 / 300, Epoch Time = 0.73s: Train Loss = 0.7208, Val Loss = 0.7289\n",
      "Epoch 179 / 300, Epoch Time = 0.74s: Train Loss = 0.7272, Val Loss = 0.7575\n",
      "Epoch 180 / 300, Epoch Time = 0.75s: Train Loss = 0.7253, Val Loss = 0.7517\n",
      "Epoch 181 / 300, Epoch Time = 0.78s: Train Loss = 0.7246, Val Loss = 0.7748\n",
      "Epoch 182 / 300, Epoch Time = 0.73s: Train Loss = 0.7150, Val Loss = 0.7369\n",
      "Epoch 183 / 300, Epoch Time = 0.74s: Train Loss = 0.7239, Val Loss = 0.7383\n",
      "Epoch 184 / 300, Epoch Time = 0.75s: Train Loss = 0.7194, Val Loss = 0.7669\n",
      "Epoch 185 / 300, Epoch Time = 0.75s: Train Loss = 0.7126, Val Loss = 0.7675\n",
      "Epoch 186 / 300, Epoch Time = 0.78s: Train Loss = 0.7185, Val Loss = 0.7350\n",
      "Epoch 187 / 300, Epoch Time = 0.74s: Train Loss = 0.7143, Val Loss = 0.7479\n",
      "Epoch 188 / 300, Epoch Time = 0.74s: Train Loss = 0.7182, Val Loss = 0.7789\n",
      "Epoch 189 / 300, Epoch Time = 0.70s: Train Loss = 0.7181, Val Loss = 0.7320\n",
      "Epoch 190 / 300, Epoch Time = 0.66s: Train Loss = 0.7142, Val Loss = 0.7796\n",
      "Epoch 191 / 300, Epoch Time = 0.72s: Train Loss = 0.7209, Val Loss = 0.7861\n",
      "Epoch 192 / 300, Epoch Time = 0.75s: Train Loss = 0.7067, Val Loss = 0.7867\n",
      "Epoch 193 / 300, Epoch Time = 0.73s: Train Loss = 0.7247, Val Loss = 0.7421\n",
      "Epoch 194 / 300, Epoch Time = 0.71s: Train Loss = 0.7004, Val Loss = 0.7467\n",
      "Epoch 195 / 300, Epoch Time = 0.81s: Train Loss = 0.7100, Val Loss = 0.7454\n",
      "Epoch 196 / 300, Epoch Time = 0.75s: Train Loss = 0.7125, Val Loss = 0.7662\n",
      "Epoch 197 / 300, Epoch Time = 0.75s: Train Loss = 0.7048, Val Loss = 0.7401\n",
      "Epoch 198 / 300, Epoch Time = 0.70s: Train Loss = 0.7067, Val Loss = 0.7511\n",
      "Epoch 199 / 300, Epoch Time = 0.66s: Train Loss = 0.7147, Val Loss = 0.7824\n",
      "Epoch 200 / 300, Epoch Time = 0.80s: Train Loss = 0.7074, Val Loss = 0.7368\n",
      "Epoch 201 / 300, Epoch Time = 0.75s: Train Loss = 0.7011, Val Loss = 0.7507\n",
      "Epoch 202 / 300, Epoch Time = 0.74s: Train Loss = 0.7014, Val Loss = 0.7325\n",
      "Epoch 203 / 300, Epoch Time = 0.74s: Train Loss = 0.7071, Val Loss = 0.7434\n",
      "Epoch 204 / 300, Epoch Time = 0.74s: Train Loss = 0.7021, Val Loss = 0.7543\n",
      "Epoch 205 / 300, Epoch Time = 0.78s: Train Loss = 0.7014, Val Loss = 0.7356\n",
      "Epoch 206 / 300, Epoch Time = 0.70s: Train Loss = 0.7075, Val Loss = 0.7654\n",
      "Epoch 207 / 300, Epoch Time = 0.72s: Train Loss = 0.7122, Val Loss = 0.7413\n",
      "Epoch 208 / 300, Epoch Time = 0.74s: Train Loss = 0.7088, Val Loss = 0.7769\n",
      "Epoch 209 / 300, Epoch Time = 0.74s: Train Loss = 0.7042, Val Loss = 0.7248\n",
      "Epoch 210 / 300, Epoch Time = 0.79s: Train Loss = 0.7009, Val Loss = 0.7361\n",
      "Epoch 211 / 300, Epoch Time = 0.74s: Train Loss = 0.7032, Val Loss = 0.7936\n",
      "Epoch 212 / 300, Epoch Time = 0.73s: Train Loss = 0.7151, Val Loss = 0.7322\n",
      "Epoch 213 / 300, Epoch Time = 0.74s: Train Loss = 0.6995, Val Loss = 0.7530\n",
      "Epoch 214 / 300, Epoch Time = 0.80s: Train Loss = 0.6998, Val Loss = 0.7409\n",
      "Epoch 215 / 300, Epoch Time = 0.74s: Train Loss = 0.7071, Val Loss = 0.7353\n",
      "Epoch 216 / 300, Epoch Time = 0.75s: Train Loss = 0.6977, Val Loss = 0.7178\n",
      "Epoch 217 / 300, Epoch Time = 0.73s: Train Loss = 0.7071, Val Loss = 0.7359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218 / 300, Epoch Time = 0.73s: Train Loss = 0.7009, Val Loss = 0.7762\n",
      "Epoch 219 / 300, Epoch Time = 0.81s: Train Loss = 0.7036, Val Loss = 0.7267\n",
      "Epoch 220 / 300, Epoch Time = 0.73s: Train Loss = 0.6855, Val Loss = 0.7865\n",
      "Epoch 221 / 300, Epoch Time = 0.74s: Train Loss = 0.6984, Val Loss = 0.7578\n",
      "Epoch 222 / 300, Epoch Time = 0.75s: Train Loss = 0.6967, Val Loss = 0.7391\n",
      "Epoch 223 / 300, Epoch Time = 0.74s: Train Loss = 0.7000, Val Loss = 0.7068\n",
      "Epoch 224 / 300, Epoch Time = 0.80s: Train Loss = 0.6990, Val Loss = 0.7607\n",
      "Epoch 225 / 300, Epoch Time = 0.75s: Train Loss = 0.6927, Val Loss = 0.7328\n",
      "Epoch 226 / 300, Epoch Time = 0.74s: Train Loss = 0.6905, Val Loss = 0.7434\n",
      "Epoch 227 / 300, Epoch Time = 0.75s: Train Loss = 0.6922, Val Loss = 0.7352\n",
      "Epoch 228 / 300, Epoch Time = 0.74s: Train Loss = 0.6874, Val Loss = 0.7295\n",
      "Epoch 229 / 300, Epoch Time = 0.81s: Train Loss = 0.6904, Val Loss = 0.7320\n",
      "Epoch 230 / 300, Epoch Time = 0.75s: Train Loss = 0.6914, Val Loss = 0.7006\n",
      "Epoch 231 / 300, Epoch Time = 0.75s: Train Loss = 0.6715, Val Loss = 0.7178\n",
      "Epoch 232 / 300, Epoch Time = 0.75s: Train Loss = 0.6910, Val Loss = 0.7260\n",
      "Epoch 233 / 300, Epoch Time = 0.80s: Train Loss = 0.7001, Val Loss = 0.7206\n",
      "Epoch 234 / 300, Epoch Time = 0.75s: Train Loss = 0.6861, Val Loss = 0.7458\n",
      "Epoch 235 / 300, Epoch Time = 0.76s: Train Loss = 0.7038, Val Loss = 0.7402\n",
      "Epoch 236 / 300, Epoch Time = 0.74s: Train Loss = 0.6944, Val Loss = 0.7328\n",
      "Epoch 237 / 300, Epoch Time = 0.75s: Train Loss = 0.6930, Val Loss = 0.7138\n",
      "Epoch 238 / 300, Epoch Time = 0.76s: Train Loss = 0.7025, Val Loss = 0.7540\n",
      "Epoch 239 / 300, Epoch Time = 0.70s: Train Loss = 0.6877, Val Loss = 0.7370\n",
      "Epoch 240 / 300, Epoch Time = 0.77s: Train Loss = 0.6868, Val Loss = 0.7326\n",
      "Epoch 241 / 300, Epoch Time = 0.75s: Train Loss = 0.6898, Val Loss = 0.7349\n",
      "Epoch 242 / 300, Epoch Time = 0.74s: Train Loss = 0.6818, Val Loss = 0.7488\n",
      "Epoch 243 / 300, Epoch Time = 0.79s: Train Loss = 0.6881, Val Loss = 0.7398\n",
      "Epoch 244 / 300, Epoch Time = 0.74s: Train Loss = 0.6826, Val Loss = 0.7297\n",
      "Epoch 245 / 300, Epoch Time = 0.74s: Train Loss = 0.6834, Val Loss = 0.7284\n",
      "Epoch 246 / 300, Epoch Time = 0.74s: Train Loss = 0.6799, Val Loss = 0.7113\n",
      "Epoch 247 / 300, Epoch Time = 0.74s: Train Loss = 0.6840, Val Loss = 0.7424\n",
      "Epoch 248 / 300, Epoch Time = 0.77s: Train Loss = 0.6795, Val Loss = 0.7394\n",
      "Epoch 249 / 300, Epoch Time = 0.73s: Train Loss = 0.6862, Val Loss = 0.7156\n",
      "Epoch 250 / 300, Epoch Time = 0.73s: Train Loss = 0.6831, Val Loss = 0.7279\n",
      "Epoch 251 / 300, Epoch Time = 0.69s: Train Loss = 0.6796, Val Loss = 0.7065\n",
      "Epoch 252 / 300, Epoch Time = 0.78s: Train Loss = 0.6811, Val Loss = 0.7251\n",
      "Epoch 253 / 300, Epoch Time = 0.75s: Train Loss = 0.6851, Val Loss = 0.7257\n",
      "Epoch 254 / 300, Epoch Time = 0.75s: Train Loss = 0.6859, Val Loss = 0.7349\n",
      "Epoch 255 / 300, Epoch Time = 0.73s: Train Loss = 0.6786, Val Loss = 0.7272\n",
      "Epoch 256 / 300, Epoch Time = 0.75s: Train Loss = 0.6768, Val Loss = 0.7239\n",
      "Epoch 257 / 300, Epoch Time = 0.78s: Train Loss = 0.6765, Val Loss = 0.7388\n",
      "Epoch 258 / 300, Epoch Time = 0.76s: Train Loss = 0.6737, Val Loss = 0.7248\n",
      "Epoch 259 / 300, Epoch Time = 0.75s: Train Loss = 0.6802, Val Loss = 0.7244\n",
      "Epoch 260 / 300, Epoch Time = 0.72s: Train Loss = 0.6783, Val Loss = 0.7056\n",
      "Epoch 261 / 300, Epoch Time = 0.74s: Train Loss = 0.6773, Val Loss = 0.7010\n",
      "Epoch 262 / 300, Epoch Time = 0.81s: Train Loss = 0.6723, Val Loss = 0.7355\n",
      "Epoch 263 / 300, Epoch Time = 0.73s: Train Loss = 0.6782, Val Loss = 0.7326\n",
      "Epoch 264 / 300, Epoch Time = 0.75s: Train Loss = 0.6740, Val Loss = 0.7158\n",
      "Epoch 265 / 300, Epoch Time = 0.70s: Train Loss = 0.6819, Val Loss = 0.7285\n",
      "Epoch 266 / 300, Epoch Time = 0.75s: Train Loss = 0.6808, Val Loss = 0.7173\n",
      "Epoch 267 / 300, Epoch Time = 0.79s: Train Loss = 0.6698, Val Loss = 0.7255\n",
      "Epoch 268 / 300, Epoch Time = 0.75s: Train Loss = 0.6705, Val Loss = 0.7284\n",
      "Epoch 269 / 300, Epoch Time = 0.75s: Train Loss = 0.6660, Val Loss = 0.7186\n",
      "Epoch 270 / 300, Epoch Time = 0.76s: Train Loss = 0.6635, Val Loss = 0.7292\n",
      "Epoch 271 / 300, Epoch Time = 0.80s: Train Loss = 0.6776, Val Loss = 0.8061\n",
      "Epoch 272 / 300, Epoch Time = 0.75s: Train Loss = 0.6736, Val Loss = 0.7122\n",
      "Epoch 273 / 300, Epoch Time = 0.76s: Train Loss = 0.6629, Val Loss = 0.7331\n",
      "Epoch 274 / 300, Epoch Time = 0.75s: Train Loss = 0.6656, Val Loss = 0.7086\n",
      "Epoch 275 / 300, Epoch Time = 0.75s: Train Loss = 0.6653, Val Loss = 0.7471\n",
      "Epoch 276 / 300, Epoch Time = 0.78s: Train Loss = 0.6723, Val Loss = 0.6981\n",
      "Epoch 277 / 300, Epoch Time = 0.75s: Train Loss = 0.6676, Val Loss = 0.7033\n",
      "Epoch 278 / 300, Epoch Time = 0.75s: Train Loss = 0.6657, Val Loss = 0.7336\n",
      "Epoch 279 / 300, Epoch Time = 0.75s: Train Loss = 0.6666, Val Loss = 0.7217\n",
      "Epoch 280 / 300, Epoch Time = 0.76s: Train Loss = 0.6837, Val Loss = 0.7354\n",
      "Epoch 281 / 300, Epoch Time = 0.80s: Train Loss = 0.6649, Val Loss = 0.7263\n",
      "Epoch 282 / 300, Epoch Time = 0.75s: Train Loss = 0.6729, Val Loss = 0.7063\n",
      "Epoch 283 / 300, Epoch Time = 0.75s: Train Loss = 0.6675, Val Loss = 0.7472\n",
      "Epoch 284 / 300, Epoch Time = 0.75s: Train Loss = 0.6778, Val Loss = 0.7159\n",
      "Epoch 285 / 300, Epoch Time = 0.75s: Train Loss = 0.6736, Val Loss = 0.7434\n",
      "Epoch 286 / 300, Epoch Time = 0.79s: Train Loss = 0.6653, Val Loss = 0.7588\n",
      "Epoch 287 / 300, Epoch Time = 0.73s: Train Loss = 0.6779, Val Loss = 0.7008\n",
      "Epoch 288 / 300, Epoch Time = 0.74s: Train Loss = 0.6626, Val Loss = 0.6823\n",
      "Epoch 289 / 300, Epoch Time = 0.75s: Train Loss = 0.6635, Val Loss = 0.7583\n",
      "Epoch 290 / 300, Epoch Time = 0.80s: Train Loss = 0.6672, Val Loss = 0.7306\n",
      "Epoch 291 / 300, Epoch Time = 0.74s: Train Loss = 0.6652, Val Loss = 0.7333\n",
      "Epoch 292 / 300, Epoch Time = 0.71s: Train Loss = 0.6586, Val Loss = 0.7237\n",
      "Epoch 293 / 300, Epoch Time = 0.76s: Train Loss = 0.6627, Val Loss = 0.7048\n",
      "Epoch 294 / 300, Epoch Time = 0.76s: Train Loss = 0.6640, Val Loss = 0.7305\n",
      "Epoch 295 / 300, Epoch Time = 0.80s: Train Loss = 0.6595, Val Loss = 0.7181\n",
      "Epoch 296 / 300, Epoch Time = 0.74s: Train Loss = 0.6687, Val Loss = 0.6999\n",
      "Epoch 297 / 300, Epoch Time = 0.74s: Train Loss = 0.6611, Val Loss = 0.6808\n",
      "Epoch 298 / 300, Epoch Time = 0.73s: Train Loss = 0.6673, Val Loss = 0.6988\n",
      "Epoch 299 / 300, Epoch Time = 0.75s: Train Loss = 0.6625, Val Loss = 0.7311\n",
      "Epoch 300 / 300, Epoch Time = 0.79s: Train Loss = 0.6654, Val Loss = 0.7462\n"
     ]
    }
   ],
   "source": [
    "model = SurnamesClassifier(vocab_size=len(char2ind), emb_dim=16, lstm_hidden_dim=64, classes_count=len(lang2ind)).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, epochs_count=300, batch_size=128, train_data=(data_train, labels_train),\n",
    "    val_data=(data_test, labels_test), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jC76XyGjigFx"
   },
   "source": [
    "**Задание** Напишите функцию для тестирования полученной сети: пусть она принимает слово и говорит, в каком языке с какой вероятностью это может быть фамилией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsGNbpBVJ3xO"
   },
   "outputs": [],
   "source": [
    "def classify_word(word, model):\n",
    "    word = torch.Tensor(\n",
    "        [[char2ind.get(symb, 0)] for symb in word]\n",
    "    ).long().cuda()\n",
    "    preds = F.softmax(model(word))\n",
    "    return list(lang2ind.keys())[torch.argmax(preds).item()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'German'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_word(\"label\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWqOPgdbIYcl"
   },
   "source": [
    "**Задание** Оцените качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dT2QE6IycXo9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 59.36%\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Scottish       0.00      0.00      0.00       600\n",
      "       Dutch       0.00      0.00      0.00        80\n",
      "  Vietnamese       0.04      0.01      0.01       156\n",
      "     Russian       0.05      0.07      0.05        89\n",
      "      Arabic       0.51      0.52      0.52      1101\n",
      "     Chinese       0.13      0.14      0.14        83\n",
      "      Korean       0.22      0.38      0.28       217\n",
      "     Italian       0.15      0.79      0.26        61\n",
      "      French       0.02      0.07      0.03        70\n",
      "     English       0.60      0.60      0.60       213\n",
      "     Spanish       0.53      0.79      0.63       297\n",
      "       Irish       0.00      0.00      0.00        28\n",
      "       Czech       0.05      0.07      0.06        42\n",
      "    Japanese       0.00      0.00      0.00        22\n",
      "  Portuguese       0.86      0.88      0.87      2823\n",
      "      Polish       0.00      0.00      0.00        30\n",
      "       Greek       0.00      0.00      0.00        89\n",
      "      German       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      6023\n",
      "   macro avg       0.18      0.24      0.19      6023\n",
      "weighted avg       0.56      0.59      0.57      6023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "y_test, y_pred = labels_test, [classify_word(word, model) for word in data_test]\n",
    "\n",
    "print('Accuracy = {:.2%}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, y_pred, \n",
    "                            target_names=[lang for lang, _ in sorted(lang2ind.items(), key=lambda x: x[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_FZ9x0NInft"
   },
   "source": [
    "## Визуализация эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJkyBV2bAK05"
   },
   "outputs": [],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.colors import RGB\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    output_notebook()\n",
    "    \n",
    "    if isinstance(color, str): \n",
    "        color = [color] * len(x)\n",
    "    if isinstance(color, np.ndarray):\n",
    "        color = [RGB(*x[:3]) for x in color]\n",
    "    print(color)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: \n",
    "        pl.show(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_tsne_projection(word_vectors):\n",
    "    tsne = TSNE(n_components=2, verbose=100)\n",
    "    return scale(tsne.fit_transform(word_vectors))\n",
    "    \n",
    "    \n",
    "def visualize_embeddings(embeddings, token, colors):\n",
    "    tsne = get_tsne_projection(embeddings)\n",
    "    draw_vectors(tsne[:, 0], tsne[:, 1], color=colors, token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1u-74cv7IrH9"
   },
   "source": [
    "Мы опять получили эмбеддинги - символьного уровня теперь.\n",
    "\n",
    "Хочется на них посмотреть\n",
    "\n",
    "**Задание** Посчитайте векторы для случайных слов и выведите их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jt6LsI0NAPAm",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1000 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1000 samples in 0.028s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1000\n",
      "[t-SNE] Mean sigma: 3.501310\n",
      "[t-SNE] Computed conditional probabilities in 0.039s\n",
      "[t-SNE] Iteration 50: error = 63.0477867, gradient norm = 0.2618175 (50 iterations in 1.514s)\n",
      "[t-SNE] Iteration 100: error = 60.0260429, gradient norm = 0.2125691 (50 iterations in 1.518s)\n",
      "[t-SNE] Iteration 150: error = 59.7682228, gradient norm = 0.2192795 (50 iterations in 1.543s)\n",
      "[t-SNE] Iteration 200: error = 59.6062698, gradient norm = 0.1886161 (50 iterations in 1.597s)\n",
      "[t-SNE] Iteration 250: error = 59.6271133, gradient norm = 0.1960319 (50 iterations in 1.458s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 59.627113\n",
      "[t-SNE] Iteration 300: error = 0.6715382, gradient norm = 0.0005931 (50 iterations in 1.449s)\n",
      "[t-SNE] Iteration 350: error = 0.6003271, gradient norm = 0.0002600 (50 iterations in 1.555s)\n",
      "[t-SNE] Iteration 400: error = 0.5850050, gradient norm = 0.0001617 (50 iterations in 1.524s)\n",
      "[t-SNE] Iteration 450: error = 0.5788264, gradient norm = 0.0001221 (50 iterations in 1.384s)\n",
      "[t-SNE] Iteration 500: error = 0.5745872, gradient norm = 0.0001017 (50 iterations in 1.452s)\n",
      "[t-SNE] Iteration 550: error = 0.5722437, gradient norm = 0.0000892 (50 iterations in 1.442s)\n",
      "[t-SNE] Iteration 600: error = 0.5708981, gradient norm = 0.0000837 (50 iterations in 1.397s)\n",
      "[t-SNE] Iteration 650: error = 0.5693783, gradient norm = 0.0000772 (50 iterations in 1.382s)\n",
      "[t-SNE] Iteration 700: error = 0.5684808, gradient norm = 0.0000688 (50 iterations in 1.353s)\n",
      "[t-SNE] Iteration 750: error = 0.5679700, gradient norm = 0.0000636 (50 iterations in 1.364s)\n",
      "[t-SNE] Iteration 800: error = 0.5673172, gradient norm = 0.0000623 (50 iterations in 1.437s)\n",
      "[t-SNE] Iteration 850: error = 0.5669302, gradient norm = 0.0000528 (50 iterations in 1.367s)\n",
      "[t-SNE] Iteration 900: error = 0.5659507, gradient norm = 0.0000597 (50 iterations in 1.532s)\n",
      "[t-SNE] Iteration 950: error = 0.5660469, gradient norm = 0.0000488 (50 iterations in 1.499s)\n",
      "[t-SNE] Iteration 1000: error = 0.5653052, gradient norm = 0.0000572 (50 iterations in 1.444s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.565305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:193: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1107\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1107\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1107\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1107' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1107\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1107\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1107\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1107' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1107\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(174, 199, 232), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(31, 119, 180), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(140, 86, 75), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(247, 182, 210), rgb(197, 176, 213), rgb(255, 187, 120), rgb(140, 86, 75), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(188, 189, 34), rgb(197, 176, 213), rgb(255, 187, 120), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(197, 176, 213), rgb(140, 86, 75), rgb(255, 187, 120), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(31, 119, 180), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(148, 103, 189), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 187, 120), rgb(174, 199, 232), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(127, 127, 127), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(197, 176, 213), rgb(219, 219, 141), rgb(255, 127, 14), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(219, 219, 141), rgb(197, 176, 213), rgb(196, 156, 148), rgb(255, 187, 120), rgb(199, 199, 199), rgb(140, 86, 75), rgb(197, 176, 213), rgb(148, 103, 189), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 127, 14), rgb(174, 199, 232), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(219, 219, 141), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(174, 199, 232), rgb(255, 187, 120), rgb(174, 199, 232), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(44, 160, 44), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(214, 39, 40), rgb(44, 160, 44), rgb(255, 187, 120), rgb(188, 189, 34), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 187, 120), rgb(188, 189, 34), rgb(197, 176, 213), rgb(44, 160, 44), rgb(247, 182, 210), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 152, 150), rgb(196, 156, 148), rgb(255, 187, 120), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(196, 156, 148), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 152, 150), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(148, 103, 189), rgb(44, 160, 44), rgb(255, 187, 120), rgb(44, 160, 44), rgb(44, 160, 44), rgb(44, 160, 44), rgb(197, 176, 213), rgb(152, 223, 138), rgb(214, 39, 40), rgb(247, 182, 210), rgb(44, 160, 44), rgb(152, 223, 138), rgb(44, 160, 44), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(148, 103, 189), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(44, 160, 44), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(247, 182, 210), rgb(247, 182, 210), rgb(247, 182, 210), rgb(255, 152, 150), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(44, 160, 44), rgb(227, 119, 194), rgb(197, 176, 213), rgb(44, 160, 44), rgb(196, 156, 148), rgb(255, 187, 120), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(44, 160, 44), rgb(255, 187, 120), rgb(247, 182, 210), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(152, 223, 138), rgb(255, 187, 120), rgb(255, 187, 120), rgb(174, 199, 232), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 187, 120), rgb(148, 103, 189), rgb(227, 119, 194), rgb(197, 176, 213), rgb(247, 182, 210), rgb(152, 223, 138), rgb(255, 187, 120), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 152, 150), rgb(44, 160, 44), rgb(219, 219, 141), rgb(255, 152, 150), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(219, 219, 141), rgb(255, 187, 120), rgb(152, 223, 138), rgb(219, 219, 141), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 127, 14), rgb(197, 176, 213), rgb(174, 199, 232), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(140, 86, 75), rgb(152, 223, 138), rgb(148, 103, 189), rgb(197, 176, 213), rgb(152, 223, 138), rgb(197, 176, 213), rgb(227, 119, 194), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(174, 199, 232), rgb(219, 219, 141), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(44, 160, 44), rgb(219, 219, 141), rgb(44, 160, 44), rgb(44, 160, 44), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(227, 119, 194), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(219, 219, 141), rgb(219, 219, 141), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(196, 156, 148), rgb(44, 160, 44), rgb(174, 199, 232), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(31, 119, 180), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(247, 182, 210), rgb(219, 219, 141), rgb(255, 187, 120), rgb(197, 176, 213), rgb(140, 86, 75), rgb(44, 160, 44), rgb(219, 219, 141), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(148, 103, 189), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(247, 182, 210), rgb(219, 219, 141), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(219, 219, 141), rgb(44, 160, 44), rgb(44, 160, 44), rgb(247, 182, 210), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(199, 199, 199), rgb(197, 176, 213), rgb(247, 182, 210), rgb(255, 187, 120), rgb(152, 223, 138), rgb(247, 182, 210), rgb(152, 223, 138), rgb(255, 187, 120), rgb(255, 152, 150), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(148, 103, 189), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(196, 156, 148), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(174, 199, 232), rgb(255, 187, 120), rgb(188, 189, 34), rgb(127, 127, 127), rgb(174, 199, 232), rgb(174, 199, 232), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(197, 176, 213), rgb(197, 176, 213), rgb(199, 199, 199), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(140, 86, 75), rgb(44, 160, 44), rgb(44, 160, 44), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 152, 150), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(152, 223, 138), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(152, 223, 138), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(174, 199, 232), rgb(140, 86, 75), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(140, 86, 75), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(152, 223, 138), rgb(197, 176, 213), rgb(197, 176, 213), rgb(219, 219, 141), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(247, 182, 210), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 152, 150), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(197, 176, 213), rgb(247, 182, 210), rgb(255, 152, 150), rgb(174, 199, 232), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(44, 160, 44), rgb(140, 86, 75), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 152, 150), rgb(255, 187, 120), rgb(247, 182, 210), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(174, 199, 232), rgb(197, 176, 213), rgb(174, 199, 232), rgb(255, 152, 150), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(188, 189, 34), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(199, 199, 199), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(197, 176, 213), rgb(148, 103, 189), rgb(255, 187, 120), rgb(197, 176, 213), rgb(188, 189, 34), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(197, 176, 213), rgb(255, 187, 120), rgb(219, 219, 141), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(247, 182, 210), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(152, 223, 138), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(174, 199, 232), rgb(255, 152, 150), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(140, 86, 75), rgb(44, 160, 44), rgb(44, 160, 44), rgb(188, 189, 34), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 127, 14), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(127, 127, 127), rgb(44, 160, 44), rgb(255, 152, 150), rgb(255, 187, 120), rgb(219, 219, 141), rgb(197, 176, 213), rgb(219, 219, 141), rgb(197, 176, 213), rgb(174, 199, 232), rgb(219, 219, 141), rgb(219, 219, 141), rgb(197, 176, 213), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(214, 39, 40), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(148, 103, 189), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(219, 219, 141), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(219, 219, 141), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(188, 189, 34), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(44, 160, 44), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(152, 223, 138), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(140, 86, 75), rgb(197, 176, 213), rgb(148, 103, 189), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(174, 199, 232), rgb(255, 187, 120), rgb(197, 176, 213), rgb(247, 182, 210), rgb(255, 187, 120), rgb(44, 160, 44), rgb(197, 176, 213), rgb(196, 156, 148), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(219, 219, 141), rgb(44, 160, 44), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(44, 160, 44), rgb(44, 160, 44), rgb(196, 156, 148), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(214, 39, 40), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(148, 103, 189), rgb(247, 182, 210), rgb(214, 39, 40), rgb(44, 160, 44), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(196, 156, 148), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(219, 219, 141), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(247, 182, 210), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(247, 182, 210), rgb(227, 119, 194), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(148, 103, 189), rgb(197, 176, 213), rgb(219, 219, 141), rgb(255, 187, 120), rgb(255, 187, 120), rgb(140, 86, 75), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(140, 86, 75), rgb(188, 189, 34), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(152, 223, 138), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(197, 176, 213), rgb(219, 219, 141), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(140, 86, 75), rgb(255, 187, 120), rgb(255, 187, 120), rgb(152, 223, 138), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(44, 160, 44), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 127, 14), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(219, 219, 141), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(219, 219, 141), rgb(255, 152, 150), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 152, 150), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(196, 156, 148), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(247, 182, 210), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(44, 160, 44), rgb(197, 176, 213), rgb(255, 187, 120), rgb(44, 160, 44), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 152, 150), rgb(44, 160, 44), rgb(255, 187, 120), rgb(255, 187, 120), rgb(227, 119, 194), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(152, 223, 138), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(219, 219, 141), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(255, 187, 120), rgb(174, 199, 232), rgb(255, 187, 120), rgb(255, 152, 150), rgb(247, 182, 210), rgb(219, 219, 141), rgb(152, 223, 138), rgb(255, 152, 150), rgb(227, 119, 194), rgb(255, 187, 120), rgb(140, 86, 75), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(197, 176, 213), rgb(152, 223, 138), rgb(255, 187, 120), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 187, 120), rgb(197, 176, 213), rgb(197, 176, 213), rgb(197, 176, 213), rgb(44, 160, 44), rgb(219, 219, 141), rgb(255, 187, 120), rgb(197, 176, 213), rgb(219, 219, 141), rgb(197, 176, 213), rgb(255, 187, 120), rgb(255, 127, 14)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"1df05bdb-94f3-45d4-b0cf-0522fc6fd719\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"33e5783f-6ee1-44e0-9cdc-c7c1574f4910\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1118\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1123\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1118\",\"type\":\"LinearAxis\"},{\"id\":\"1122\",\"type\":\"Grid\"},{\"id\":\"1123\",\"type\":\"LinearAxis\"},{\"id\":\"1127\",\"type\":\"Grid\"},{\"id\":\"1136\",\"type\":\"BoxAnnotation\"},{\"id\":\"1146\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1160\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1134\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1110\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1114\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1112\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1116\",\"type\":\"LinearScale\"}},\"id\":\"1109\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"formatter\":{\"id\":\"1162\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1109\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1119\",\"type\":\"BasicTicker\"}},\"id\":\"1118\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1119\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1148\",\"type\":\"HoverTool\"},{\"attributes\":{\"plot\":{\"id\":\"1109\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1119\",\"type\":\"BasicTicker\"}},\"id\":\"1122\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1160\",\"type\":\"Title\"},{\"attributes\":{\"formatter\":{\"id\":\"1164\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1109\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1124\",\"type\":\"BasicTicker\"}},\"id\":\"1123\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1162\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1124\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1164\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1109\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1124\",\"type\":\"BasicTicker\"}},\"id\":\"1127\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1165\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1144\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1166\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1129\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1128\",\"type\":\"PanTool\"},{\"id\":\"1129\",\"type\":\"WheelZoomTool\"},{\"id\":\"1130\",\"type\":\"BoxZoomTool\"},{\"id\":\"1131\",\"type\":\"SaveTool\"},{\"id\":\"1132\",\"type\":\"ResetTool\"},{\"id\":\"1133\",\"type\":\"HelpTool\"},{\"id\":\"1148\",\"type\":\"HoverTool\"}]},\"id\":\"1134\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1128\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(31, 119, 180)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(188, 189, 34)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(197, 176, 213)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(31, 119, 180)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(148, 103, 189)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(127, 127, 127)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(255, 127, 14)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(199, 199, 199)\",\"rgb(140, 86, 75)\",\"rgb(197, 176, 213)\",\"rgb(148, 103, 189)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 127, 14)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(214, 39, 40)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(188, 189, 34)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(188, 189, 34)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(148, 103, 189)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(152, 223, 138)\",\"rgb(214, 39, 40)\",\"rgb(247, 182, 210)\",\"rgb(44, 160, 44)\",\"rgb(152, 223, 138)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(148, 103, 189)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(247, 182, 210)\",\"rgb(247, 182, 210)\",\"rgb(247, 182, 210)\",\"rgb(255, 152, 150)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(227, 119, 194)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(152, 223, 138)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(148, 103, 189)\",\"rgb(227, 119, 194)\",\"rgb(197, 176, 213)\",\"rgb(247, 182, 210)\",\"rgb(152, 223, 138)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 152, 150)\",\"rgb(44, 160, 44)\",\"rgb(219, 219, 141)\",\"rgb(255, 152, 150)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 127, 14)\",\"rgb(197, 176, 213)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(152, 223, 138)\",\"rgb(148, 103, 189)\",\"rgb(197, 176, 213)\",\"rgb(152, 223, 138)\",\"rgb(197, 176, 213)\",\"rgb(227, 119, 194)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(219, 219, 141)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(196, 156, 148)\",\"rgb(44, 160, 44)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(31, 119, 180)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(140, 86, 75)\",\"rgb(44, 160, 44)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(148, 103, 189)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(199, 199, 199)\",\"rgb(197, 176, 213)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(247, 182, 210)\",\"rgb(152, 223, 138)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(148, 103, 189)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(188, 189, 34)\",\"rgb(127, 127, 127)\",\"rgb(174, 199, 232)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(199, 199, 199)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(152, 223, 138)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(247, 182, 210)\",\"rgb(255, 152, 150)\",\"rgb(174, 199, 232)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(140, 86, 75)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(197, 176, 213)\",\"rgb(174, 199, 232)\",\"rgb(255, 152, 150)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(188, 189, 34)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(199, 199, 199)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(197, 176, 213)\",\"rgb(148, 103, 189)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(188, 189, 34)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(247, 182, 210)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(152, 223, 138)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(255, 152, 150)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(188, 189, 34)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 127, 14)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(127, 127, 127)\",\"rgb(44, 160, 44)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(174, 199, 232)\",\"rgb(219, 219, 141)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(214, 39, 40)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(148, 103, 189)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(188, 189, 34)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(197, 176, 213)\",\"rgb(148, 103, 189)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(219, 219, 141)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(214, 39, 40)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(148, 103, 189)\",\"rgb(247, 182, 210)\",\"rgb(214, 39, 40)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(196, 156, 148)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(247, 182, 210)\",\"rgb(227, 119, 194)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(148, 103, 189)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(188, 189, 34)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 127, 14)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(255, 152, 150)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(196, 156, 148)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(247, 182, 210)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 152, 150)\",\"rgb(44, 160, 44)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(152, 223, 138)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(174, 199, 232)\",\"rgb(255, 187, 120)\",\"rgb(255, 152, 150)\",\"rgb(247, 182, 210)\",\"rgb(219, 219, 141)\",\"rgb(152, 223, 138)\",\"rgb(255, 152, 150)\",\"rgb(227, 119, 194)\",\"rgb(255, 187, 120)\",\"rgb(140, 86, 75)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(152, 223, 138)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(197, 176, 213)\",\"rgb(44, 160, 44)\",\"rgb(219, 219, 141)\",\"rgb(255, 187, 120)\",\"rgb(197, 176, 213)\",\"rgb(219, 219, 141)\",\"rgb(197, 176, 213)\",\"rgb(255, 187, 120)\",\"rgb(255, 127, 14)\"],\"token\":[\"Worsnop\",\"Tamaev\",\"Jagofarov\",\"Tsapaev\",\"Moghadam\",\"Sakin\",\"Mogilensky\",\"Morandi\",\"Toma\",\"Nyrko\",\"Neverkovets\",\"Dzhibuti\",\"Brandt\",\"Froyanov\",\"Serejkin\",\"Zharnov\",\"Haldei\",\"Gasho\",\"Tannous\",\"Guirguis\",\"Abboud\",\"Breda\",\"Mahinov\",\"Zhmelkov\",\"Koury\",\"Horkov\",\"Deane\",\"Fakhoury\",\"Grigorevsky\",\"Chukhlov\",\"Lysyakov\",\"O'Hara\",\"Paradzinsky\",\"Antar\",\"Malone\",\"Alsky\",\"San\",\"Chikviladze\",\"Maalouf\",\"Panayiotopoulos\",\"Vyaznikovtsev\",\"Ginty\",\"Karube\",\"Zogby\",\"Asghar\",\"Widdowson\",\"Jaskolski\",\"Shamoun\",\"Aven\",\"Rikhter\",\"Matsuoka\",\"Hinich\",\"Tron\",\"Turukhin\",\"Chihachev\",\"Mather\",\"Oneill\",\"Yukhov\",\"Likhodedov\",\"Lichtenberg\",\"Vavravsky\",\"Lapenkov\",\"Oboldin\",\"Kachalkin\",\"Mordashov\",\"Marik\",\"Tocher\",\"Trnkova\",\"Busto\",\"Rosso\",\"Bazzoli\",\"Bavykin\",\"Veseliev\",\"Awtorkhanoff\",\"Bishara\",\"Vilbushevich\",\"Babakhanov\",\"Shiraev\",\"Natashkin\",\"Shimanouchi\",\"Pakhunov\",\"Agamirov\",\"Kiernan\",\"Nishihara\",\"Gladun\",\"Guzner\",\"Tallett\",\"Finenko\",\"Hutchinson\",\"Fairbrace\",\"Hiratasuka\",\"Elston\",\"Isayan\",\"Balahonsky\",\"Vizhonsky\",\"Lynch\",\"Gudjabidze\",\"Johnston\",\"Smol\\u00e1k\",\"Crabb\",\"Uetake\",\"Forbes\",\"Yuschak\",\"Tanaka\",\"Vyrodkov\",\"Usenko\",\"Coward\",\"Marutenkov\",\"Lowndes\",\"Tulnikov\",\"Atiyeh\",\"Missiakos\",\"Fofanov\",\"Ta\",\"Haanraats\",\"Twine\",\"Tzelovalnikov\",\"Whitlock\",\"Addley\",\"Tselikov\",\"Abbas\",\"Jelen\",\"Foley\",\"Feng\",\"Orellana\",\"Ryjenkov\",\"Ramm\",\"Noon\",\"Novosadov\",\"Esparza\",\"Jennson\",\"Ladyjets\",\"Eliashberg\",\"Sch\\u00e4fer\",\"Djatdoev\",\"Agalarov\",\"Cotter\",\"Schr\\u00f6der\",\"Mihlin\",\"Dehtyar\",\"Lazzari\",\"Kalievsky\",\"Shimaoka\",\"Pavluhin\",\"Langridge\",\"Dodolev\",\"L\\u00e9vesque\",\"Inglefield\",\"Zimny\",\"Fromberg\",\"Saksonov\",\"Wilkin\",\"Dobrinsky\",\"Horalya\",\"Upton\",\"Lyon\",\"Exton\",\"Rend\\u00f3n\",\"Yakovichenko\",\"Russel\",\"Batsakis\",\"Wither\",\"Hashimoto\",\"Okten\",\"Valenti\",\"Vanteev\",\"Molov\",\"Maroun\",\"Langton\",\"Mill\",\"Laraway\",\"Arihyoshi\",\"Efanov\",\"Kouri\",\"Evsyukov\",\"Pakhtel\",\"Katz\",\"Dagher\",\"Lenihan\",\"Harisov\",\"Yaminsky\",\"Golofastov\",\"Gribenkin\",\"Serafin\",\"Yamov\",\"Gro\\u00df\",\"Wraight\",\"Vistchinsky\",\"Page\",\"Weldon\",\"Jund\",\"Horanov\",\"Mann\",\"Serpico\",\"Nurgaliev\",\"Katsenelenbaum\",\"Tsalyhin\",\"Sommer\",\"Emmons\",\"Huffmann\",\"Kablits\",\"Jenovach\",\"Javoronok\",\"Matzigura\",\"Shalhoub\",\"Hassan\",\"Dubnitsky\",\"Kent\",\"Penkovsky\",\"Pickthall\",\"Levett\",\"Lokhanin\",\"Sayegh\",\"Kats\",\"Tuma\",\"Thurbon\",\"Greenway\",\"Yatsyshin\",\"Belmonte\",\"Mcdonagh\",\"Govyadin\",\"Vindman\",\"Arian\",\"Kang\",\"Eglin\",\"Morcos\",\"Riain\",\"Podsizertsev\",\"Brambilla\",\"Booth\",\"Kumasaka\",\"Shand\",\"Dzhakson\",\"Bezruchenkov\",\"Favre\",\"Homentovsky\",\"Leiko\",\"Dyde\",\"Awad\",\"Holzmann\",\"Rao\",\"Levann\",\"Jigailov\",\"Manoukarakis\",\"Dubrowski\",\"Romero\",\"Holyuchenko\",\"Khouri\",\"Yakovkin\",\"Kalenov\",\"Bazhenin\",\"Jvykin\",\"Kassis\",\"Hachaturyan\",\"Zenbitsky\",\"Timin\",\"Ustinkin\",\"Gi\\u00f9govaz\",\"Gong\",\"Accorso\",\"Dymond\",\"Wheatcroft\",\"Meeuwessen\",\"Chu\",\"Bennett\",\"Abdeev\",\"Issa\",\"Palin\",\"Knowles\",\"Tzann-Kay-Si\",\"Mikhnenko\",\"Close\",\"Maroun\",\"Nifterick\",\"Levitin\",\"Emelin\",\"Piccoli\",\"Vystavkin\",\"Timkachev\",\"Enik\",\"Salzwedel\",\"Bekuh\",\"Vasin\",\"Biragov\",\"Zhilyaev\",\"Lossky\",\"Seidel\",\"Mikhail\",\"Bazzi\",\"Belogubov\",\"Molchadsky\",\"Baidukov\",\"Deeb\",\"Slapnickova\",\"Metz\",\"Ligorner\",\"Yuzvikov\",\"Garver\",\"Awloff\",\"Rujitsky\",\"Mikhail\",\"Timkaev\",\"Rollinson\",\"Aloisi\",\"Storey\",\"Boutros\",\"Atshushi\",\"Malouf\",\"Zasluev\",\"Stoppelbein\",\"Hapkov\",\"Holmogortsev\",\"Rotolo\",\"Okimoto\",\"Vandale\",\"Chermak\",\"Abakeliya\",\"Turkov\",\"Snell\",\"Lupei\",\"Tsvei\",\"Rebinder\",\"Langenberg\",\"Gibbins\",\"Antonowitsch\",\"Sharpe\",\"Lozhchenko\",\"Zhovtun\",\"Timpy\",\"Astbury\",\"Tonks\",\"Sarno\",\"D'ambrosio\",\"Yuzefov\",\"Deeb\",\"Serchuk\",\"Abrosimoff\",\"Makushev\",\"Paragulgov\",\"Vandalkovsky\",\"Hlopetsky\",\"Broomfield\",\"Dobrosotsky\",\"Iskandarov\",\"Morehin\",\"Totolos\",\"Kimiyama\",\"Haik\",\"Lawrence\",\"Tugwell\",\"Boulos\",\"Yagunov\",\"Kokan\",\"Velikanov\",\"Brunet\",\"Elepov\",\"Alberghini\",\"Whelan\",\"Parasyuk\",\"Specht\",\"Jijin\",\"Yim\",\"Loder\",\"Essa\",\"Vanin\",\"Camfrlova\",\"Crowley\",\"Zinyuhin\",\"Djarimov\",\"Hapsirokov\",\"Birkin\",\"Cochrane\",\"Deeb\",\"Nemec\",\"Auberton\",\"Zogby\",\"Musahanov\",\"Demichev\",\"Abamelek\",\"Deighton\",\"Basara\",\"Dikul\",\"Tzaregorodtsev\",\"Bright\",\"Rafaj1\",\"Vylomov\",\"Ajello\",\"Potenza\",\"Gass\",\"Hajkova\",\"Nanton\",\"Lihov\",\"Silje\",\"Marugo\",\"Yuferev\",\"Frankland\",\"Otrohov\",\"Muzalevskih\",\"Tcheklyanov\",\"Zhalnin\",\"Mikhalev\",\"Telis\",\"Rowe\",\"Maloof\",\"Likharev\",\"Malouf\",\"Ostler\",\"Beltov\",\"Menendez\",\"Zhizha\",\"Ukhovsky\",\"Obinata\",\"Nader\",\"Robins\",\"Lozin\",\"Ajibana\",\"Good\",\"Mcauley\",\"Trinh\",\"Gastello\",\"Mooney\",\"Hazov\",\"Gribashev\",\"Saller\",\"Cuevas\",\"Killock\",\"Wang\",\"Adyrkhaev\",\"Iida\",\"Shadid\",\"Kaloshin\",\"Shammas\",\"Avaev\",\"Brauer\",\"Kapsimalles\",\"Julidov\",\"Antufiev\",\"Daele\",\"Buchta\",\"Mahotkin\",\"Montagne\",\"Newton\",\"Farina\",\"Thelwell\",\"Yeo\",\"Egger\",\"Jakimets\",\"Western\",\"Olson\",\"V\\u00e1squez\",\"Nyago\",\"Mcginty\",\"Gross\",\"Paraskun\",\"Postnikov\",\"Eoin\",\"Bishara\",\"Salib\",\"Antoun\",\"Diakogeorgiou\",\"Vo\\u00df\",\"Sleiman\",\"Trukhnin\",\"Lymar\",\"Mitchell\",\"Shalhoub\",\"Abdulbekoff\",\"Jijemsky\",\"Yukhanaev\",\"Mccallum\",\"Matjeka\",\"Di stefano\",\"Shamoon\",\"Eizen\",\"Hussain\",\"Kabitsin\",\"Lyvin\",\"Jablovsky\",\"Dobromyslov\",\"Xiang\",\"Patsev\",\"Abelev\",\"Pickering\",\"Jankevich\",\"Felix\",\"Vainson\",\"Belikov\",\"Buchan\",\"G\\u00f3rka\",\"Schepetkov\",\"Teale\",\"Matzyuk\",\"Avrorin\",\"Vitram\",\"Golomovzy\",\"Holgu\\u00edn\",\"Martinkus\",\"Holmov\",\"Marfunin\",\"Agresta\",\"Mikhail\",\"Vainonen\",\"Cabral\",\"Tovstukha\",\"Evsyutin\",\"Vakanya\",\"Rahal\",\"Ajiganoff\",\"Nagel\",\"Krusen\",\"Roth\",\"Assaf\",\"Halyavin\",\"Halabi\",\"Yadrov\",\"Ataev\",\"Vasyanovich\",\"Fadyaev\",\"Mochtarev\",\"Debenham\",\"Adessi\",\"Nesis\",\"Nassar\",\"Mustafa\",\"Kaleev\",\"Davy\",\"Rose\",\"Neave\",\"Dudley\",\"Goncharuk\",\"Mochanovsky\",\"Lindsay\",\"Pypin\",\"Dirchs\",\"Villa\",\"Zherzdev\",\"Prokoshev\",\"Campana\",\"Jukes\",\"Noh\",\"Avdyushin\",\"Kaldybaev\",\"Balakleevsky\",\"Tziolkovsky\",\"Awhadieff\",\"Bramley\",\"Tuttle\",\"Bell\",\"Rumsey\",\"Abukhov\",\"Hamer\",\"Orsini\",\"Skwor\",\"Ganim\",\"Yam\",\"Schoettmer\",\"Webster\",\"Eijvertin\",\"Cerv\",\"Wolf\",\"Tan\",\"Bazyuta\",\"Badykshanoff\",\"Chekoev\",\"Kouman\",\"Lorenzen\",\"Mann\",\"Adlam\",\"Steffen\",\"Martinenas\",\"Zhivotenko\",\"Bisset\",\"Aston\",\"Nuriev\",\"Hubutiya\",\"Zhevakhov\",\"Bagmewsky\",\"Diduh\",\"Yatsyk\",\"Nolan\",\"Hodoval\",\"Odea\",\"Zasko\",\"Zhegulin\",\"Twigg\",\"Novotortsev\",\"Isman\",\"Veselitsky\",\"Dunst\",\"Mikhoels\",\"Knightley\",\"Nesgovorov\",\"Que\",\"Luo\",\"Rocco\",\"Losa\",\"Snell\",\"Nakhodkin\",\"Trigg\",\"Adoduroff\",\"Middlesworth\",\"Bazzi\",\"Gillett\",\"Awad\",\"Sano\",\"Talkov\",\"K\\u00e4stner\",\"Verba\",\"Davydenko\",\"Makhonov\",\"Yakushevich\",\"Ganim\",\"Baikin\",\"Badyashin\",\"Newlands\",\"Vann\",\"Linford\",\"Hairov\",\"Ryjkin\",\"Awduloff\",\"Sonnen\",\"Furness\",\"Peltsman\",\"Porokhov\",\"Sheludshev\",\"Chadrantsev\",\"Leighton\",\"Sharples\",\"Kabak\",\"Alshits\",\"Yoshioka\",\"Waugh\",\"Cheung\",\"Shakhnazaryants\",\"Filippenko\",\"Rowlands\",\"Apeldoorn\",\"Jitnik\",\"Babaitsev\",\"Awkhimovich\",\"Klossner\",\"Fei\",\"Sakuraba\",\"Valeev\",\"Wragg\",\"Yuhanaev\",\"Hewitt\",\"Dehmel\",\"Hardy\",\"Neznanov\",\"Okada\",\"Pochechikin\",\"Mcmanus\",\"Zheng\",\"Kanada\",\"Bahtoff\",\"Prygoda\",\"Porfiriev\",\"Moh\",\"Liliental\",\"Antony\",\"Renaud\",\"Kilbride\",\"Djelepov\",\"Hrdy\",\"Allsop\",\"Vakulko\",\"Chutchikov\",\"Lian\",\"Morozovsky\",\"Arbore\",\"Faddeev\",\"Geaney\",\"Kuai\",\"Prigozhin\",\"Abaloff\",\"Mikhailyants\",\"Hatov\",\"Bagni\",\"Demirchyan\",\"Komatsuzaki\",\"Kanaan\",\"Husk\",\"Bakradze\",\"Kasimor\",\"Peisar\",\"Phung\",\"Balakaev\",\"Ansaldi\",\"Guirguis\",\"Jablokov\",\"Laterza\",\"Moletotov\",\"Jigachev\",\"Mikhalkin\",\"Haworth\",\"Tahan\",\"Sakson\",\"Jmulev\",\"Pears\",\"Blazek\",\"Hakimi\",\"Masih\",\"Baigulov\",\"Koban\",\"Machado\",\"Filipovich\",\"Baibakov\",\"Tumenov\",\"Bakrymoff\",\"an\",\"Vasyankin\",\"Hase\",\"Vitruk\",\"Andryuschenko\",\"Babanoff\",\"Bakin\",\"Elstone\",\"Bazil\",\"Baburin\",\"Jankin\",\"Ha\",\"Gwock\",\"Ashbridge\",\"Adoratsky\",\"Deriglazov\",\"Gallai\",\"Moghadam\",\"Andrushko\",\"Najjar\",\"Derrien\",\"Funaki\",\"Nusberg\",\"Walter\",\"Holloway\",\"Gerrard\",\"Kohl\",\"Juhtanov\",\"Romeijn\",\"Smith\",\"Goloborodov\",\"Seredkin\",\"Yablontzev\",\"Abdulkhabiroff\",\"Antonino\",\"Prescott\",\"Langbroek\",\"Andryuhin\",\"Tovar\",\"Mach\",\"Lynes\",\"Bazowsky\",\"Kawasaki\",\"Blanc\",\"Touma\",\"Remmer\",\"Saitoh\",\"Jordison\",\"Viridarsky\",\"Jagodin\",\"Dent\",\"Bazulin\",\"Jemoitel\",\"Demin\",\"Bakhtiyaroff\",\"Daryalov\",\"Lutfullin\",\"Ferguson\",\"Fujioka\",\"Rossem\",\"Bekhtin\",\"Shalyto\",\"Jiu\",\"Neznamov\",\"Sabbag\",\"Zhvanetsky\",\"Kaldin\",\"Tindell\",\"Lobo\",\"Erenkov\",\"Dillon\",\"Gladchenko\",\"Santos\",\"Jaklashkin\",\"Alcheri\",\"Huako\",\"Shan\",\"Koury\",\"Tchekharin\",\"Shamakhov\",\"Andrushkevich\",\"Brain\",\"Ly\",\"Zholobov\",\"Bajanoff\",\"Sugitani\",\"Fowler\",\"Dovlatov\",\"Sciacca\",\"Adashevsky\",\"Zhivotovsky\",\"Anuprienko\",\"Desrosiers\",\"Foreman\",\"Askew\",\"Zherdev\",\"Ansell\",\"Guirguis\",\"Uddin\",\"Rotermel\",\"Jeleznov\",\"Pond\",\"Mcculloch\",\"Atalikov\",\"Baklastoff\",\"Abramson\",\"Hodge\",\"Awdiewsky\",\"Desnitsky\",\"Ohme\",\"Dobryshin\",\"Harlov\",\"Mihalychev\",\"Fraser\",\"Seredov\",\"Talov\",\"Hinchuk\",\"Asghar\",\"Avkhimovich\",\"Deminov\",\"Ronchi\",\"Pechernikov\",\"Oleastro\",\"Milligan\",\"O'Donnell\",\"Kabyshev\",\"Chursin\",\"Daher\",\"O'Rourke\",\"Martinelli\",\"Bagretsov\",\"Pehterev\",\"Tchekhluev\",\"Remyannikov\",\"Batchmanoff\",\"Samaha\",\"Moshenkov\",\"Andreichenko\",\"Tchekhovsky\",\"Jafarov\",\"Wyer\",\"Garvey\",\"Pavlyukov\",\"Rokhin\",\"Kassis\",\"Said\",\"Dozmorov\",\"Traverso\",\"Agoev\",\"Illingworth\",\"Omischenko\",\"Pochkaev\",\"Deeb\",\"Nejinsky\",\"D\\u00fabhshlaine\",\"Saigin\",\"Mottram\",\"Mlechin\",\"Yugov\",\"Daalen\",\"Hlopov\",\"Tait\",\"Salazar\",\"Jamaltdinov\",\"Ganim\",\"Shahmin\",\"Mikhail\",\"Velikorechin\",\"Vinarov\",\"Zhikharev\",\"Berezovoi\",\"Jizdik\",\"Albanesi\",\"Otake\",\"Foulkes\",\"Vypolzov\",\"Ferns\",\"Favreau\",\"Nazarkin\",\"Tsukahara\",\"Gordasevich\",\"Schultheis\",\"Atajahov\",\"Nozara\",\"Balamutenko\",\"Seif\",\"Cho\",\"Zhelezov\",\"Oldland\",\"Mifsud\",\"Vaiserman\",\"Goloborodko\",\"Basara\",\"Francis\",\"De laurentis\",\"Goodall\",\"Pickard\",\"Sandoval\",\"Oldham\",\"Ba\",\"Burden\",\"Ryjov\",\"Hilchevsky\",\"Neale\",\"Tillens\",\"Nader\",\"Jalovoi\",\"Padkin\",\"Tsapin\",\"Sleiman\",\"Belotserkovets\",\"Abidoff\",\"Ryzhenko\",\"Vickerman\",\"Halip\",\"Awtorhanoff\",\"Shakhgildyan\",\"Faure\",\"Altfater\",\"Macmillan\",\"Nijo\",\"Cairns\",\"Ilyakhin\",\"Attia\",\"Eckersall\",\"Kawate\",\"Kalb\",\"Fung\",\"Badalyants\",\"Makunin\",\"Kenneford\",\"Bazzi\",\"Mason\",\"Niadh\",\"Koury\",\"Pawluk\",\"Averbuch\",\"Cu\\u00e9llar\",\"Matzak\",\"Arnolfi\",\"Novohatsky\",\"Lepihin\",\"Luckhurst\",\"Mansour\",\"Newey\",\"Barabolya\",\"Snider\",\"Eastham\",\"Artliff\",\"Falsh\",\"Raihert\",\"Yosano\",\"Falconer\",\"Zhemlihanov\",\"Allman\",\"Bessonov\",\"Harchev\",\"Alkvist\",\"Rotmistrov\",\"Mackenzie\",\"Tian\",\"Cham\",\"Sanchez\",\"Haddad\",\"Awkhimovitch\",\"Zhdanovsky\",\"Chuvatkin\",\"Finyutin\",\"Svejkovsky\",\"Lyon\",\"Likhanov\",\"Jahin\",\"Halifman\",\"Pavlyuk\",\"Saifulov\",\"Dimmock\",\"Bazhov\",\"Artyushkov\",\"Shaidarov\",\"Meszes\",\"Vyazovoy\",\"Sneijer\",\"Kirtley\",\"Ader\",\"Tatnell\",\"Myers\",\"Eyett\",\"Sauvageau\",\"Mikhail\",\"Jakhnenko\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1165\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1166\",\"type\":\"UnionRenderers\"}},\"id\":\"1108\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1129\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1136\",\"type\":\"BoxAnnotation\"}},\"id\":\"1130\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1131\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1132\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1145\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1133\",\"type\":\"HelpTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1110\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"1112\",\"type\":\"DataRange1d\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1136\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1114\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"1108\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1144\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1145\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1147\",\"type\":\"CDSView\"}},\"id\":\"1146\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1116\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"1108\",\"type\":\"ColumnDataSource\"}},\"id\":\"1147\",\"type\":\"CDSView\"}],\"root_ids\":[\"1109\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.2\"}};\n",
       "  var render_items = [{\"docid\":\"33e5783f-6ee1-44e0-9cdc-c7c1574f4910\",\"roots\":{\"1109\":\"1df05bdb-94f3-45d4-b0cf-0522fc6fd719\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1109"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_indices = np.random.choice(np.arange(len(data_test)), 1000, replace=False)\n",
    "words = [data_test[ind] for ind in word_indices]\n",
    "word_labels = [labels_test[ind] for ind in word_indices]\n",
    "\n",
    "model.eval()\n",
    "X_batch, y_batch = next(iterate_batches(words, word_labels, batch_size=1000))\n",
    "embeddings = model((torch.Tensor(X_batch).long().cuda()))\n",
    "colors = plt.cm.tab20(y_batch) * 255\n",
    "\n",
    "visualize_embeddings(embeddings.cpu().detach().numpy(), words, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnQMDFTgKCY0"
   },
   "source": [
    "## Визуализация работы сети\n",
    "\n",
    "На каждом шаге RNN выдает какой-то вектор. Полносвязный слой применяется только к последнему выходу. Но можно же посмотреть и на промежуточные состояния - как менялось мнение сети о том, к чему относится это слово.\n",
    "\n",
    "**Задание** Напишите свой визуализатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "86lffPwLKmqt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DickfCNwJZFT"
   },
   "source": [
    "## Улучшение сети\n",
    "\n",
    "**Задание** Замените SimpleRNN на LSTM. Сравните качества.\n",
    "\n",
    "**Задание** Добавьте Dropout до LSTM (а можно и после). Адекватным будет значение порядка 0.3.\n",
    "\n",
    "**Задание** Важным видом RNN является Bidirectional RNN. По сути это две RNN, одна обходит последовательность слева направо, вторая - наоборот. \n",
    "\n",
    "В результате для каждого момента времени у нас есть вектор $h_t = [f_t; b_t]$ - конкатенация (или какая-то ещё функция от $f_t$ и $b_t$) состояний $f_t$ и $b_t$ - прямого и обратного прохода последовательности. В сумме они покрывают весь контекст.\n",
    "\n",
    "В нашей задаче Bidirectional вариант может помочь тем, что сеть будет меньше забывать, с чего начиналась последовательность. То есть нам нужно будет взять $f_N$ и $b_N$ состояния: первое - последнее состояние в проходе слева направо, т.е. выход от последнего символа. Второе - последнее состояние при обратно проходе, т.е. выход для первого символа.\n",
    "\n",
    "Реализуйте Bidirectional классификатор. Для этого в `LSTM` есть параметр `bidirectional`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukwXJppHrDwS"
   },
   "source": [
    "# Дополнительные материалы\n",
    "\n",
    "## Почитать\n",
    "\n",
    "### Блоги\n",
    "[The Unreasonable Effectiveness of Recurrent Neural Networks, Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)  \n",
    "[Understanding LSTM Networks, Christopher Olah](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)  \n",
    "[Recurrent Neural Networks Tutorial, Denny Britz](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)  \n",
    "[Vanishing Gradients & LSTMs, Harini Suresh](http://harinisuresh.com/2016/10/09/lstms/)\n",
    "\n",
    "### Разное\n",
    "[Non-Zero Initial States for Recurrent Neural Networks](https://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html)\n",
    "\n",
    "[Explaining and illustrating orthogonal initialization for recurrent neural networks, Stephen Merity](http://smerity.com/articles/2016/orthogonal_init.html)\n",
    "\n",
    "[Comparative Study of CNN and RNN for Natural Language Processing, Yin, 2017](https://arxiv.org/abs/1702.01923)\n",
    "\n",
    "## Посмотреть\n",
    "[cs224n \"Lecture 8: Recurrent Neural Networks and Language Models\"](https://www.youtube.com/watch?v=Keqep_PKrY8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdMatMdGKq9X"
   },
   "source": [
    "# Сдача задания\n",
    "\n",
    "[Опрос](https://goo.gl/forms/6d04Bkk36mVpBYt32)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 05 - RNNs Intro.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
