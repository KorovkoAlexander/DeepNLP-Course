{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P59NYU98GCb9"
   },
   "outputs": [],
   "source": [
    "# !pip3 -qq install torch==0.4.1\n",
    "#!pip install bokeh==0.13.0\n",
    "#!pip install gensim==3.6.0\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6CNKM3b4hT1"
   },
   "source": [
    "# Рекуррентные нейронные сети, часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_XkoGNQUeGm"
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFEtWrS_4rUs"
   },
   "source": [
    "Мы уже посмотрели на применение рекуррентных сетей для классификации.\n",
    "\n",
    "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg \" \")\n",
    "\n",
    "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n",
    "Перейдем к ещё одному варианту - sequence labeling (последняя картинка).\n",
    "\n",
    "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
    "\n",
    "Мы порешаем сейчас POS Tagging для английского.\n",
    "\n",
    "Будем работать с таким набором тегов:\n",
    "- ADJ - adjective (new, good, high, ...)\n",
    "- ADP - adposition (on, of, at, ...)\n",
    "- ADV - adverb (really, already, still, ...)\n",
    "- CONJ - conjunction (and, or, but, ...)\n",
    "- DET - determiner, article (the, a, some, ...)\n",
    "- NOUN - noun (year, home, costs, ...)\n",
    "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
    "- PRT - particle (at, on, out, ...)\n",
    "- PRON - pronoun (he, their, her, ...)\n",
    "- VERB - verb (is, say, told, ...)\n",
    "- . - punctuation marks (. , ;)\n",
    "- X - other (ersatz, esprit, dunno, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPIkKdFlHB-X"
   },
   "source": [
    "Скачаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiA2dGmgF1rW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/alexander/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/alexander/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QstS4NO0L97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The            \tDET\n",
      "Fulton         \tNOUN\n",
      "County         \tNOUN\n",
      "Grand          \tADJ\n",
      "Jury           \tNOUN\n",
      "said           \tVERB\n",
      "Friday         \tNOUN\n",
      "an             \tDET\n",
      "investigation  \tNOUN\n",
      "of             \tADP\n",
      "Atlanta's      \tNOUN\n",
      "recent         \tADJ\n",
      "primary        \tNOUN\n",
      "election       \tNOUN\n",
      "produced       \tVERB\n",
      "``             \t.\n",
      "no             \tDET\n",
      "evidence       \tNOUN\n",
      "''             \t.\n",
      "that           \tADP\n",
      "any            \tDET\n",
      "irregularities \tNOUN\n",
      "took           \tVERB\n",
      "place          \tNOUN\n",
      ".              \t.\n"
     ]
    }
   ],
   "source": [
    "for word, tag in data[0]:\n",
    "    print('{:15}\\t{}'.format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epdW8u_YXcAv"
   },
   "source": [
    "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
    "\n",
    "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTai8Ta0lgwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count in train set: 739769\n",
      "Words count in val set: 130954\n",
      "Words count in test set: 290469\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
    "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
    "print('Words count in test set:', sum(len(sent) for sent in test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eChdLNGtXyP0"
   },
   "source": [
    "Построим маппинги из слов в индекс и из тега в индекс:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCjwwDs6Zq9x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in train = 45441. Tags = {'ADJ', 'PRON', 'NOUN', 'ADV', 'CONJ', 'NUM', '.', 'PRT', 'VERB', 'DET', 'X', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "words = {word for sample in train_data for word, tag in sample}\n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tags = {tag for sample in train_data for word, tag in sample}\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
    "tag2ind['<pad>'] = 0\n",
    "\n",
    "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URC1B2nvPGFt"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAEyCAYAAABH+Yw/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHZBJREFUeJzt3X20XXV95/H3p8ngsg8MKCmlgAY1aIHaKFnKarWDIhpsl2CX1TCtBMsYXcLqQJ2O2HYWTtUptnUyi6niwpoROkqgWgvjisWUYm1nihIk5UmBgCjJ8JCCynRwVPA7f5zflc31JvfmPv4u9/1a66x79nc/nO9J9j33c/bev3NSVUiSJKlfP7LQDUiSJGnvDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUueWL3QDs+2ggw6qlStXLnQbkiRJk7r++uv/qapWTLbcky6wrVy5km3bti10G5IkSZNK8rWpLOcpUUmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzk0a2JJsSvJAkpsHtcuSbG+3u5Nsb/WVSb49mPehwTrHJrkpyY4kFyRJqz8tydYkd7SfB7Z62nI7ktyY5IWz//QlSZL6N5UjbB8F1g4LVfWGqlpdVauBTwJ/MZh959i8qnrroH4h8GZgVbuNbfNc4OqqWgVc3aYBThosu6GtL0mStORM+l2iVfX5JCsnmteOkr0eePnetpHkEGD/qrq2TV8CnAJ8BjgZOL4tejHwOeAdrX5JVRVwbZIDkhxSVfdO+qz0pLBx6+3TXvecE4+cxU4kSVpYM72G7aXA/VV1x6B2RJIbkvxtkpe22qHAzsEyO1sN4OBBCLsPOHiwzj17WOcJkmxIsi3Jtt27d8/g6UiSJPVnpoHtVODSwfS9wDOq6gXAbwEfT7L/VDfWjqbVvjZRVRdV1ZqqWrNixYp9XV2SJKlrk54S3ZMky4FfAY4dq1XVd4DvtPvXJ7kTOBLYBRw2WP2wVgO4f+xUZzt1+kCr7wIO38M6kiRJS8ZMjrC9AvhKVf3gVGeSFUmWtfvPYjRg4K52yvPhJMe1695OA65oq10JrG/314+rn9ZGix4HfMvr1yRJ0lI0lY/1uBT4B+C5SXYmOaPNWscTT4cC/CJwY/uYj08Ab62qh9q8twF/CuwA7mQ04ADgfODEJHcwCoHnt/oW4K62/Ifb+pIkSUvOVEaJnrqH+ukT1D7J6GM+Jlp+G3DMBPUHgRMmqBdw5mT9SZIkPdn5TQeSJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUuUkDW5JNSR5IcvOg9q4ku5Jsb7dXD+a9M8mOJLcledWgvrbVdiQ5d1A/IskXWv2yJPu1+lPa9I42f+VsPWlJkqTFZCpH2D4KrJ2gvrGqVrfbFoAkRwHrgKPbOh9MsizJMuADwEnAUcCpbVmA97VtPQf4BnBGq58BfKPVN7blJEmSlpxJA1tVfR54aIrbOxnYXFXfqaqvAjuAF7Xbjqq6q6q+C2wGTk4S4OXAJ9r6FwOnDLZ1cbv/CeCEtrwkSdKSMpNr2M5KcmM7ZXpgqx0K3DNYZmer7an+dOCbVfXouPoTttXmf6stL0mStKRMN7BdCDwbWA3cC7x/1jqahiQbkmxLsm337t0L2YokSdKsm1Zgq6r7q+qxqvo+8GFGpzwBdgGHDxY9rNX2VH8QOCDJ8nH1J2yrzf+XbfmJ+rmoqtZU1ZoVK1ZM5ylJkiR1a1qBLckhg8nXAmMjSK8E1rURnkcAq4AvAtcBq9qI0P0YDUy4sqoKuAZ4XVt/PXDFYFvr2/3XAX/TlpckSVpSlk+2QJJLgeOBg5LsBM4Djk+yGijgbuAtAFV1S5LLgVuBR4Ezq+qxtp2zgKuAZcCmqrqlPcQ7gM1J3gPcAHyk1T8C/FmSHYwGPayb8bOVJElahCYNbFV16gTlj0xQG1v+vcB7J6hvAbZMUL+Lx0+pDuv/D/jVyfqTJEl6svObDiRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOmdgkyRJ6pyBTZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOmdgkyRJ6pyBTZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOTRrYkmxK8kCSmwe1P0rylSQ3JvlUkgNafWWSbyfZ3m4fGqxzbJKbkuxIckGStPrTkmxNckf7eWCrpy23oz3OC2f/6UuSJPVvKkfYPgqsHVfbChxTVc8HbgfeOZh3Z1Wtbre3DuoXAm8GVrXb2DbPBa6uqlXA1W0a4KTBshva+pIkSUvOpIGtqj4PPDSu9tmqerRNXgsctrdtJDkE2L+qrq2qAi4BTmmzTwYubvcvHle/pEauBQ5o25EkSVpSZuMatt8APjOYPiLJDUn+NslLW+1QYOdgmZ2tBnBwVd3b7t8HHDxY5549rCNJkrRkLJ/Jykl+F3gU+Fgr3Qs8o6oeTHIs8JdJjp7q9qqqktQ0+tjA6LQpz3jGM/Z1dUmSpK5N+whbktOBXwZ+rZ3mpKq+U1UPtvvXA3cCRwK7eOJp08NaDeD+sVOd7ecDrb4LOHwP6zxBVV1UVWuqas2KFSum+5QkSZK6NK3AlmQt8O+B11TVI4P6iiTL2v1nMRowcFc75flwkuPa6NDTgCvaalcC69v99ePqp7XRoscB3xqcOpUkSVoyJj0lmuRS4HjgoCQ7gfMYjQp9CrC1fTrHtW1E6C8Cv5/ke8D3gbdW1diAhbcxGnH6VEbXvI1d93Y+cHmSM4CvAa9v9S3Aq4EdwCPAm2byRCVJkharSQNbVZ06Qfkje1j2k8An9zBvG3DMBPUHgRMmqBdw5mT9SZIkPdn5TQeSJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1LkZfZeoJEk92Lj19hmtf86JR85SJ9Lc8AibJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktS5KQW2JJuSPJDk5kHtaUm2Jrmj/Tyw1ZPkgiQ7ktyY5IWDdda35e9Isn5QPzbJTW2dC5Jkb48hSZK0lEz1CNtHgbXjaucCV1fVKuDqNg1wErCq3TYAF8IofAHnAS8GXgScNwhgFwJvHqy3dpLHkCRJWjKmFNiq6vPAQ+PKJwMXt/sXA6cM6pfUyLXAAUkOAV4FbK2qh6rqG8BWYG2bt39VXVtVBVwyblsTPYYkSdKSMZNr2A6uqnvb/fuAg9v9Q4F7BsvtbLW91XdOUN/bYzxBkg1JtiXZtnv37mk+HUmSpD7NyqCDdmSsZmNb03mMqrqoqtZU1ZoVK1bMZRuSJEnzbiaB7f52OpP284FW3wUcPljusFbbW/2wCep7ewxJkqQlYyaB7UpgbKTneuCKQf20Nlr0OOBb7bTmVcArkxzYBhu8EriqzXs4yXFtdOhp47Y10WNIkiQtGcunslCSS4HjgYOS7GQ02vN84PIkZwBfA17fFt8CvBrYATwCvAmgqh5K8m7gurbc71fV2ECGtzEaifpU4DPtxl4eQ5IkacmYUmCrqlP3MOuECZYt4Mw9bGcTsGmC+jbgmAnqD070GJIkSUuJ33QgSZLUOQObJElS5wxskiRJnZvSNWySpOnbuPX2aa97zolHzmInkhYrj7BJkiR1zsAmSZLUOU+JSpKkJ6WZXI4AfV2S4BE2SZKkzhnYJEmSOmdgkyRJ6pyBTZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcn8MmSdIC8CvLtC88wiZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktS5aQe2JM9Nsn1wezjJ2UnelWTXoP7qwTrvTLIjyW1JXjWor221HUnOHdSPSPKFVr8syX7Tf6qSJEmL07QDW1XdVlWrq2o1cCzwCPCpNnvj2Lyq2gKQ5ChgHXA0sBb4YJJlSZYBHwBOAo4CTm3LAryvbes5wDeAM6bbryRJ0mI1W6dETwDurKqv7WWZk4HNVfWdqvoqsAN4UbvtqKq7quq7wGbg5CQBXg58oq1/MXDKLPUrSZK0aMxWYFsHXDqYPivJjUk2JTmw1Q4F7hkss7PV9lR/OvDNqnp0XP2HJNmQZFuSbbt37575s5EkSerIjANbu67sNcCft9KFwLOB1cC9wPtn+hiTqaqLqmpNVa1ZsWLFXD+cJEnSvFo+C9s4CfhSVd0PMPYTIMmHgU+3yV3A4YP1Dms19lB/EDggyfJ2lG24vCRJ0pIxG6dET2VwOjTJIYN5rwVubvevBNYleUqSI4BVwBeB64BVbUTofoxOr15ZVQVcA7yurb8euGIW+pUkSVpUZnSELcmPAScCbxmU/zDJaqCAu8fmVdUtSS4HbgUeBc6sqsfads4CrgKWAZuq6pa2rXcAm5O8B7gB+MhM+pUkSVqMZhTYqur/MhocMKy9cS/Lvxd47wT1LcCWCep3MRpFKkmStGT5TQeSJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1bvlCN7AYbdx6+4zWP+fEI2epE0mStBR4hE2SJKlzMw5sSe5OclOS7Um2tdrTkmxNckf7eWCrJ8kFSXYkuTHJCwfbWd+WvyPJ+kH92Lb9HW3dzLRnSZKkxWS2jrC9rKpWV9WaNn0ucHVVrQKubtMAJwGr2m0DcCGMAh5wHvBi4EXAeWMhry3z5sF6a2epZ0mSpEVhrk6Jngxc3O5fDJwyqF9SI9cCByQ5BHgVsLWqHqqqbwBbgbVt3v5VdW1VFXDJYFuSJElLwmwEtgI+m+T6JBta7eCqurfdvw84uN0/FLhnsO7OVttbfecE9SdIsiHJtiTbdu/ePdPnI0mS1JXZGCX6kqraleQnga1JvjKcWVWVpGbhcfaoqi4CLgJYs2bNnD6WJEnSfJvxEbaq2tV+PgB8itE1aPe305m0nw+0xXcBhw9WP6zV9lY/bIK6JEnSkjGjwJbkx5L8xNh94JXAzcCVwNhIz/XAFe3+lcBpbbToccC32qnTq4BXJjmwDTZ4JXBVm/dwkuPa6NDTBtuSJElaEmZ6SvRg4FPtkzaWAx+vqr9Kch1weZIzgK8Br2/LbwFeDewAHgHeBFBVDyV5N3BdW+73q+qhdv9twEeBpwKfaTdJkqQlY0aBraruAn5ugvqDwAkT1As4cw/b2gRsmqC+DThmJn1KkiQtZn7TgSRJUucMbJIkSZ0zsEmSJHXOwCZJktQ5A5skSVLnDGySJEmdM7BJkiR1zsAmSZLUOQObJElS5wxskiRJnTOwSZIkdc7AJkmS1DkDmyRJUucMbJIkSZ0zsEmSJHVu+UI3ID2ZbNx6+7TXPefEI2exE0nSk4lH2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnB/rsUTM5OMmwI+ckCRpIXmETZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlz0w5sSQ5Pck2SW5PckuTftvq7kuxKsr3dXj1Y551JdiS5LcmrBvW1rbYjybmD+hFJvtDqlyXZb7r9SpIkLVYzOcL2KPD2qjoKOA44M8lRbd7GqlrdblsA2rx1wNHAWuCDSZYlWQZ8ADgJOAo4dbCd97VtPQf4BnDGDPqVJElalKYd2Krq3qr6Urv/f4AvA4fuZZWTgc1V9Z2q+iqwA3hRu+2oqruq6rvAZuDkJAFeDnyirX8xcMp0+5UkSVqsZuUatiQrgRcAX2ils5LcmGRTkgNb7VDgnsFqO1ttT/WnA9+sqkfH1Sd6/A1JtiXZtnv37ll4RpIkSf2Y8TcdJPlx4JPA2VX1cJILgXcD1X6+H/iNmT7O3lTVRcBFAGvWrKm5fCzpycRvwJCkxWFGgS3Jv2AU1j5WVX8BUFX3D+Z/GPh0m9wFHD5Y/bBWYw/1B4EDkixvR9mGy0uSJC0ZMxklGuAjwJer6j8P6ocMFnstcHO7fyWwLslTkhwBrAK+CFwHrGojQvdjNDDhyqoq4BrgdW399cAV0+1XkiRpsZrJEbZfAN4I3JRke6v9DqNRnqsZnRK9G3gLQFXdkuRy4FZGI0zPrKrHAJKcBVwFLAM2VdUtbXvvADYneQ9wA6OAKEmStKRMO7BV1d8DmWDWlr2s817gvRPUt0y0XlXdxWgUqSRJ0pLlNx1IkiR1zsAmSZLUOQObJElS52b8OWySpCcXP59P6o9H2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOmdgkyRJ6pyBTZIkqXMGNkmSpM4Z2CRJkjq3fKEbkKR9sXHr7TNa/5wTj5ylTiRp/niETZIkqXMGNkmSpM4Z2CRJkjpnYJMkSeqcgU2SJKlzBjZJkqTOGdgkSZI6Z2CTJEnqnIFNkiSpc90HtiRrk9yWZEeScxe6H0mSpPnWdWBLsgz4AHAScBRwapKjFrYrSZKk+dV1YANeBOyoqruq6rvAZuDkBe5JkiRpXvX+5e+HAvcMpncCL16gXiRJWrI2br19Ruufc+KRs9TJ0pSqWuge9ijJ64C1VfVv2vQbgRdX1VnjltsAbGiTzwVum9dGf9hBwD8tcA/7yp7n3mLrF+x5Piy2fsGe58ti63mx9Qt99PzMqlox2UK9H2HbBRw+mD6s1Z6gqi4CLpqvpiaTZFtVrVnoPvaFPc+9xdYv2PN8WGz9gj3Pl8XW82LrFxZXz71fw3YdsCrJEUn2A9YBVy5wT5IkSfOq6yNsVfVokrOAq4BlwKaqumWB25IkSZpXXQc2gKraAmxZ6D72UTenZ/eBPc+9xdYv2PN8WGz9gj3Pl8XW82LrFxZRz10POpAkSVL/17BJkiQteQY2SZKkzhnYZiDJKUkqyfPa9Mok305yQ5IvJ/liktMHy5+e5E/moa/HkmxPcnOSP0/yoxPU/0eSAwbrHJ3kb9r3tt6R5D8kyaDv7yd5/mD5m5OsnKV+K8n7B9P/Lsm7BtMbknyl3b6Y5CWDeXcnOWgwfXyST89H3xM8jynvD23eziQ/Mm4b25PM6YdDJ/mpJJuT3Jnk+iRbkhw5k31g/P/DHPS8x30kyUfbZzYOl//n9nNlW/c9g3kHJfnefPwuLlb78hqS5GdbbXuSh5J8td3/6znq7ZokrxpXOzvJZ9rv2/bB7bQ2/+4kNyW5McnfJnnmBM/1H5N8KcnPz0XfEzyPsce9pT3228deD9rr2LfGPZc3DO7fl2TXYHq/+eh5D8/j8PZ//rQ2fWCbXrlQPQ3ty+tym396kt3t3/XWJG9esObHMbDNzKnA37efY+6sqhdU1c8w+hiSs5O8aZ77+nZVra6qY4DvAm+doP4QcCZAkqcy+riU86vqucDPAT8PvG2wzZ3A785Rv98BfmWiP/hJfhl4C/CSqnpeey4fT/JTU9z2XPY93pT3h6q6G/g68NKxBdsLyk9U1RfmqsEWwD4FfK6qnl1VxwLvBA5mYfeByexxH5mCrwK/NJj+VcDR5ns35deQqrqp1VYz2od+u02/Yo56u5TR79LQOuAPGP2+rR7cLhks87Kqej7wOeD3BvWx5/RzjH4X/mCO+h5v7HGPBk5k9J3Z5w3m/92453LZ4N/5Q8DGwbzvzlPPP6Sq7gEuBM5vpfOBi9prXA+m83f6svbvfDzwn5IcPG/d7oWBbZqS/DjwEuAMfvjFA4Cqugv4LeA357G18f4OeM4E9X9g9NVfAP8a+J9V9VmAqnoEOAs4d7D8p4Gjkzx3Dnp8lNFInXMmmPcORn8A/qn19iXgYlrYnIK57PsHprk/jP/Ds47R9+XOpZcB36uqDw36+kfgSBZ2H5jM3vaRyTwCfDnJ2IdjvgG4fLYaWwKm8hoynz4B/NLYUaV2JOeneeLXGO7N3vreH/jGDPvbZ1X1AKNv6zlr7Kj2IrMROC7J2YxeB/94gfsBZv53uv2/3Ak8c/y8hWBgm76Tgb+qqtuBB5Mcu4flvgQ8b/7aelyS5Yzetd00rr4MOIHHP4T4aOD64TJVdSfw40n2b6XvA38I/M4ctfsB4NeS/Mtx9R/qDdjW6lMx132Pmc7+cDlwSvt/glGQuHRu2+QYfvjfE/rYByazp31kKjYD65IcDjwG/O9Z7exJah9eQ+ZNVT0EfLH1BaM/xJcDBTx73GnEl06wibXAXw6mn9qW/Qrwp8C757D9PWrBYRnwk6300nHP5dkL0ddUVNX3gN9mFNzObtM9mNHf6STPAp4F7Ji7FqfOwDZ9p/L40ZDNPPFw69BCvFt6apLtjILN14GPjKvfx+gU2NZ93O7HGb2LOmLWOm2q6mHgEvb9aOREn0szvjZnfQ/s8/5QVfcDNwMnJFkNPFpVN89hj7NhPv4tJ7SXfWQq+8BfMTrttA64bPa7e9KZq9eQ2TI8Or2Ox9/ojD8l+neDda5JsotR0Bu+MRo7Nfk8RmHukk6Oco0/JXrnQjc0iZOAexm9KezFdP9Ov6Ht55cCb2lvEhZc9x+c26N2ceXLgZ9NUozeFRWjIwDjvQD48jy2B+0FaE/1jC4gvorRacULgFuBXxwu2N5Z/HNVPTz22tW+eeL9jE5TzoX/wuidzn8b1G4FjgX+ZlA7lsevQXoQOJDHv7z3aYz7It+57nuG+8PYH577mfujazD6d3vdBPVe9oHJTLSPjO0DwA/+P8bvA99Ncj3wduAo4DVz3+qitq+vIfPtCmBjkhcCP1pV10/hIveXAd8EPgb8R0anwZ6gqv6hXSe5AnhgVjueRPt9e6w97s/M52PPVHvDeSJwHPD3STZX1b0L3NNMXpcvq6qz5r7LfeMRtul5HfBnVfXMqlpZVYczurB5+EX1Y9dW/DHwX+e9w71o1yf9JvD2dsrjY8BLkrwCfjAI4QJGp7/G+yjwCkYvaLPd10OMTm2cMSj/IfC+JE9vva0GTgc+2OZ/Dnhjm7cM+HXgmvnsm5ntD38BvJrR6dC5vn4NRsH3KUk2DPp6PnAbHewDk9nDPvI5Ru+Ix0bKnc7E+8D7gXf08m55MZvgNWS+H/+fGf0fb2If3uhU1aPA2cBpY6Mah9rAn2WM3gTMmyQrGA0k+JNaZJ9m345GXsjoVOjXgT+ij2vYFvXf6YkY2KbnVEYj7YY+yWiE0bPHhgsz+sNyQVWNHQ1Yzmi024KrqhuAG4FTq+rbjM71/16S2xhdr3Id8EMfe9BGI13A49dZzLb3Az8YCVhVVzJ6Uf5f7RqTDwO/Pnj39m7gOUn+EbiB0bUG/32e+57u/kBVfZPRRdD3t2tY5lT7Y/Ba4BUZfazHLYxGxd3HzPaB+dy3x+8jn2Z0Yfz17TTGLzDBEcCquqWqLp6nHqcso49V+emF7mNfDV9DFqiFSxmNZh4GtvHXsE10Ifm9bZ2xgUtj17BtZ3S6fH1VPTbXzQ8e9xbgr4HPMjryN2b8NWwTHRnvwZuBr1fV2OnxDwI/k+RfLWBPMIPX5V751VTzKMlG4I6q+uCkC0uLRDs6sL2qFmLEoCQtCR5hmydJPgM8n9HpR+lJIclrGB3deudC9yJJT2YeYZMkSeqcR9gkSZI6Z2CTJEnqnIFNkiSpcwY2SZKkzhnYJEmSOvf/AZCufOQubo51AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
    "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bar_width = 0.35\n",
    "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(tags)), tags)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gArQwbzWWkgi"
   },
   "source": [
    "## Бейзлайн\n",
    "\n",
    "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
    "\n",
    "![tag-context](https://www.nltk.org/images/tag-context.png \" \")  \n",
    "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
    "\n",
    "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
    "\n",
    "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
    "\n",
    "Простейший вариант - униграммная модель, учитывающая только слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rWmSToIaeAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of unigram tagger = 92.62%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07Ymb_MkbWsF"
   },
   "source": [
    "Добавим вероятности переходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjz_Rk0bbMyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of bigram tagger = 93.42%\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWMw6QHvbaDd"
   },
   "source": [
    "Обратите внимание, что `backoff` важен:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XCuxEBVbOY_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trigram tagger = 23.33%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_data)\n",
    "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4t3xyYd__8d-"
   },
   "source": [
    "## Увеличиваем контекст с рекуррентными сетями\n",
    "\n",
    "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
    "\n",
    "Омонимия - основная причина, почему униграмная модель плоха:\n",
    "*“he cashed a check at the **bank**”*  \n",
    "vs  \n",
    "*“he sat on the **bank** of the river”*\n",
    "\n",
    "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
    "\n",
    "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
    "\n",
    "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png \" \")\n",
    "\n",
    "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4XsRII5kW5x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[12117., 10563., 37682., 43738.],\n",
       "        [24561., 44054., 39575., 32846.],\n",
       "        [25542., 39530., 31529., 12069.],\n",
       "        [43738., 20292., 28826., 23651.],\n",
       "        [ 2735., 16409., 25542., 39530.],\n",
       "        [39530.,  6202.,  6159.,  3519.],\n",
       "        [43738.,  7288., 39530., 11441.],\n",
       "        [26247., 27813., 18150., 35823.],\n",
       "        [25344., 16802., 37359., 29200.],\n",
       "        [17727., 43738., 43738., 44825.],\n",
       "        [39530., 44774., 21504., 39530.],\n",
       "        [ 9621.,  4128., 16331., 29200.],\n",
       "        [38662., 39530., 43738., 29334.],\n",
       "        [42193., 42842., 32492., 28399.],\n",
       "        [    0.,  8695., 11200., 33513.],\n",
       "        [    0.,  5802., 39530., 36170.],\n",
       "        [    0., 17941., 43738., 39575.],\n",
       "        [    0., 16331., 17439., 21101.],\n",
       "        [    0., 43738., 16331., 17187.],\n",
       "        [    0., 36009., 10656., 19731.],\n",
       "        [    0., 16331., 16063., 25542.],\n",
       "        [    0.,   234.,  5208., 27647.],\n",
       "        [    0., 42193., 15805., 42193.],\n",
       "        [    0.,     0., 14429.,     0.],\n",
       "        [    0.,     0.,  4354.,     0.],\n",
       "        [    0.,     0., 37165.,     0.],\n",
       "        [    0.,     0.,  9621.,     0.],\n",
       "        [    0.,     0., 33513.,     0.],\n",
       "        [    0.,     0., 26244.,     0.],\n",
       "        [    0.,     0.,  4374.,     0.],\n",
       "        [    0.,     0., 43058.,     0.],\n",
       "        [    0.,     0., 42193.,     0.]]), array([[11.,  3.,  9., 10.],\n",
       "        [ 3.,  3., 12.,  3.],\n",
       "        [12.,  7.,  3.,  9.],\n",
       "        [10.,  2.,  4.,  1.],\n",
       "        [ 3.,  9., 12.,  7.],\n",
       "        [ 7.,  3.,  3., 10.],\n",
       "        [10., 11.,  7.,  3.],\n",
       "        [ 3., 11.,  3.,  1.],\n",
       "        [12., 12.,  9.,  5.],\n",
       "        [ 3., 10., 10.,  9.],\n",
       "        [ 7.,  9.,  3.,  7.],\n",
       "        [ 2.,  3., 12.,  5.],\n",
       "        [ 9.,  7., 10.,  8.],\n",
       "        [ 7.,  9.,  1.,  9.],\n",
       "        [ 0.,  6.,  3.,  4.],\n",
       "        [ 0.,  4.,  7.,  9.],\n",
       "        [ 0.,  1., 10.,  8.],\n",
       "        [ 0., 12.,  3.,  9.],\n",
       "        [ 0., 10., 12.,  1.],\n",
       "        [ 0.,  3., 10.,  3.],\n",
       "        [ 0., 12., 10., 12.],\n",
       "        [ 0.,  3.,  3.,  2.],\n",
       "        [ 0.,  7.,  9.,  7.],\n",
       "        [ 0.,  0.,  9.,  0.],\n",
       "        [ 0.,  0.,  9.,  0.],\n",
       "        [ 0.,  0.,  9.,  0.],\n",
       "        [ 0.,  0.,  2.,  0.],\n",
       "        [ 0.,  0.,  4.,  0.],\n",
       "        [ 0.,  0., 10.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  3.,  0.],\n",
       "        [ 0.,  0.,  7.,  0.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "\n",
    "X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5I9E9P6eFYv"
   },
   "source": [
    "**Задание** Реализуйте `LSTMTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count,)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim, len(tag2ind))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        x, hidden = self.lstm(x)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_HA8zyheYGH"
   },
   "source": [
    "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbrxsZ2mehWB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.), tensor(92.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ")\n",
    "\n",
    "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "logits = model(X_batch)\n",
    "\n",
    "def get_accuracy(logits, target):\n",
    "    preds = torch.argmax(torch.sigmoid(logits), dim =2).reshape(-1)\n",
    "    y_true = target.reshape(-1)\n",
    "    return ((y_true == preds).float()*(y_true != 0).float()).sum(), (y_true != 0).float().sum()\n",
    "    \n",
    "get_accuracy(logits, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMUyUm1hgpe3"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "loss = criterion(logits.reshape((-1, len(tag2ind))), y_batch.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSgV3NPUpcjH"
   },
   "source": [
    "**Задание** Вставьте эти вычисление в функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    correct_count = 0\n",
    "    sum_count = 0\n",
    "    \n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
    "                logits = model(X_batch)\n",
    "\n",
    "                loss = criterion(logits.reshape((-1, len(tag2ind))), y_batch.reshape(-1))\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                cur_correct_count, cur_sum_count = get_accuracy(logits, y_batch)\n",
    "                correct_count += cur_correct_count\n",
    "                sum_count += cur_sum_count\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, correct_count / sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pqfbeh1ltEYa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 50] Train: Loss = 0.31694, Accuracy = 71.41%: 100%|██████████| 572/572 [00:05<00:00, 99.05it/s] \n",
      "[1 / 50]   Val: Loss = 0.10786, Accuracy = 84.91%: 100%|██████████| 13/13 [00:00<00:00, 82.28it/s]\n",
      "[2 / 50] Train: Loss = 0.10155, Accuracy = 89.85%: 100%|██████████| 572/572 [00:05<00:00, 99.89it/s] \n",
      "[2 / 50]   Val: Loss = 0.07664, Accuracy = 89.60%: 100%|██████████| 13/13 [00:00<00:00, 83.10it/s]\n",
      "[3 / 50] Train: Loss = 0.06807, Accuracy = 93.16%: 100%|██████████| 572/572 [00:05<00:00, 101.07it/s]\n",
      "[3 / 50]   Val: Loss = 0.07008, Accuracy = 91.28%: 100%|██████████| 13/13 [00:00<00:00, 77.28it/s]\n",
      "[4 / 50] Train: Loss = 0.05095, Accuracy = 94.79%: 100%|██████████| 572/572 [00:05<00:00, 102.23it/s]\n",
      "[4 / 50]   Val: Loss = 0.06625, Accuracy = 92.27%: 100%|██████████| 13/13 [00:00<00:00, 85.95it/s]\n",
      "[5 / 50] Train: Loss = 0.04101, Accuracy = 95.80%: 100%|██████████| 572/572 [00:05<00:00, 99.46it/s] \n",
      "[5 / 50]   Val: Loss = 0.06756, Accuracy = 92.80%: 100%|██████████| 13/13 [00:00<00:00, 82.08it/s]\n",
      "[6 / 50] Train: Loss = 0.03342, Accuracy = 96.55%: 100%|██████████| 572/572 [00:05<00:00, 101.91it/s]\n",
      "[6 / 50]   Val: Loss = 0.06400, Accuracy = 93.14%: 100%|██████████| 13/13 [00:00<00:00, 80.68it/s]\n",
      "[7 / 50] Train: Loss = 0.02794, Accuracy = 97.11%: 100%|██████████| 572/572 [00:05<00:00, 99.69it/s] \n",
      "[7 / 50]   Val: Loss = 0.06641, Accuracy = 93.20%: 100%|██████████| 13/13 [00:00<00:00, 83.46it/s]\n",
      "[8 / 50] Train: Loss = 0.02314, Accuracy = 97.60%: 100%|██████████| 572/572 [00:05<00:00, 99.69it/s] \n",
      "[8 / 50]   Val: Loss = 0.06619, Accuracy = 93.36%: 100%|██████████| 13/13 [00:00<00:00, 83.09it/s]\n",
      "[9 / 50] Train: Loss = 0.01930, Accuracy = 97.98%: 100%|██████████| 572/572 [00:05<00:00, 102.83it/s]\n",
      "[9 / 50]   Val: Loss = 0.07481, Accuracy = 93.37%: 100%|██████████| 13/13 [00:00<00:00, 88.83it/s]\n",
      "[10 / 50] Train: Loss = 0.01623, Accuracy = 98.31%: 100%|██████████| 572/572 [00:05<00:00, 102.45it/s]\n",
      "[10 / 50]   Val: Loss = 0.07947, Accuracy = 93.32%: 100%|██████████| 13/13 [00:00<00:00, 87.16it/s]\n",
      "[11 / 50] Train: Loss = 0.01339, Accuracy = 98.62%: 100%|██████████| 572/572 [00:05<00:00, 100.37it/s]\n",
      "[11 / 50]   Val: Loss = 0.07146, Accuracy = 93.34%: 100%|██████████| 13/13 [00:00<00:00, 80.27it/s]\n",
      "[12 / 50] Train: Loss = 0.01113, Accuracy = 98.88%: 100%|██████████| 572/572 [00:05<00:00, 100.73it/s] \n",
      "[12 / 50]   Val: Loss = 0.08173, Accuracy = 93.34%: 100%|██████████| 13/13 [00:00<00:00, 84.00it/s]\n",
      "[13 / 50] Train: Loss = 0.00902, Accuracy = 99.10%: 100%|██████████| 572/572 [00:05<00:00, 98.85it/s] \n",
      "[13 / 50]   Val: Loss = 0.07840, Accuracy = 93.21%: 100%|██████████| 13/13 [00:00<00:00, 80.20it/s]\n",
      "[14 / 50] Train: Loss = 0.00741, Accuracy = 99.28%: 100%|██████████| 572/572 [00:05<00:00, 98.37it/s] \n",
      "[14 / 50]   Val: Loss = 0.08048, Accuracy = 93.23%: 100%|██████████| 13/13 [00:00<00:00, 76.22it/s]\n",
      "[15 / 50] Train: Loss = 0.00603, Accuracy = 99.42%: 100%|██████████| 572/572 [00:05<00:00, 100.73it/s]\n",
      "[15 / 50]   Val: Loss = 0.09044, Accuracy = 93.20%: 100%|██████████| 13/13 [00:00<00:00, 85.11it/s]\n",
      "[16 / 50] Train: Loss = 0.00490, Accuracy = 99.54%: 100%|██████████| 572/572 [00:05<00:00, 101.79it/s] \n",
      "[16 / 50]   Val: Loss = 0.09149, Accuracy = 93.18%: 100%|██████████| 13/13 [00:00<00:00, 73.49it/s]\n",
      "[17 / 50] Train: Loss = 0.00405, Accuracy = 99.63%: 100%|██████████| 572/572 [00:05<00:00, 101.03it/s] \n",
      "[17 / 50]   Val: Loss = 0.09681, Accuracy = 93.14%: 100%|██████████| 13/13 [00:00<00:00, 81.95it/s]\n",
      "[18 / 50] Train: Loss = 0.00329, Accuracy = 99.70%: 100%|██████████| 572/572 [00:05<00:00, 100.23it/s] \n",
      "[18 / 50]   Val: Loss = 0.10764, Accuracy = 93.08%: 100%|██████████| 13/13 [00:00<00:00, 87.75it/s]\n",
      "[19 / 50] Train: Loss = 0.00279, Accuracy = 99.75%: 100%|██████████| 572/572 [00:05<00:00, 100.71it/s] \n",
      "[19 / 50]   Val: Loss = 0.10601, Accuracy = 93.15%: 100%|██████████| 13/13 [00:00<00:00, 80.22it/s]\n",
      "[20 / 50] Train: Loss = 0.00252, Accuracy = 99.77%: 100%|██████████| 572/572 [00:05<00:00, 100.99it/s] \n",
      "[20 / 50]   Val: Loss = 0.11254, Accuracy = 93.07%: 100%|██████████| 13/13 [00:00<00:00, 86.33it/s]\n",
      "[21 / 50] Train: Loss = 0.00251, Accuracy = 99.77%: 100%|██████████| 572/572 [00:05<00:00, 100.81it/s] \n",
      "[21 / 50]   Val: Loss = 0.11054, Accuracy = 93.03%: 100%|██████████| 13/13 [00:00<00:00, 79.27it/s]\n",
      "[22 / 50] Train: Loss = 0.00202, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 103.14it/s] \n",
      "[22 / 50]   Val: Loss = 0.12194, Accuracy = 93.08%: 100%|██████████| 13/13 [00:00<00:00, 88.44it/s]\n",
      "[23 / 50] Train: Loss = 0.00187, Accuracy = 99.82%: 100%|██████████| 572/572 [00:05<00:00, 102.19it/s] \n",
      "[23 / 50]   Val: Loss = 0.11741, Accuracy = 93.10%: 100%|██████████| 13/13 [00:00<00:00, 79.17it/s]\n",
      "[24 / 50] Train: Loss = 0.00185, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 100.28it/s] \n",
      "[24 / 50]   Val: Loss = 0.13128, Accuracy = 93.06%: 100%|██████████| 13/13 [00:00<00:00, 87.25it/s]\n",
      "[25 / 50] Train: Loss = 0.00199, Accuracy = 99.79%: 100%|██████████| 572/572 [00:05<00:00, 99.96it/s]  \n",
      "[25 / 50]   Val: Loss = 0.12129, Accuracy = 93.02%: 100%|██████████| 13/13 [00:00<00:00, 80.69it/s]\n",
      "[26 / 50] Train: Loss = 0.00182, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 100.57it/s] \n",
      "[26 / 50]   Val: Loss = 0.12730, Accuracy = 93.08%: 100%|██████████| 13/13 [00:00<00:00, 77.22it/s]\n",
      "[27 / 50] Train: Loss = 0.00165, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 99.99it/s]  \n",
      "[27 / 50]   Val: Loss = 0.13377, Accuracy = 93.06%: 100%|██████████| 13/13 [00:00<00:00, 84.76it/s]\n",
      "[28 / 50] Train: Loss = 0.00161, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 98.97it/s]  \n",
      "[28 / 50]   Val: Loss = 0.12596, Accuracy = 93.06%: 100%|██████████| 13/13 [00:00<00:00, 80.91it/s]\n",
      "[29 / 50] Train: Loss = 0.00169, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 101.89it/s] \n",
      "[29 / 50]   Val: Loss = 0.13651, Accuracy = 93.02%: 100%|██████████| 13/13 [00:00<00:00, 80.42it/s]\n",
      "[30 / 50] Train: Loss = 0.00181, Accuracy = 99.78%: 100%|██████████| 572/572 [00:05<00:00, 101.97it/s] \n",
      "[30 / 50]   Val: Loss = 0.13840, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 85.04it/s]\n",
      "[31 / 50] Train: Loss = 0.00155, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 99.56it/s]  \n",
      "[31 / 50]   Val: Loss = 0.14024, Accuracy = 93.11%: 100%|██████████| 13/13 [00:00<00:00, 81.31it/s]\n",
      "[32 / 50] Train: Loss = 0.00145, Accuracy = 99.82%: 100%|██████████| 572/572 [00:05<00:00, 98.84it/s]  \n",
      "[32 / 50]   Val: Loss = 0.13800, Accuracy = 93.05%: 100%|██████████| 13/13 [00:00<00:00, 83.50it/s]\n",
      "[33 / 50] Train: Loss = 0.00148, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 100.87it/s] \n",
      "[33 / 50]   Val: Loss = 0.14327, Accuracy = 93.08%: 100%|██████████| 13/13 [00:00<00:00, 88.97it/s]\n",
      "[34 / 50] Train: Loss = 0.00151, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 101.46it/s] \n",
      "[34 / 50]   Val: Loss = 0.15181, Accuracy = 93.03%: 100%|██████████| 13/13 [00:00<00:00, 85.35it/s]\n",
      "[35 / 50] Train: Loss = 0.00189, Accuracy = 99.76%: 100%|██████████| 572/572 [00:05<00:00, 102.85it/s] \n",
      "[35 / 50]   Val: Loss = 0.13835, Accuracy = 92.97%: 100%|██████████| 13/13 [00:00<00:00, 81.63it/s]\n",
      "[36 / 50] Train: Loss = 0.00155, Accuracy = 99.79%: 100%|██████████| 572/572 [00:05<00:00, 98.07it/s]  \n",
      "[36 / 50]   Val: Loss = 0.15608, Accuracy = 93.05%: 100%|██████████| 13/13 [00:00<00:00, 85.65it/s]\n",
      "[37 / 50] Train: Loss = 0.00138, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 99.75it/s]  \n",
      "[37 / 50]   Val: Loss = 0.15409, Accuracy = 93.16%: 100%|██████████| 13/13 [00:00<00:00, 82.91it/s]\n",
      "[38 / 50] Train: Loss = 0.00131, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 99.84it/s]  \n",
      "[38 / 50]   Val: Loss = 0.14023, Accuracy = 93.11%: 100%|██████████| 13/13 [00:00<00:00, 81.28it/s]\n",
      "[39 / 50] Train: Loss = 0.00131, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 99.91it/s]  \n",
      "[39 / 50]   Val: Loss = 0.16754, Accuracy = 93.15%: 100%|██████████| 13/13 [00:00<00:00, 85.94it/s]\n",
      "[40 / 50] Train: Loss = 0.00132, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 101.24it/s] \n",
      "[40 / 50]   Val: Loss = 0.15725, Accuracy = 93.11%: 100%|██████████| 13/13 [00:00<00:00, 86.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[41 / 50] Train: Loss = 0.00175, Accuracy = 99.76%: 100%|██████████| 572/572 [00:05<00:00, 98.33it/s]  \n",
      "[41 / 50]   Val: Loss = 0.15788, Accuracy = 92.92%: 100%|██████████| 13/13 [00:00<00:00, 81.73it/s]\n",
      "[42 / 50] Train: Loss = 0.00212, Accuracy = 99.71%: 100%|██████████| 572/572 [00:05<00:00, 96.95it/s]  \n",
      "[42 / 50]   Val: Loss = 0.17239, Accuracy = 93.09%: 100%|██████████| 13/13 [00:00<00:00, 88.59it/s]\n",
      "[43 / 50] Train: Loss = 0.00143, Accuracy = 99.79%: 100%|██████████| 572/572 [00:05<00:00, 100.90it/s] \n",
      "[43 / 50]   Val: Loss = 0.16384, Accuracy = 93.11%: 100%|██████████| 13/13 [00:00<00:00, 82.63it/s]\n",
      "[44 / 50] Train: Loss = 0.00125, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 100.88it/s] \n",
      "[44 / 50]   Val: Loss = 0.16262, Accuracy = 93.13%: 100%|██████████| 13/13 [00:00<00:00, 85.30it/s]\n",
      "[45 / 50] Train: Loss = 0.00124, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 98.42it/s]  \n",
      "[45 / 50]   Val: Loss = 0.16167, Accuracy = 93.10%: 100%|██████████| 13/13 [00:00<00:00, 75.62it/s]\n",
      "[46 / 50] Train: Loss = 0.00122, Accuracy = 99.81%: 100%|██████████| 572/572 [00:05<00:00, 99.38it/s]  \n",
      "[46 / 50]   Val: Loss = 0.16539, Accuracy = 93.16%: 100%|██████████| 13/13 [00:00<00:00, 77.19it/s]\n",
      "[47 / 50] Train: Loss = 0.00126, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 100.53it/s] \n",
      "[47 / 50]   Val: Loss = 0.16031, Accuracy = 93.14%: 100%|██████████| 13/13 [00:00<00:00, 86.50it/s]\n",
      "[48 / 50] Train: Loss = 0.00127, Accuracy = 99.80%: 100%|██████████| 572/572 [00:05<00:00, 102.12it/s] \n",
      "[48 / 50]   Val: Loss = 0.16756, Accuracy = 93.18%: 100%|██████████| 13/13 [00:00<00:00, 88.12it/s]\n",
      "[49 / 50] Train: Loss = 0.00211, Accuracy = 99.70%: 100%|██████████| 572/572 [00:05<00:00, 102.71it/s] \n",
      "[49 / 50]   Val: Loss = 0.16640, Accuracy = 93.07%: 100%|██████████| 13/13 [00:00<00:00, 84.92it/s]\n",
      "[50 / 50] Train: Loss = 0.00165, Accuracy = 99.75%: 100%|██████████| 572/572 [00:05<00:00, 100.32it/s] \n",
      "[50 / 50]   Val: Loss = 0.17043, Accuracy = 93.18%: 100%|██████████| 13/13 [00:00<00:00, 85.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0qGetIhfUE5"
   },
   "source": [
    "### Masking\n",
    "\n",
    "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
    "\n",
    "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAfV2dEOfHo5"
   },
   "source": [
    "**Задание** Посчитайте качество модели на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98wr38_rw55D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXUTSFaEHbDG"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
    "\n",
    "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png \" \")  \n",
    "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
    "\n",
    "**Задание** Добавьте Bidirectional LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTaggerBidirectional(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count, bidirectional = True)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim*2, len(tag2ind))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        x, hidden = self.lstm(x)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 0.25371, Accuracy = 76.52%: 100%|██████████| 572/572 [00:07<00:00, 79.30it/s]\n",
      "[1 / 20]   Val: Loss = 0.07123, Accuracy = 89.57%: 100%|██████████| 13/13 [00:00<00:00, 65.47it/s]\n",
      "[2 / 20] Train: Loss = 0.07577, Accuracy = 92.60%: 100%|██████████| 572/572 [00:07<00:00, 81.36it/s]\n",
      "[2 / 20]   Val: Loss = 0.05010, Accuracy = 93.19%: 100%|██████████| 13/13 [00:00<00:00, 64.41it/s]\n",
      "[3 / 20] Train: Loss = 0.04941, Accuracy = 95.29%: 100%|██████████| 572/572 [00:07<00:00, 81.22it/s]\n",
      "[3 / 20]   Val: Loss = 0.04085, Accuracy = 94.56%: 100%|██████████| 13/13 [00:00<00:00, 70.57it/s]\n",
      "[4 / 20] Train: Loss = 0.03493, Accuracy = 96.70%: 100%|██████████| 572/572 [00:07<00:00, 78.60it/s]\n",
      "[4 / 20]   Val: Loss = 0.03634, Accuracy = 95.18%: 100%|██████████| 13/13 [00:00<00:00, 73.03it/s]\n",
      "[5 / 20] Train: Loss = 0.02576, Accuracy = 97.58%: 100%|██████████| 572/572 [00:07<00:00, 80.25it/s]\n",
      "[5 / 20]   Val: Loss = 0.03452, Accuracy = 95.53%: 100%|██████████| 13/13 [00:00<00:00, 67.30it/s]\n",
      "[6 / 20] Train: Loss = 0.01906, Accuracy = 98.24%: 100%|██████████| 572/572 [00:07<00:00, 79.87it/s]\n",
      "[6 / 20]   Val: Loss = 0.03483, Accuracy = 95.72%: 100%|██████████| 13/13 [00:00<00:00, 68.88it/s]\n",
      "[7 / 20] Train: Loss = 0.01381, Accuracy = 98.75%: 100%|██████████| 572/572 [00:07<00:00, 80.02it/s]\n",
      "[7 / 20]   Val: Loss = 0.03699, Accuracy = 95.83%: 100%|██████████| 13/13 [00:00<00:00, 69.17it/s]\n",
      "[8 / 20] Train: Loss = 0.00974, Accuracy = 99.14%: 100%|██████████| 572/572 [00:07<00:00, 79.20it/s]\n",
      "[8 / 20]   Val: Loss = 0.03701, Accuracy = 95.94%: 100%|██████████| 13/13 [00:00<00:00, 70.23it/s]\n",
      "[9 / 20] Train: Loss = 0.00662, Accuracy = 99.44%: 100%|██████████| 572/572 [00:07<00:00, 80.58it/s] \n",
      "[9 / 20]   Val: Loss = 0.03989, Accuracy = 96.02%: 100%|██████████| 13/13 [00:00<00:00, 71.30it/s]\n",
      "[10 / 20] Train: Loss = 0.00446, Accuracy = 99.65%: 100%|██████████| 572/572 [00:07<00:00, 80.96it/s] \n",
      "[10 / 20]   Val: Loss = 0.04191, Accuracy = 95.98%: 100%|██████████| 13/13 [00:00<00:00, 73.41it/s]\n",
      "[11 / 20] Train: Loss = 0.00286, Accuracy = 99.80%: 100%|██████████| 572/572 [00:06<00:00, 82.70it/s] \n",
      "[11 / 20]   Val: Loss = 0.04390, Accuracy = 95.99%: 100%|██████████| 13/13 [00:00<00:00, 70.92it/s]\n",
      "[12 / 20] Train: Loss = 0.00181, Accuracy = 99.89%: 100%|██████████| 572/572 [00:07<00:00, 80.47it/s] \n",
      "[12 / 20]   Val: Loss = 0.04334, Accuracy = 95.97%: 100%|██████████| 13/13 [00:00<00:00, 68.19it/s]\n",
      "[13 / 20] Train: Loss = 0.00132, Accuracy = 99.93%: 100%|██████████| 572/572 [00:07<00:00, 80.81it/s] \n",
      "[13 / 20]   Val: Loss = 0.04817, Accuracy = 96.04%: 100%|██████████| 13/13 [00:00<00:00, 69.30it/s]\n",
      "[14 / 20] Train: Loss = 0.00068, Accuracy = 99.98%: 100%|██████████| 572/572 [00:07<00:00, 81.68it/s] \n",
      "[14 / 20]   Val: Loss = 0.04678, Accuracy = 96.00%: 100%|██████████| 13/13 [00:00<00:00, 70.48it/s]\n",
      "[15 / 20] Train: Loss = 0.00040, Accuracy = 99.99%: 100%|██████████| 572/572 [00:07<00:00, 80.56it/s] \n",
      "[15 / 20]   Val: Loss = 0.05179, Accuracy = 96.12%: 100%|██████████| 13/13 [00:00<00:00, 70.55it/s]\n",
      "[16 / 20] Train: Loss = 0.00030, Accuracy = 99.99%: 100%|██████████| 572/572 [00:07<00:00, 80.76it/s] \n",
      "[16 / 20]   Val: Loss = 0.05241, Accuracy = 96.05%: 100%|██████████| 13/13 [00:00<00:00, 70.56it/s]\n",
      "[17 / 20] Train: Loss = 0.00026, Accuracy = 99.98%: 100%|██████████| 572/572 [00:07<00:00, 79.48it/s] \n",
      "[17 / 20]   Val: Loss = 0.05442, Accuracy = 96.01%: 100%|██████████| 13/13 [00:00<00:00, 62.39it/s]\n",
      "[18 / 20] Train: Loss = 0.00167, Accuracy = 99.82%: 100%|██████████| 572/572 [00:07<00:00, 79.14it/s] \n",
      "[18 / 20]   Val: Loss = 0.05087, Accuracy = 95.91%: 100%|██████████| 13/13 [00:00<00:00, 61.07it/s]\n",
      "[19 / 20] Train: Loss = 0.00062, Accuracy = 99.94%: 100%|██████████| 572/572 [00:07<00:00, 79.05it/s] \n",
      "[19 / 20]   Val: Loss = 0.05522, Accuracy = 95.85%: 100%|██████████| 13/13 [00:00<00:00, 70.19it/s]\n",
      "[20 / 20] Train: Loss = 0.00018, Accuracy = 99.98%: 100%|██████████| 572/572 [00:07<00:00, 79.12it/s] \n",
      "[20 / 20]   Val: Loss = 0.05673, Accuracy = 96.00%: 100%|██████████| 13/13 [00:00<00:00, 72.16it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTaggerBidirectional(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTXmYGD_ANhm"
   },
   "source": [
    "### Предобученные эмбеддинги\n",
    "\n",
    "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
    "\n",
    "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZpY_Q1xZ18h"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYogOoKlgtcf"
   },
   "source": [
    "Построим подматрицу для слов из нашей тренировочной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsCstxiO03oT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Know 38736 out of 45441 word embeddings\n"
     ]
    }
   ],
   "source": [
    "known_count = 0\n",
    "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
    "for word, ind in word2ind.items():\n",
    "    word = word.lower()\n",
    "    if word in w2v_model.vocab:\n",
    "        embeddings[ind] = w2v_model.get_vector(word)\n",
    "        known_count += 1\n",
    "        \n",
    "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45441, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcG7i-R8hbY3"
   },
   "source": [
    "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxaRBpQd0pat"
   },
   "outputs": [],
   "source": [
    "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding.from_pretrained(torch.Tensor(embeddings))\n",
    "        self.lstm = nn.LSTM(w2v_model.vectors.shape[1], lstm_hidden_dim, lstm_layers_count)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        x, hidden = self.lstm(x)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBtI6BDE-Fc7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 0.75980, Accuracy = 77.67%: 100%|██████████| 572/572 [00:03<00:00, 143.19it/s]\n",
      "[1 / 20]   Val: Loss = 0.37398, Accuracy = 88.83%: 100%|██████████| 13/13 [00:00<00:00, 106.30it/s]\n",
      "[2 / 20] Train: Loss = 0.28850, Accuracy = 91.36%: 100%|██████████| 572/572 [00:04<00:00, 130.39it/s]\n",
      "[2 / 20]   Val: Loss = 0.26221, Accuracy = 92.05%: 100%|██████████| 13/13 [00:00<00:00, 107.45it/s]\n",
      "[3 / 20] Train: Loss = 0.21270, Accuracy = 93.37%: 100%|██████████| 572/572 [00:04<00:00, 143.81it/s]\n",
      "[3 / 20]   Val: Loss = 0.21322, Accuracy = 93.24%: 100%|██████████| 13/13 [00:00<00:00, 112.14it/s]\n",
      "[4 / 20] Train: Loss = 0.17584, Accuracy = 94.39%: 100%|██████████| 572/572 [00:03<00:00, 145.79it/s]\n",
      "[4 / 20]   Val: Loss = 0.18785, Accuracy = 93.94%: 100%|██████████| 13/13 [00:00<00:00, 111.92it/s]\n",
      "[5 / 20] Train: Loss = 0.15417, Accuracy = 94.97%: 100%|██████████| 572/572 [00:04<00:00, 137.57it/s]\n",
      "[5 / 20]   Val: Loss = 0.17080, Accuracy = 94.43%: 100%|██████████| 13/13 [00:00<00:00, 100.85it/s]\n",
      "[6 / 20] Train: Loss = 0.13988, Accuracy = 95.37%: 100%|██████████| 572/572 [00:04<00:00, 131.02it/s]\n",
      "[6 / 20]   Val: Loss = 0.16136, Accuracy = 94.67%: 100%|██████████| 13/13 [00:00<00:00, 110.87it/s]\n",
      "[7 / 20] Train: Loss = 0.12976, Accuracy = 95.65%: 100%|██████████| 572/572 [00:04<00:00, 137.77it/s]\n",
      "[7 / 20]   Val: Loss = 0.15427, Accuracy = 94.87%: 100%|██████████| 13/13 [00:00<00:00, 108.91it/s]\n",
      "[8 / 20] Train: Loss = 0.12201, Accuracy = 95.86%: 100%|██████████| 572/572 [00:04<00:00, 136.42it/s]\n",
      "[8 / 20]   Val: Loss = 0.14985, Accuracy = 95.00%: 100%|██████████| 13/13 [00:00<00:00, 114.59it/s]\n",
      "[9 / 20] Train: Loss = 0.11601, Accuracy = 96.04%: 100%|██████████| 572/572 [00:04<00:00, 139.69it/s]\n",
      "[9 / 20]   Val: Loss = 0.14665, Accuracy = 95.07%: 100%|██████████| 13/13 [00:00<00:00, 121.43it/s]\n",
      "[10 / 20] Train: Loss = 0.11129, Accuracy = 96.19%: 100%|██████████| 572/572 [00:04<00:00, 138.77it/s]\n",
      "[10 / 20]   Val: Loss = 0.14457, Accuracy = 95.14%: 100%|██████████| 13/13 [00:00<00:00, 122.63it/s]\n",
      "[11 / 20] Train: Loss = 0.10718, Accuracy = 96.31%: 100%|██████████| 572/572 [00:04<00:00, 140.23it/s]\n",
      "[11 / 20]   Val: Loss = 0.14078, Accuracy = 95.28%: 100%|██████████| 13/13 [00:00<00:00, 108.55it/s]\n",
      "[12 / 20] Train: Loss = 0.10402, Accuracy = 96.40%: 100%|██████████| 572/572 [00:04<00:00, 136.73it/s]\n",
      "[12 / 20]   Val: Loss = 0.13923, Accuracy = 95.34%: 100%|██████████| 13/13 [00:00<00:00, 106.89it/s]\n",
      "[13 / 20] Train: Loss = 0.10108, Accuracy = 96.47%: 100%|██████████| 572/572 [00:04<00:00, 137.54it/s]\n",
      "[13 / 20]   Val: Loss = 0.14031, Accuracy = 95.32%: 100%|██████████| 13/13 [00:00<00:00, 104.83it/s]\n",
      "[14 / 20] Train: Loss = 0.09849, Accuracy = 96.56%: 100%|██████████| 572/572 [00:04<00:00, 136.23it/s]\n",
      "[14 / 20]   Val: Loss = 0.13566, Accuracy = 95.35%: 100%|██████████| 13/13 [00:00<00:00, 113.90it/s]\n",
      "[15 / 20] Train: Loss = 0.09634, Accuracy = 96.62%: 100%|██████████| 572/572 [00:04<00:00, 137.17it/s]\n",
      "[15 / 20]   Val: Loss = 0.13617, Accuracy = 95.42%: 100%|██████████| 13/13 [00:00<00:00, 109.04it/s]\n",
      "[16 / 20] Train: Loss = 0.09431, Accuracy = 96.70%: 100%|██████████| 572/572 [00:04<00:00, 135.04it/s]\n",
      "[16 / 20]   Val: Loss = 0.13566, Accuracy = 95.32%: 100%|██████████| 13/13 [00:00<00:00, 112.97it/s]\n",
      "[17 / 20] Train: Loss = 0.09235, Accuracy = 96.74%: 100%|██████████| 572/572 [00:04<00:00, 134.50it/s]\n",
      "[17 / 20]   Val: Loss = 0.13641, Accuracy = 95.28%: 100%|██████████| 13/13 [00:00<00:00, 118.33it/s]\n",
      "[18 / 20] Train: Loss = 0.09057, Accuracy = 96.80%: 100%|██████████| 572/572 [00:04<00:00, 138.46it/s]\n",
      "[18 / 20]   Val: Loss = 0.13593, Accuracy = 95.34%: 100%|██████████| 13/13 [00:00<00:00, 113.18it/s]\n",
      "[19 / 20] Train: Loss = 0.08910, Accuracy = 96.85%: 100%|██████████| 572/572 [00:04<00:00, 140.36it/s]\n",
      "[19 / 20]   Val: Loss = 0.13550, Accuracy = 95.38%: 100%|██████████| 13/13 [00:00<00:00, 112.66it/s]\n",
      "[20 / 20] Train: Loss = 0.08753, Accuracy = 96.93%: 100%|██████████| 572/572 [00:04<00:00, 135.98it/s]\n",
      "[20 / 20]   Val: Loss = 0.13621, Accuracy = 95.33%: 100%|██████████| 13/13 [00:00<00:00, 107.10it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTaggerWithPretrainedEmbs(\n",
    "    embeddings=embeddings,\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ne_8f24h8kg"
   },
   "source": [
    "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPUuAPGhEGVR"
   },
   "outputs": [],
   "source": [
    "<calc test accuracy>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enF9GAPAN3RB"
   },
   "source": [
    "### Дообучение предобученных векторов\n",
    "\n",
    "**Задание** Почему бы не попробовать дообучать вектора? Для этого нужно просто заменить флаг `freeze=False` в методе `from_pretrained`. Попробуйте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AdB6olUiyf7"
   },
   "outputs": [],
   "source": [
    "class LSTMTaggerWithPretrainedEmbsNonFreeze(nn.Module):\n",
    "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding.from_pretrained(torch.Tensor(embeddings), freeze=False)\n",
    "        self.lstm = nn.LSTM(w2v_model.vectors.shape[1], lstm_hidden_dim, lstm_layers_count)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        x, hidden = self.lstm(x)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 0.53423, Accuracy = 84.76%: 100%|██████████| 572/572 [00:05<00:00, 100.83it/s]\n",
      "[1 / 20]   Val: Loss = 0.16963, Accuracy = 94.70%: 100%|██████████| 13/13 [00:00<00:00, 113.35it/s]\n",
      "[2 / 20] Train: Loss = 0.11610, Accuracy = 96.13%: 100%|██████████| 572/572 [00:05<00:00, 101.79it/s]\n",
      "[2 / 20]   Val: Loss = 0.12865, Accuracy = 95.65%: 100%|██████████| 13/13 [00:00<00:00, 117.64it/s]\n",
      "[3 / 20] Train: Loss = 0.08292, Accuracy = 97.09%: 100%|██████████| 572/572 [00:05<00:00, 102.36it/s]\n",
      "[3 / 20]   Val: Loss = 0.11879, Accuracy = 95.91%: 100%|██████████| 13/13 [00:00<00:00, 118.91it/s]\n",
      "[4 / 20] Train: Loss = 0.06753, Accuracy = 97.57%: 100%|██████████| 572/572 [00:05<00:00, 98.27it/s] \n",
      "[4 / 20]   Val: Loss = 0.11694, Accuracy = 96.05%: 100%|██████████| 13/13 [00:00<00:00, 101.72it/s]\n",
      "[5 / 20] Train: Loss = 0.05791, Accuracy = 97.88%: 100%|██████████| 572/572 [00:05<00:00, 102.88it/s]\n",
      "[5 / 20]   Val: Loss = 0.11846, Accuracy = 96.10%: 100%|██████████| 13/13 [00:00<00:00, 118.08it/s]\n",
      "[6 / 20] Train: Loss = 0.05108, Accuracy = 98.12%: 100%|██████████| 572/572 [00:05<00:00, 99.62it/s] \n",
      "[6 / 20]   Val: Loss = 0.12165, Accuracy = 96.06%: 100%|██████████| 13/13 [00:00<00:00, 110.32it/s]\n",
      "[7 / 20] Train: Loss = 0.04578, Accuracy = 98.31%: 100%|██████████| 572/572 [00:05<00:00, 98.47it/s] \n",
      "[7 / 20]   Val: Loss = 0.12734, Accuracy = 96.07%: 100%|██████████| 13/13 [00:00<00:00, 109.60it/s]\n",
      "[8 / 20] Train: Loss = 0.04130, Accuracy = 98.49%: 100%|██████████| 572/572 [00:05<00:00, 101.43it/s]\n",
      "[8 / 20]   Val: Loss = 0.12918, Accuracy = 96.05%: 100%|██████████| 13/13 [00:00<00:00, 111.49it/s]\n",
      "[9 / 20] Train: Loss = 0.03713, Accuracy = 98.66%: 100%|██████████| 572/572 [00:05<00:00, 102.30it/s]\n",
      "[9 / 20]   Val: Loss = 0.13470, Accuracy = 96.01%: 100%|██████████| 13/13 [00:00<00:00, 113.65it/s]\n",
      "[10 / 20] Train: Loss = 0.03354, Accuracy = 98.80%: 100%|██████████| 572/572 [00:05<00:00, 99.15it/s] \n",
      "[10 / 20]   Val: Loss = 0.14201, Accuracy = 95.94%: 100%|██████████| 13/13 [00:00<00:00, 105.09it/s]\n",
      "[11 / 20] Train: Loss = 0.03019, Accuracy = 98.93%: 100%|██████████| 572/572 [00:05<00:00, 102.91it/s]\n",
      "[11 / 20]   Val: Loss = 0.15391, Accuracy = 95.86%: 100%|██████████| 13/13 [00:00<00:00, 113.14it/s]\n",
      "[12 / 20] Train: Loss = 0.02729, Accuracy = 99.04%: 100%|██████████| 572/572 [00:05<00:00, 105.77it/s]\n",
      "[12 / 20]   Val: Loss = 0.16108, Accuracy = 95.81%: 100%|██████████| 13/13 [00:00<00:00, 115.97it/s]\n",
      "[13 / 20] Train: Loss = 0.02453, Accuracy = 99.16%: 100%|██████████| 572/572 [00:05<00:00, 101.51it/s]\n",
      "[13 / 20]   Val: Loss = 0.16328, Accuracy = 95.74%: 100%|██████████| 13/13 [00:00<00:00, 110.54it/s]\n",
      "[14 / 20] Train: Loss = 0.02194, Accuracy = 99.25%: 100%|██████████| 572/572 [00:05<00:00, 99.44it/s] \n",
      "[14 / 20]   Val: Loss = 0.18031, Accuracy = 95.61%: 100%|██████████| 13/13 [00:00<00:00, 109.49it/s]\n",
      "[15 / 20] Train: Loss = 0.01976, Accuracy = 99.33%: 100%|██████████| 572/572 [00:05<00:00, 101.18it/s]\n",
      "[15 / 20]   Val: Loss = 0.18484, Accuracy = 95.62%: 100%|██████████| 13/13 [00:00<00:00, 114.11it/s]\n",
      "[16 / 20] Train: Loss = 0.01769, Accuracy = 99.40%: 100%|██████████| 572/572 [00:05<00:00, 105.03it/s] \n",
      "[16 / 20]   Val: Loss = 0.19380, Accuracy = 95.53%: 100%|██████████| 13/13 [00:00<00:00, 116.64it/s]\n",
      "[17 / 20] Train: Loss = 0.01595, Accuracy = 99.46%: 100%|██████████| 572/572 [00:05<00:00, 102.11it/s] \n",
      "[17 / 20]   Val: Loss = 0.20427, Accuracy = 95.49%: 100%|██████████| 13/13 [00:00<00:00, 109.84it/s]\n",
      "[18 / 20] Train: Loss = 0.01441, Accuracy = 99.52%: 100%|██████████| 572/572 [00:05<00:00, 103.69it/s] \n",
      "[18 / 20]   Val: Loss = 0.21309, Accuracy = 95.42%: 100%|██████████| 13/13 [00:00<00:00, 113.83it/s]\n",
      "[19 / 20] Train: Loss = 0.01298, Accuracy = 99.57%: 100%|██████████| 572/572 [00:05<00:00, 100.44it/s] \n",
      "[19 / 20]   Val: Loss = 0.21809, Accuracy = 95.47%: 100%|██████████| 13/13 [00:00<00:00, 114.04it/s]\n",
      "[20 / 20] Train: Loss = 0.01174, Accuracy = 99.62%: 100%|██████████| 572/572 [00:05<00:00, 99.74it/s]  \n",
      "[20 / 20]   Val: Loss = 0.22939, Accuracy = 95.34%: 100%|██████████| 13/13 [00:00<00:00, 111.79it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTaggerWithPretrainedEmbsNonFreeze(\n",
    "    embeddings=embeddings,\n",
    "    tagset_size=len(tag2ind)\n",
    ").cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVJet3RQix98"
   },
   "source": [
    "**Задание** На самом деле, понятно, почему это плохо - после этого нельзя использовать старые предобученные вектора (которые не попали в трейн). Проверьте, какое качество получается на тесте со старыми векторами.\n",
    "\n",
    "Чтобы бороться с этим, можно использовать такой прием: на предобученные вектора накладывать $l_2$-регуляризацию, чтобы они не удалялись от исходных векторов, а для слов, эмбеддинги которых мы не знаем, строить случайные вектора и учить их как обычно.\n",
    "\n",
    "Почитать про это можно чуть-чуть здесь: [Pseudo-rehearsal: A simple solution to catastrophic forgetting for NLP](https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting) либо в книжке Goldberg'а.\n",
    "\n",
    "**Задание** Попробуйте реализовать это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23abeGwPp163"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EfN1olf6RZne"
   },
   "source": [
    "## We need to go deeper, сети символьного уровня\n",
    "\n",
    "Напомню, на прошлом занятии мы строили LSTM сеть, которая обрабатывала последовательности символов, и предсказывала, к какому языку относится слово. \n",
    "\n",
    "LSTM выступал в роли feature extractor'а, работающего с произвольного размера последовательностью символов (ну, почти произвольного - мы ограничивались максимальной длиной слова). Батч для сети имел размерность `(max_word_len, batch_size)`.\n",
    "\n",
    "Теперь мы опять хотим использовать такую же идею для извлечения признаков из последовательности символов - потому что последовательность символов же должна быть полезной для предсказания части речи, правда?\n",
    "\n",
    "Сеть должна будет запомнить, например, что `-ly` - это часто про наречие, а `-tion` - про существительное.\n",
    "\n",
    "![](https://image.ibb.co/kzbh6L/Char-Bi-LSTM.png \" \")\n",
    "\n",
    "Остальная часть сети при этом будет такой же.\n",
    "\n",
    "Найдем границу для длины слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SczGwL8Cy0Ws"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word len for 99% of words is 12\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "    \n",
    "def find_max_len(counter, threshold):\n",
    "    sum_count = sum(counter.values())\n",
    "    cum_count = 0\n",
    "    for i in range(max(counter)):\n",
    "        cum_count += counter[i]\n",
    "        if cum_count > sum_count * threshold:\n",
    "            return i\n",
    "    return max(counter)\n",
    "\n",
    "word_len_counter = Counter()\n",
    "for sent in data:\n",
    "    for word, _ in sent:\n",
    "        word_len_counter[len(word)] += 1\n",
    "    \n",
    "threshold = 0.99\n",
    "MAX_WORD_LEN = find_max_len(word_len_counter, threshold)\n",
    "\n",
    "print('Max word len for {:.0%} of words is {}'.format(threshold, MAX_WORD_LEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YlArjEvqkMGk"
   },
   "source": [
    "Построим алфавит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LWXHmXGcotd"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def get_range(first_symb, last_symb):\n",
    "    return set(chr(c) for c in range(ord(first_symb), ord(last_symb) + 1))\n",
    "\n",
    "chars = get_range('a', 'z') | get_range('A', 'Z') | get_range('0', '9') | set(punctuation)\n",
    "char2ind = {c : i + 1 for i, c in enumerate(chars)}\n",
    "char2ind['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0OS9WQjkO9b"
   },
   "source": [
    "**Задание** Сконвертируйте данные, как в функции выше - только теперь слова должны отобразиться не в один индекс, а в последовательность.\n",
    "\n",
    "Обрезайте слова по `MAX_WORD_LEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3Q3arGCmgi-"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, char2ind, tag2ind):\n",
    "    X, y = [], []\n",
    "    for sent in data:\n",
    "        sent_x = []\n",
    "        sent_y = []\n",
    "        for word in sent:\n",
    "            vector = []\n",
    "            for i, char in enumerate(word[0]):\n",
    "                if i < MAX_WORD_LEN:\n",
    "                    vector.append(char2ind.get(char, 0))\n",
    "            sent_x.append(vector)\n",
    "            sent_y.append(tag2ind.get(word[1], 0))\n",
    "        X.append(sent_x)\n",
    "        y.append(sent_y)\n",
    "    return X, y\n",
    "  \n",
    "X_train, y_train = convert_data(train_data, char2ind, tag2ind)\n",
    "X_val, y_val = convert_data(val_data, char2ind, tag2ind)\n",
    "X_test, y_test = convert_data(test_data, char2ind, tag2ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SMmXMx5Rr5z"
   },
   "source": [
    "Напишем генератор батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c835LEVERXzl"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start: end]\n",
    "        \n",
    "        sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        word_len = max(len(word) for ind in batch_indices for word in X[ind])\n",
    "            \n",
    "        X_batch = np.zeros((sent_len, len(batch_indices), word_len))\n",
    "        y_batch = np.zeros((sent_len, len(batch_indices)))\n",
    "        \n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            for word_ind, word in enumerate(X[sample_ind]):\n",
    "                X_batch[word_ind, batch_ind, :len(word)] = word\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWcRRe11jFI8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 4, 12), (32, 4))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfY7FcXCknzX"
   },
   "source": [
    "**Задание** Реализуйте сеть, которая принимает батч размера `(seq_len, batch_size, word_len)` и возвращает `(seq_len, batch_size, word_emb_dim)`. Это может быть любая функция, которая умеет в последовательности произвольной длины. Мы уже смотрели на сверточные и рекуррентные сети для такой задачи - попробуйте обе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1qs96uAY3Wd"
   },
   "outputs": [],
   "source": [
    "class CharsEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, char_emb_dim=24, word_emb_dim=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, char_emb_dim)\n",
    "        self.lstm = nn.LSTM(char_emb_dim, word_emb_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        y = []\n",
    "        for i in range(x.size(2)):\n",
    "            out, hidden = self.lstm(x[:,:,i,:])\n",
    "            y.append(out)\n",
    "        y = torch.stack(y)\n",
    "        return y.mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharsEmbedding(len(char2ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 100])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.LongTensor(X_batch)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ag2R5sIglLhh"
   },
   "source": [
    "**Задание** Реализуйте теггер с эмбеддингами символьного уровня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRB8tAOAa_YW"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, char_vocab_size, tagset_size, char_emb_dim=24, \n",
    "                 word_emb_dim=128, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = CharsEmbedding(\n",
    "            char_vocab_size,\n",
    "            char_emb_dim,\n",
    "            word_emb_dim\n",
    "        )\n",
    "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count)\n",
    "        self.lin = nn.Linear(lstm_hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.emb(inputs)\n",
    "        x, hidden = self.lstm(x)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEaWjN0qjFfe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 20] Train: Loss = 1.45723, Accuracy = 49.62%: 100%|██████████| 572/572 [00:44<00:00, 12.78it/s]\n",
      "[1 / 20]   Val: Loss = 1.11405, Accuracy = 62.63%: 100%|██████████| 202/202 [00:03<00:00, 63.28it/s]\n",
      "[2 / 20] Train: Loss = 0.97629, Accuracy = 66.75%: 100%|██████████| 572/572 [00:44<00:00, 12.88it/s]\n",
      "[2 / 20]   Val: Loss = 0.85175, Accuracy = 70.78%: 100%|██████████| 202/202 [00:03<00:00, 63.48it/s]\n",
      "[3 / 20] Train: Loss = 0.75735, Accuracy = 74.28%: 100%|██████████| 572/572 [00:44<00:00, 12.78it/s]\n",
      "[3 / 20]   Val: Loss = 0.68564, Accuracy = 76.77%: 100%|██████████| 202/202 [00:03<00:00, 62.95it/s]\n",
      "[4 / 20] Train: Loss = 0.63824, Accuracy = 78.33%: 100%|██████████| 572/572 [00:44<00:00, 14.29it/s]\n",
      "[4 / 20]   Val: Loss = 0.60450, Accuracy = 79.30%: 100%|██████████| 202/202 [00:03<00:00, 64.11it/s]\n",
      "[5 / 20] Train: Loss = 0.57644, Accuracy = 80.35%: 100%|██████████| 572/572 [00:44<00:00, 12.80it/s]\n",
      "[5 / 20]   Val: Loss = 0.55624, Accuracy = 81.02%: 100%|██████████| 202/202 [00:03<00:00, 62.73it/s]\n",
      "[6 / 20] Train: Loss = 0.53419, Accuracy = 81.64%: 100%|██████████| 572/572 [00:44<00:00, 12.75it/s]\n",
      "[6 / 20]   Val: Loss = 0.52704, Accuracy = 81.96%: 100%|██████████| 202/202 [00:03<00:00, 63.12it/s]\n",
      "[7 / 20] Train: Loss = 0.50138, Accuracy = 82.72%: 100%|██████████| 572/572 [00:44<00:00, 14.63it/s]\n",
      "[7 / 20]   Val: Loss = 0.48997, Accuracy = 83.09%: 100%|██████████| 202/202 [00:03<00:00, 63.52it/s]\n",
      "[8 / 20] Train: Loss = 0.47346, Accuracy = 83.63%: 100%|██████████| 572/572 [00:44<00:00, 12.75it/s]\n",
      "[8 / 20]   Val: Loss = 0.47334, Accuracy = 83.59%: 100%|██████████| 202/202 [00:03<00:00, 60.62it/s]\n",
      "[9 / 20] Train: Loss = 0.44932, Accuracy = 84.39%: 100%|██████████| 572/572 [00:44<00:00, 12.92it/s]\n",
      "[9 / 20]   Val: Loss = 0.45084, Accuracy = 84.33%: 100%|██████████| 202/202 [00:03<00:00, 65.28it/s]\n",
      "[10 / 20] Train: Loss = 0.42708, Accuracy = 85.09%: 100%|██████████| 572/572 [00:44<00:00, 14.48it/s]\n",
      "[10 / 20]   Val: Loss = 0.42612, Accuracy = 85.10%: 100%|██████████| 202/202 [00:03<00:00, 62.55it/s]\n",
      "[11 / 20] Train: Loss = 0.40857, Accuracy = 85.67%: 100%|██████████| 572/572 [00:44<00:00, 12.64it/s]\n",
      "[11 / 20]   Val: Loss = 0.40833, Accuracy = 85.66%: 100%|██████████| 202/202 [00:03<00:00, 61.31it/s]\n",
      "[12 / 20] Train: Loss = 0.39177, Accuracy = 86.22%: 100%|██████████| 572/572 [00:44<00:00, 12.75it/s]\n",
      "[12 / 20]   Val: Loss = 0.39489, Accuracy = 86.15%: 100%|██████████| 202/202 [00:03<00:00, 65.94it/s]\n",
      "[13 / 20] Train: Loss = 0.37645, Accuracy = 86.74%: 100%|██████████| 572/572 [00:44<00:00, 12.95it/s]\n",
      "[13 / 20]   Val: Loss = 0.38206, Accuracy = 86.53%: 100%|██████████| 202/202 [00:02<00:00, 72.23it/s]\n",
      "[14 / 20] Train: Loss = 0.36263, Accuracy = 87.18%: 100%|██████████| 572/572 [00:39<00:00, 14.32it/s]\n",
      "[14 / 20]   Val: Loss = 0.38133, Accuracy = 86.63%: 100%|██████████| 202/202 [00:02<00:00, 69.71it/s]\n",
      "[15 / 20] Train: Loss = 0.34981, Accuracy = 87.60%: 100%|██████████| 572/572 [00:39<00:00, 14.37it/s]\n",
      "[15 / 20]   Val: Loss = 0.36027, Accuracy = 87.38%: 100%|██████████| 202/202 [00:02<00:00, 73.63it/s]\n",
      "[16 / 20] Train: Loss = 0.33868, Accuracy = 88.02%: 100%|██████████| 572/572 [00:39<00:00, 14.44it/s]\n",
      "[16 / 20]   Val: Loss = 0.35185, Accuracy = 87.66%: 100%|██████████| 202/202 [00:02<00:00, 72.77it/s]\n",
      "[17 / 20] Train: Loss = 0.32809, Accuracy = 88.39%: 100%|██████████| 572/572 [00:39<00:00, 14.51it/s]\n",
      "[17 / 20]   Val: Loss = 0.35039, Accuracy = 87.68%: 100%|██████████| 202/202 [00:02<00:00, 71.06it/s]\n",
      "[18 / 20] Train: Loss = 0.31816, Accuracy = 88.72%: 100%|██████████| 572/572 [00:39<00:00, 14.30it/s]\n",
      "[18 / 20]   Val: Loss = 0.33532, Accuracy = 88.15%: 100%|██████████| 202/202 [00:02<00:00, 71.65it/s]\n",
      "[19 / 20] Train: Loss = 0.31007, Accuracy = 89.00%: 100%|██████████| 572/572 [00:39<00:00, 14.33it/s]\n",
      "[19 / 20]   Val: Loss = 0.32799, Accuracy = 88.38%: 100%|██████████| 202/202 [00:02<00:00, 70.16it/s]\n",
      "[20 / 20] Train: Loss = 0.30138, Accuracy = 89.35%: 100%|██████████| 572/572 [00:39<00:00, 14.54it/s]\n",
      "[20 / 20]   Val: Loss = 0.32072, Accuracy = 88.69%: 100%|██████████| 202/202 [00:02<00:00, 71.56it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(char_vocab_size=len(char2ind), tagset_size=len(tag2ind)).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20, \n",
    "    batch_size=64, val_data=(X_val, y_val), val_batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGDJqyG9lTxV"
   },
   "source": [
    "**Задание** Оцените его качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCUj9_nqjgrL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      Loss = 0.32018, Accuracy = 88.66%: 100%|██████████| 448/448 [00:06<00:00, 71.19it/s]\n"
     ]
    }
   ],
   "source": [
    "_, test_accuracy = do_epoch(model, criterion, (X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12HYYmSzlZtm"
   },
   "source": [
    "### Визуализации\n",
    "\n",
    "**Задание** Посчитайте эмбеддинги символьного уровня (обученные внутри модели перед этим) для 1000 случайных слов из `word2ind`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand_words = random.choices(list(word2ind.items()), k = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word, embedder):\n",
    "    code = [[[char2ind.get(char, 0) for char in word]]]\n",
    "    out = embedder(torch.LongTensor(code).cuda()).detach().cpu().numpy()[0][0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyXEJ6MUG8PE"
   },
   "outputs": [],
   "source": [
    "embeddings, index2word = np.array([get_embedding(word[0], model.emb) for word in rand_words]), [word[0] for word in rand_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K2klT31GSWlR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1000 samples in 0.004s...\n",
      "[t-SNE] Computed neighbors for 1000 samples in 0.188s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1000\n",
      "[t-SNE] Mean sigma: 0.600048\n",
      "[t-SNE] Computed conditional probabilities in 0.034s\n",
      "[t-SNE] Iteration 50: error = 71.1975708, gradient norm = 0.2982585 (50 iterations in 2.142s)\n",
      "[t-SNE] Iteration 100: error = 71.7269516, gradient norm = 0.3061621 (50 iterations in 2.325s)\n",
      "[t-SNE] Iteration 150: error = 72.8170395, gradient norm = 0.2880439 (50 iterations in 2.279s)\n",
      "[t-SNE] Iteration 200: error = 72.9741669, gradient norm = 0.2731404 (50 iterations in 2.287s)\n",
      "[t-SNE] Iteration 250: error = 71.7529449, gradient norm = 0.2862889 (50 iterations in 2.338s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 71.752945\n",
      "[t-SNE] Iteration 300: error = 1.9013201, gradient norm = 0.0018252 (50 iterations in 1.504s)\n",
      "[t-SNE] Iteration 350: error = 1.8025655, gradient norm = 0.0006507 (50 iterations in 1.426s)\n",
      "[t-SNE] Iteration 400: error = 1.7669766, gradient norm = 0.0003623 (50 iterations in 1.424s)\n",
      "[t-SNE] Iteration 450: error = 1.7515889, gradient norm = 0.0002068 (50 iterations in 1.411s)\n",
      "[t-SNE] Iteration 500: error = 1.7408277, gradient norm = 0.0001964 (50 iterations in 1.425s)\n",
      "[t-SNE] Iteration 550: error = 1.7366548, gradient norm = 0.0001232 (50 iterations in 1.421s)\n",
      "[t-SNE] Iteration 600: error = 1.7338136, gradient norm = 0.0001307 (50 iterations in 1.411s)\n",
      "[t-SNE] Iteration 650: error = 1.7314360, gradient norm = 0.0001812 (50 iterations in 1.422s)\n",
      "[t-SNE] Iteration 700: error = 1.7235602, gradient norm = 0.0001715 (50 iterations in 1.433s)\n",
      "[t-SNE] Iteration 750: error = 1.7188071, gradient norm = 0.0001384 (50 iterations in 1.442s)\n",
      "[t-SNE] Iteration 800: error = 1.7135649, gradient norm = 0.0002041 (50 iterations in 1.437s)\n",
      "[t-SNE] Iteration 850: error = 1.7115908, gradient norm = 0.0000840 (50 iterations in 1.439s)\n",
      "[t-SNE] Iteration 900: error = 1.7101854, gradient norm = 0.0001073 (50 iterations in 1.401s)\n",
      "[t-SNE] Iteration 950: error = 1.7068951, gradient norm = 0.0001181 (50 iterations in 1.422s)\n",
      "[t-SNE] Iteration 1000: error = 1.7048154, gradient norm = 0.0001196 (50 iterations in 1.445s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.704815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/miniconda3/envs/temp3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"7b696bf1-f7f4-4a33-a28d-f8d81aab5631\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"7b696bf1-f7f4-4a33-a28d-f8d81aab5631\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"7b696bf1-f7f4-4a33-a28d-f8d81aab5631\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '7b696bf1-f7f4-4a33-a28d-f8d81aab5631' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"7b696bf1-f7f4-4a33-a28d-f8d81aab5631\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"7b696bf1-f7f4-4a33-a28d-f8d81aab5631\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"7b696bf1-f7f4-4a33-a28d-f8d81aab5631\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '7b696bf1-f7f4-4a33-a28d-f8d81aab5631' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"7b696bf1-f7f4-4a33-a28d-f8d81aab5631\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"2a4dac26-349f-4a9d-9314-e9da304e226d\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"8f1d24df-c3fc-474c-968f-9c2e9843fac6\":{\"roots\":{\"references\":[{\"attributes\":{\"callback\":null,\"renderers\":\"auto\",\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"a38aae37-f636-42f1-8561-d1abcc028478\",\"type\":\"HoverTool\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"6689bac0-726e-4f66-9f9c-90f87e5dedbb\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"68529e97-eed7-4f99-84cf-d91455138467\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"3bc3f417-4b72-4a5b-92be-e1858587e63c\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"a2be185e-fa6c-4dff-8c5b-d5ddd5593460\",\"type\":\"PanTool\"},{\"id\":\"3bc3f417-4b72-4a5b-92be-e1858587e63c\",\"type\":\"WheelZoomTool\"},{\"id\":\"1bd20d33-c2b9-4dfd-93a4-cd9e20f4eb57\",\"type\":\"BoxZoomTool\"},{\"id\":\"3eef4aec-8fea-43a0-82f7-a0f6abf1d1c0\",\"type\":\"SaveTool\"},{\"id\":\"ce1910c4-0e91-49a1-8472-2ddf97e59c9d\",\"type\":\"ResetTool\"},{\"id\":\"287d4117-7193-4a23-b1e3-1c2becc55b4d\",\"type\":\"HelpTool\"},{\"id\":\"a38aae37-f636-42f1-8561-d1abcc028478\",\"type\":\"HoverTool\"}]},\"id\":\"db596f8f-6e86-4533-a286-da83db034c69\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"12f4e0d7-95e9-4c95-a425-c703345ae95e\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"3eef4aec-8fea-43a0-82f7-a0f6abf1d1c0\",\"type\":\"SaveTool\"},{\"attributes\":{\"plot\":{\"id\":\"724bb008-36e4-4441-ae20-2fa7f78035d3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"cfae4232-638e-40a8-bbec-48e2753646ee\",\"type\":\"BasicTicker\"}},\"id\":\"75250b97-3b18-4002-9f57-109774e23565\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"4cbf8488-f4c5-4d64-adc0-9a49b16f368b\",\"type\":\"ColumnDataSource\"}},\"id\":\"f20e34a7-65d5-472e-bafc-60ef8eae200d\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"287d4117-7193-4a23-b1e3-1c2becc55b4d\",\"type\":\"HelpTool\"},{\"attributes\":{\"callback\":null},\"id\":\"ac1a169e-c123-4756-8dd3-a3495f27c4f5\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"d50dc63c-fa5b-4244-a9bf-649a6875b588\",\"type\":\"Circle\"},{\"attributes\":{\"callback\":null},\"id\":\"6734ac2e-5f71-4dca-b5dd-882ee3fbd24a\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"e4e3cb7e-cbcc-487b-a023-607414b5088a\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"724bb008-36e4-4441-ae20-2fa7f78035d3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ec0e79bb-8711-4e67-9d2c-0302ff2c5b67\",\"type\":\"BasicTicker\"}},\"id\":\"31e11c4e-c39a-4ebc-a2b1-40f519f7b28a\",\"type\":\"LinearAxis\"},{\"attributes\":{\"formatter\":{\"id\":\"3f944025-6c44-4609-afac-fd4a2ab8b518\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"724bb008-36e4-4441-ae20-2fa7f78035d3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"cfae4232-638e-40a8-bbec-48e2753646ee\",\"type\":\"BasicTicker\"}},\"id\":\"c4380341-61e9-49fb-ac7e-305283ab4d6b\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"3f944025-6c44-4609-afac-fd4a2ab8b518\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"cfae4232-638e-40a8-bbec-48e2753646ee\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"4cbf8488-f4c5-4d64-adc0-9a49b16f368b\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d50dc63c-fa5b-4244-a9bf-649a6875b588\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"e52933aa-e8c5-43b4-9529-974a34b074cf\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"f20e34a7-65d5-472e-bafc-60ef8eae200d\",\"type\":\"CDSView\"}},\"id\":\"afac5316-b0ce-4c1a-b34b-69342e298fe1\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"a2be185e-fa6c-4dff-8c5b-d5ddd5593460\",\"type\":\"PanTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"615f1569-2b49-4044-840b-edefc00c9d27\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"24ce0d0c-bfdc-484c-8290-0a0b0c4c517b\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"e52933aa-e8c5-43b4-9529-974a34b074cf\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"ce1910c4-0e91-49a1-8472-2ddf97e59c9d\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"],\"token\":[\"entities\",\"apron\",\"Adriatic\",\"Sally\",\"Ewen\",\"experienced\",\"analysed\",\"doubleheader\",\"heroine\",\"premiums\",\"volunteer\",\"faculty\",\"all-Negro\",\"term-end\",\"seashore\",\"sowing\",\"annoying\",\"enlargements\",\"Lionel\",\"serenely\",\"sprinted\",\"continue\",\"loss\",\"declaration\",\"blubber\",\"projects\",\"Ringel\",\"backbone\",\"Cried\",\"Trujillo\",\"bitter\",\"$15,000,000\",\"pooling\",\"Pip's\",\"Unconscionable\",\"plagiarism\",\"Money-saving\",\"redwoods\",\"poison\",\"Minoan-Mycenaean\",\"desolate\",\"hunched\",\"Mondrian\",\"post-mortem\",\"mock\",\"polka-dotted\",\"repent\",\"officeholders\",\"healthily\",\"Ursuline\",\"CH\",\"wont\",\"brethren\",\"Stephens\",\"take-off\",\"predicator\",\"adsorbed\",\"balance\",\"hateful\",\"Normal\",\"fast\",\"5-3\",\"abide\",\"beveled\",\"Histochemistry\",\"berries\",\"Rockville\",\"vagina\",\"Babatunde\",\"table\",\"despised\",\"Sounds\",\"factor\",\"relief\",\"affiliations\",\"prosceniums\",\"procured\",\"cherished\",\"multi-phase\",\"kisses\",\"Pantheon\",\"perfunctorily\",\"veracious\",\"proficiency\",\"312\",\"Oranges\",\"embraces\",\"home\",\"atom's\",\"fellow-men\",\"parents'\",\"Convocation\",\"swellings\",\"repose\",\"Tobin\",\"phenomena\",\"hoop\",\"dampness\",\"urgencies\",\"plowshares\",\"transmitting\",\"long-acting\",\"radiosterilization\",\"onrush\",\"ticks\",\"Boxell\",\"helion\",\"constitute\",\"Churchill\",\"resolution\",\"supervisor\",\"Non-God\",\"photographers\",\"Eyes\",\"Dachshund\",\"Schiele\",\"Frisco\",\"liberated\",\"prancing\",\"goggle-eyed\",\"Benefit\",\"wash\",\"mining\",\"glimpse\",\"Brevard\",\"timely\",\"rebut\",\"dilatation\",\"hotel's\",\"Lenygon\",\"increasing\",\"match-width\",\"twenties\",\"discolored\",\"erudite\",\"Thomas's\",\"I've\",\"managed\",\"commend\",\"604,622\",\"beneficiaries\",\"lure\",\"induction\",\"parents\",\"Judea\",\"Method\",\"confuses\",\"cherubim\",\"kick-off\",\"riboflavin\",\"yanked\",\"Milan\",\"ex-bandits\",\"spraying\",\"Months\",\"Jody\",\"1778\",\"crystal\",\"not\",\"Futotsu\",\"thickens\",\"rolling\",\"Heydrich\",\"swathed\",\"fairness\",\"resurgence\",\"scrupulously\",\"Sanchez\",\"desperadoes\",\"oil-bearing\",\"sweetpeas\",\"rum\",\"Ditch\",\"Riverview\",\"cabana\",\"Spanish-American\",\"1624\",\"lioness\",\"ravenous\",\"plasticity\",\"Bolet\",\"Designers\",\"SCR\",\"pupates\",\"submucosa\",\"boys\",\"chiseled\",\"posts\",\"hesitate\",\"calving\",\"Yesterday\",\"septum\",\"culminates\",\"cunningly\",\"rod\",\"defense\",\"unleavened\",\"self-serve\",\"affairs\",\"incentives\",\"healthful\",\"Superior\",\"aftermath\",\"Who's\",\"oust\",\"insignificant\",\"treason\",\"equate\",\"reverberation\",\"Tristano\",\"gut-flattening\",\"various\",\"Ideas\",\"revelling\",\"Sandman\",\"Vadim\",\"Bacon\",\"brew\",\"insignificances\",\"Sword\",\"tackles\",\"Potsdam\",\"Gretchen\",\"invest\",\"Aristide\",\"kinds\",\"flows\",\"Platter\",\"dies\",\"again\",\"retailing\",\"catchwords\",\"Humpty\",\"beatific\",\"Menuhin\",\"sulky's\",\"blame\",\"freehand\",\"presuming\",\"potpourri\",\"neuroses\",\"adherence\",\"perished\",\"Sievers\",\"Petitioner\",\"inexpressible\",\"affinity\",\"Slavs\",\"cornering\",\"illusionary\",\"Carrots\",\"250\",\"Designs\",\"meteoric\",\"Scarcity\",\"reminiscence\",\"whisked\",\"well-developed\",\"violins\",\"fault\",\"nearly\",\"butlers\",\"stepwise\",\"seaman\",\"furnishings\",\"Evangelicalism\",\"conscripted\",\"affable\",\"suburbia\",\"nowhere\",\"shunt\",\"extremely\",\"tugged\",\"nails\",\"ingredients\",\"$1.8\",\"overdue\",\"Senora\",\"perplexity\",\"urbanization\",\"demography\",\"scream\",\"eye-machine\",\"appanage\",\"sparkle\",\"backpack\",\"1732\",\"Orioles\",\"begging\",\"must've\",\"romancing\",\"enemy's\",\"surrender\",\"otter\",\"ill-prepared\",\"cadenza\",\"dogmas\",\"Grenoble\",\"Frankfurt\",\"everybody's\",\"carcass\",\"friendship\",\"Art's\",\"boggled\",\"rostrum\",\"must've\",\"unpaired\",\"Sonata\",\"rattail\",\"Ito\",\"tumefaciens\",\"couples\",\"polyisocyanate\",\"Nadine's\",\"amendment's\",\"pry\",\"scratching\",\"relinquish\",\"eye-deceiving\",\"nod\",\"journeys\",\"Easy\",\"balkiness\",\"espouses\",\"pastor\",\"wastebasket\",\"Subic\",\"gins\",\"micrometeoritic\",\"McNaughton\",\"drahve\",\"household\",\"cringed\",\"just\",\"New-York\",\"Worth\",\"lumpish\",\"interrupted\",\"endorse\",\"meanness\",\"1,600\",\"warmth\",\"DA\",\"lust\",\"increase\",\"closer\",\"yeard\",\"romantically\",\"Within\",\"hoppled\",\"Hazards\",\"Jagan\",\"soul's\",\"Lord\",\"bouts\",\"1687\",\"Casbah\",\"stunned\",\"detente\",\"leftist\",\"advancement\",\"intercollegiate\",\"reflect\",\"antagonize\",\"flower\",\"Gaveston\",\"Whiskey\",\"Practices\",\"C\",\"resignation\",\"outmatched\",\"offered\",\"dejeuners\",\"a-gracious\",\"unwrinkled\",\"summer\",\"green-tinted\",\"reprisals\",\"resource\",\"monstrosity\",\"close\",\"scuffle\",\"amass\",\"Inland\",\"skinny\",\"slyness\",\"anarchical\",\"dance\",\"grim\",\"commemorated\",\"fishing\",\"Niven\",\"shreds\",\"misanthrope\",\"viewpoints\",\"hymen\",\"Santa's\",\"retrospect\",\"lid\",\"Picasso's\",\"photocathode\",\"benevolent\",\"unaccustomed\",\"Tee-wah\",\"Frankfort\",\"'tis\",\"32,589\",\"personae\",\"insubstantial\",\"Lizzie\",\"reams\",\"lower-status\",\"Domestic\",\"Spillane's\",\"Rates\",\"baby\",\"BTU's\",\"lost\",\"fourteenth\",\"Tomkins\",\"heavy-weight\",\"Englanders\",\"Newport\",\"dash\",\"Fifteen\",\"Des\",\"Caligula\",\"Commerce\",\"judgments\",\"broadcasting\",\"founders\",\"duplication\",\"galled\",\"desire\",\"nationalize\",\"rubies\",\"formalism\",\"persuading\",\"confidential\",\"Springfield\",\"manually\",\"Chapter\",\"transported\",\"Though\",\"epitaph\",\"gins\",\"questionnaire\",\"Beismortier\",\"strings\",\"centrifuge\",\"testicle\",\"medically\",\"wove\",\"Air\",\"longed\",\"jerkings\",\"historical\",\"ponies\",\"cabins\",\"Daniel\",\"criss-crossing\",\"millennia\",\"triptych\",\"carefree\",\"road-show\",\"inquiring\",\"wept\",\"fined\",\"Piranesi\",\"impaling\",\"6:30\",\"Adrianople\",\"decompression\",\"Pius\",\"well-administered\",\"hamming\",\"urgency\",\"wryly\",\"swarmed\",\"hr.\",\"Ubermenschen\",\"visibility\",\"freeways\",\"Thackeray\",\"liquidated\",\"value-problems\",\"Varian\",\"sorting\",\"empowered\",\"slugs\",\"nodes\",\"python\",\"McCrady\",\"aqueous\",\"hoss\",\"dismemberment\",\"sulfide\",\"Maximum\",\"f'ovuh\",\"indifference\",\"flight\",\"slitters\",\"crypt\",\"Sheridan\",\"respectability\",\"Barre-Montpelier\",\"writer-turned-painter\",\"Currently\",\"Wheeler\",\"sayin\",\"McCone's\",\"breathe\",\"thirteenth-century\",\"happily\",\"Tsvetkov\",\"puzzlement\",\"superimpose\",\"avoided\",\"Lou\",\"breath\",\"procured\",\"Torrid-Mighty\",\"full-year\",\"2000\",\"conformists\",\"pick\",\"excite\",\"glib\",\"weren't\",\"intricate\",\"coldness\",\"industry\",\"address\",\"halo\",\"Test\",\"heavy-handed\",\"preposition\",\"weak\",\"drafters\",\"tells\",\"godlike\",\"import\",\"revolver\",\"Contradictions\",\"censorship\",\"photography\",\"Sarason\",\"amphitheater\",\"fussing\",\"Particular\",\"sandy\",\"children\",\"pals\",\"Grigori\",\"osmotic\",\"indiscriminantly\",\"coupling\",\"utterances\",\"plopped\",\"1853\",\"Habla\",\"June\",\"Hearst's\",\"slowing\",\"permanently\",\"Casassa\",\"puncher\",\"2:30.3-:36\",\"coverage\",\"interfere\",\"weld\",\"Tom's\",\"shuts\",\"contains\",\"Portugal\",\"b\",\"desensitized\",\"Turkish\",\"week-ends\",\"impelled\",\"catered\",\"Murat\",\"chorines\",\"stand-ins\",\"Pels\",\"Says\",\"Concluding\",\"tells\",\"babel\",\"sinners\",\"repealed\",\"theories\",\"Selecting\",\"buffalo\",\"Round's\",\"roundabout\",\"ankles\",\"shabbily\",\"Alexandria\",\"legality\",\"1599\",\"heaped\",\"loyalties\",\"1.00\",\"Assyrian\",\"dishwater\",\"orbit\",\"cove\",\"Apropos\",\"Detailed\",\"Kearton\",\"Delon\",\"Alaska\",\"lower\",\"Higher\",\"slowly-mending\",\"diagram\",\"resulted\",\"microorganisms\",\"bankruptcy\",\"That\",\"air-cell\",\"Bechhofer\",\"0.50\",\"pierced\",\"Lura\",\"retinal\",\"necessities\",\"Fairmount\",\"Gov.\",\"Western-style\",\"Rainy\",\"Only\",\"vice-president\",\"informality\",\"threatened\",\"flagrant\",\"celluloses\",\"Moreover\",\"Helping\",\"Nassau\",\"eighth\",\"**yb\",\"maneuverability\",\"patterns\",\"Spots\",\"Nibelungenlied\",\"snatched\",\"astounded\",\"disaster\",\"assassins\",\"commonplace\",\"heroically\",\"sales-conscious\",\"virginity\",\"fever\",\"Dora\",\"brainy\",\"1951\",\"pillage\",\"Prevents\",\"all-night\",\"enzymatic\",\"Wee\",\"poodle\",\"unusually\",\"satire\",\"Terrible\",\"Protectorate\",\"liberally\",\"guardedness\",\"Poetics\",\"10.6%\",\"maelstrom\",\"disturbance\",\"Corelli\",\"Richardson's\",\"lighter\",\"dilating\",\"Mondonville\",\"Loan\",\"ova\",\"leg's\",\"interruptions\",\"Following\",\"function\",\"venereal\",\"Conservatory\",\"inclusive\",\"gainer\",\"Rotelli\",\"Bismarck\",\"drought\",\"detergent\",\"540-K\",\"Vichy\",\"unwanted\",\"corrupted\",\"intuitively\",\"aforesaid\",\"Eleazar\",\"Diametric\",\"Wingman\",\"Early\",\"hotel's\",\"racially\",\"hair-raising\",\"Hinckley\",\"contend\",\"$63.8\",\"Howe\",\"wohaw\",\"middle-school\",\"agreeableness\",\"Askington\",\"springs\",\"forthrightness\",\"Neighbor\",\"452\",\"Tracing\",\"Penrose\",\"knew\",\"terrain\",\"insurmountable\",\"constants\",\"20-gauge\",\"astounding\",\"speculating\",\"gardeners\",\"magnified\",\"hastened\",\"statutory\",\"collie\",\"broaden\",\"Superposed\",\"regiments\",\"excellence\",\"James's\",\"listener\",\"hazy\",\"nerve-ends\",\"Brumidi's\",\"fantods\",\"Rev.\",\"Southerners\",\"Helps\",\"remember\",\"masquers'\",\"Wagner\",\"tertian\",\"analyzable\",\"moneymaking\",\"Ab63711-r\",\"winehead\",\"re-echo\",\"dubious\",\"Crowd\",\"Hord\",\"Dufresne\",\"Initiating\",\"near-by\",\"Direct\",\"Freud's\",\"second-degree\",\"Ouse\",\"synthesize\",\"Renaults\",\"throughout\",\"docked\",\"escorted\",\"Tractor\",\"17th\",\"bombastic\",\"accused\",\"Preliminary\",\"Rose\",\"septic\",\"crouch\",\"Foundation's\",\"pug-nosed\",\"ribs\",\"sorted\",\"Polk's\",\"Agone\",\"Litowski\",\"Hindus\",\"receiving\",\"chopping\",\"rejections\",\"nonionic\",\"mode\",\"Noctiluca\",\"Antoine's\",\"makeshift\",\"deterrent\",\"feared\",\"uphold\",\"renders\",\"Wonderland\",\"Eventually\",\"Suvorov's\",\"tecum\",\"gait\",\"plates\",\"men's\",\"intelligence\",\"endogenous\",\"array\",\"devil's-food\",\"unpack\",\"Whose\",\"Highness\",\"state-supported\",\"mingled\",\"1596\",\"Played\",\"Bridges\",\"trade-preparatory\",\"nobody\",\"chicken\",\"environments\",\"fiche\",\"referendum\",\"draperies\",\"$400\",\"violently\",\"glycols\",\"DuPont\",\"gag\",\"nun\",\"thei\",\"sommelier\",\"wanton\",\"rancorous\",\"garter\",\"examinations\",\"interrelationship\",\"stamps\",\"Calls\",\"trench\",\"miniature\",\"gallium\",\"foppish\",\"imbroglio\",\"Pavlovsky\",\"bathrobe\",\"untouched\",\"chemistry\",\"triumph\",\"Gene\",\"Westmore\",\"pink\",\"Maxine's\",\"lanky\",\"categories\",\"sewing\",\"dwindled\",\"unnourished\",\"Sioux\",\"fitted\",\"voyage\",\"palms\",\"Dutch\",\"Burle\",\"mucker\",\"girlish\",\"highs\",\"critics'\",\"jerky\",\"C.C.B.\",\"Compared\",\"forties\",\"alien\",\"mathematics\",\"bursts\",\"merged\",\"apparition\",\"Frans\",\"reserve\",\"meddling\",\"Hessians\",\"emasculated\",\"coding\",\"Dollar-Britten\",\"OH\",\"esthetics\",\"paused\",\"Canyon\",\"Dorr\",\"enrichment\",\"gloss\",\"Rackmil\",\"knocking\",\"unbounded\",\"Tshombe\",\"collaborators\",\"conviction\",\"Summers\",\"nuance\",\"phenothiazine\",\"twins'\",\"lute\",\"thaw\",\"**yj\",\"liniment\",\"wheeled\",\"memos\",\"faces\",\"sweeter\",\"complaint\",\"ambulatory\",\"dewdrops\",\"assemblages\",\"limbo\",\"whit\",\"encouraging\",\"lullaby\",\"F.Supp.235\",\"bonnet\",\"Graff\",\"footballer's\",\"two-timed\",\"polished\",\"ruins\",\"2:30.3-:36\",\"faim\",\"clefts\",\"varnish\",\"locate\",\"lesson\",\"effusive\",\"discussed\",\"Give\",\"Dupont\",\"selfeffacing\",\"suffocating\",\"hexagon\",\"thousandths\",\"simulation\",\"Shrugs\",\"Berche\",\"impressive\",\"impurities\",\"rested\",\"backed\",\"wizard\",\"Nevada\",\"clutched\",\"boiled\",\"armchair\",\"05\",\"pronouncing\",\"$47,101,000\",\"Heel-Kaola\",\"whistling\",\"31\",\"cheetal\",\"marvels\",\"Pirie\",\"patent\",\"calculating\",\"chantey\",\"Moses\",\"Dogberry\",\"received\",\"meanings\",\"color-TV\",\"detriment\",\"fervent\",\"Hemingway's\",\"Fruit\",\"conning\",\"stripped\",\"Russian\",\"seeking\",\"fugitive\",\"Fanning\",\"caviar\",\"ICC\",\"winsome\",\"promote\",\"Urich\",\"McGehee\",\"hr.\",\"Ekstrohm\",\"$230,000\",\"boxcar\",\"Each\",\"clucks\",\"twilight\",\"image-provoking\",\"behaves\",\"appropriating\",\"nine-game\",\"Dallas\",\"Hanover-Mauri\",\"green-tinted\",\"deadly\",\"Arabs\",\"$3.11\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"I4azvPUCuj47Wg0/SGeDP3Dqf77fqL+/ljatPwb2/r4d6Ne/deABv3KqKb9VyWw/Z4JEPxKAnL/Mdem/a2ApP6fyWz9IDUm+AW2AP7j5jb/aDmQ9AkoYPw74hj8D9D0/FBGZP9JsHL/zQ6k/jqPRPvKUFL7n+hY/5eqdv2P+cb/UogE/hfTcPw3D2z5rpMs/W7orP77KF7+U78o+tsQvP/lLFr9lWc6/o2U5P3I+br/i1aU/DivPvi7Oq7/9zzM+gCNsP1U13T5L0Mg+jxdEP1haoL/k4bS/6U5KPivoF7/HSPO+zgSsP0GUfD8wsYM/fxgCQJT5Qr9r/tk/uuyGv7hwwr4zqCK+/joSP1BQ1z9vV9c+dPeiP6g/57+Op3A+k45nv20FLL5P7Yc/L5ayvsYjOL9RM9W/XIO+Pqls8j9PpnE/6GWNv2kfWr90O2I+QiBrv44boT+3WHG/Qsfovw6Yu75z97g+YZATvhH1oj7XDvI+3/oYv5803T6WNIA/9qXFv1i4AkBzSo++MiqOPpzPWD8+QiE/tDonP4Ofpr98Rdk/X6EqP35rJz71Zpq/yBpXP8Shk78TKVm/6QqePkIeuL/pBwtAfwmkv7evU7/hmbo/eZ1+O8gbaj/Rbr+/T3GFviiBBcDYRaA/WPrTPk309b5shAo/lsaiv3iMUT+YWBu+IqB+P2WNdj+40pm/AsgrvYm/Hb/Uv6C/T5HPvoKx4r782ts/+rMsvwOVb78WsNO9EWWPP6rGHj99ONa9wmkDwKet279vwMs/mDHxviVtYD7rFYE/5YvJP71Skj9pndg+ox5+Px75qb+bv1Y+KPVvv0UYZD9v+Ek/XmPAv3FRdL62pP8+lE/avqlYV79tTZA/fh64vwZ+Sj8AcGa/jq3kvyDmJj8ZJIy/cadqvy3sjL8iawa/iX/6P75qOj9prHy/wVfVPx0Wj7+C8lQ+So0bP2jGfr2CHuY+2Tqyvi1r1z8qmcQ/nmNLvxDqQ7+BKj6/RaV2P/viuL/ioiC/ZdvQPgWDVT+kyYO/XBCuv23Tfb+B+42+j6kBQD7MlDrzwHg/WPtKvw26U786rDm+Dkq9vzD7dj/kQYq/Q8dFv2F9lr/2a/w+74crP1a4Xr+oJ52/EAjivd13rz81m9k/vwGXPjl4r7/BCHw/Es2Mv2jyU781Dpe+kC66v3fQPjy1UQI/ObeIPwot5D65e0s/rMThvwiN2D+71hI/4jVQvx022r8gt907GF45PuboTj+7zqk/wvyLv+OLNjygD0+/QqUKvzoRjL+Gac2/fm/5vvgZoT6lxWq95iaMP8H0sz9Rn0Y/r317P/PrcL8QLYC/19mGvfJbAL9N+iw+stxgvkRI17/KecM8XfZ+P7Lzfj+w+6c+2xjfPu5OwL69OQJA55pVPzsr3j4pr6W+0ZuTP97vez+yK9e/WOGwv0EGj79bH8S/0gmjP5m42z0V5EO/SVQev7Tfjb/Jno89iPlfP8LP4L69kmm/QxdBvyKj4D8afVG/44s+PafKcL9Yx/Y+L2vlP3D2474ps1c/CwitP+Vrzr8hEHG/Uv6OPRA31z8ArZi+rGkBP+Dwc72ZZim/z1LwP16NSj87MR29HVOKPnfwbb+69OO+zQUrPu8iJD5hKFM/2hDJv2TYl71fxlY/1AaDP/YvCj+k8qk/fMWcvvQxjj5FJMY+hJKav+BD8T50KRu/I7wJQNTMtT8X1Pc/sklXv7v3a7+00N2/3IuQP1zw6769bp+/Rbp5v+DWCL4Kpts9KfrqvtYhTb8xktu/FEXAPigdmb89fga/8jgCQEYgZ78jVZW/+MH5PuOTNz/AmkO+X6BfP+OIvb8hNno/8CeIP4TN9b5ahOY/j8zgP12BRj+40oa/esG7v+kCZb/3EM8/6+QnPwxHr79JMFc+vDKpP08E373q6R6+Y7SjP1HFFz4IGJe/jCmYvhta3D1ATeg+cw9fP5hiw78lLFM9wY+2v677Oz8K6U4+4/4fvwvWob9ykSU90mgqv9F0uD/ISFo/Dr65u1Am6z/PmhE/V7OZPx7Z2T8X80k/VVTVP1KBfL0pMiy/qJpeP+prcD0GzOu/Y0OhPu9m+z1M0Ko/KI7OPcKhKb+9VA5ArDvfP3xAw7/4zHC/orA7v3lHUr8DXly9MZYRPdsZVL+mMuy+6dqbP1KOtD/csWm/ABXJPiZ8oT1tKx4/sXtzv9qF8z/AnsU/nWA1P1p4xb8pPqo/8XtHv06ioj8CXkG/AJgFwF3xhL5Kch4+4t3hPqgqKL+D62y+/8SsPkZXib8RLEI/u2ePPtlnzb8vRFc/5i0Qvnhjmj8TuwY+me46PyOcnj+hYYg/kn91v+6l+b61iN+/MasEv92LkD9UQJ4+BzTVvql1hz+BRIi/HxsNv0TY5j7FxBW/SbQYP90TkT7dIqG8HBTPPojPgb43DMw/3tyNPxtXuT/HiY0/b1aOv2OToL/8/7S/Ag59P95Lhb73yk6+Ea6mP7jFwj+JjVu/f29BP1Wmw74kUtk/icmHOzPduz965Ju+kTudvwPk5b8GXwHAb4wuvpIhqj4V3rS/pXhnv9BN77zTceM+F1tyP/QyED+yQcC/dA+GP2viPb71R66/5ScBP3fBGb/Lyeo/Q5+EvnZnuz1XBOA/ZpoIvuzmVr5RtxE/Spc6PuJmnb7NXXA+sLkpPpaNZb8md5e/aT2Qv457ar9xC7s/SUrevsKCbr8ISsG/gDrxvim+Ab99qHw9w+jrvgMCtb5HxLa/gq9sv2kgOL8vZXq/fhlfP0EUhL9l3rc/EgjeP1/KlL9XjrU/XrO2v+uX0T5bt80/aWenPprv6r8csF8/vdwHvz7Xdb8OMo8+jjyTvwl0Ar/lsys/qrFQPvigSr+/iyi/WxkFP4lCqL7teLm/d6kUPnyKRb/PcYY/3/BbPwIUvT8bk4y+hvbaP67HCb7ZDa8/0S9uP27IAT8Ggja/g0vdvkPRYr/3LLs/hKhgPzLC8L4NSh8/lUSUPqFz6D8kPbi/LeNNvxvwpr8714+/uDUNPE+Hyb4HebO/GSbZPij3Wj80nPg/kKjdv0mcqj4hXbW/awyTPgcHsb9zdmk/MNCovmDsPz9BNh0+jUMJQHlMGT/lsys/gz2jPxukjj/I/pO/T1Xav8Frab3FcYc/S71jPtvuRT7xobM/UxKhP94gTj/nHvI+xuVHv89djb/xqDk/wM5svxCGvz+zKlG/jzA5vvchFL/iDE+/ncGDvToNi7/nGAg/ZGXbP4wgHj4uAOe+4okdPxF71j/HBOu++SaxPwoTzLuu4qW/w7hQP2a/07/+NHe/hNjFv/YdbD/AAwg/Y8qdvgOfX7ysErW/JFogvyxcsz/sE4k/xI4Wvld9hT/ZQYy/Bo5hP86wRz/EQYa/wl2nP1hZ5T+xVhq/odsvP4JA7T4NTvS9SnVHvzi2WL21Ylu/41ufvrjvajyBpu0/NpGbPwT7QT/yqtc/rh17P2MeRL+bYX6/NipmP0rIUr/1D7A+b34rvxc+GT+QIBU/i+V3v38Z9b5grVw/ZKnBO5GLZL6EW2S/YtNoP/ej3r+ExK09KCVYvwPTs76WaKU+aUwaPyawYL9MWYC+ea+7PydsED8Q7nA+Xguhv7jg4D3a9J4+3nABP30rIT9K0IG/pWCKv4HXoz4vQpc/QOgbP03yzz/wndK/jeGtvzEDdb9U1qi+mQAmP6fLOL+sXag+8EpDP9iLtj/qWRg+Pl6oP2tgdj+JWBu+nL50P5HmKD9fXVC+srEmP/qLRr8/JuG/U3m7v+whgj7n04S/7oplPxtfhz/cBpO/prVmv+fzhb8L4F8/O4r+vha9XL7pZuY+flYcP/dtwz5cIiY+bV4nP5vGAj+9Cte/Ceq4P/sDgr/fAra/1CM2P7l29j4Ikwm/Sap5viLLhr/VLvS++kP2vdiFW7/uaZm/7+zqPhFWmT5hn7i/opyQv7wbN78udtG/LVnrvn2imj9nUd8+CRSuPw/tsz9FF1u/y6OEv5zZ2b+6mNS/X7WLv1wJjb8lI4G/pPKBP+5ozT6kh/c9a0mWPsYkur/GBja/nFGZvsvjHz8FMdi/c7cTv3VrKb8donG/u9FPv4apzT9ssva/L5KjP/gbAkCAOsO+9XvOvyMcgD4RfIW+jvOgPwvwLb8mplI/rG+CP+ABEz8v5xo/ZjdUvmeU2T6txuS+/mBEPzw9OL97bik/IOoJPo2Fq722ray/IImdvxuYBr9F5M+/ADcAPyHhQj99VLW/YI0ov1aqwj+8/Eq/TYOsPyGLnb1jwEG+cK1WP5KTnj7jPBA9qvfnv2ggjL5ZAwW/AULWP3nyVr9U25A+Gj6wvUqpDr+tK9c+GntovlQq8Ls1Dsy/7qiQv4eNzr8KmYO/QnVBP06hcz83qrW/17DqP0tXRj9VAh+/pGkWv0EJOD9h+3e/6vgQv+ELQz/oyK8+nwboP5hTyz919L2/uPXFPrOB3T7kU5c+5VqQPyKlsz9l0G+/fHTMvwtcx74sQYu/HPmnv44gEb84GIE/+OYMPw3+mT86V8u+yd5XPTU90z/sk6C/r6vWvzH8kr97LqW/32nePxMvjr/WyeY+XOfvvo1X3D6oDQq/2t6CPkF/BL+c2TC/wvznvm5fhr9sDI4/9lWwvQmUjz2J28W/v4wvP9LDCD09lqa/grbVPxaW6T/PERm/sFovP+cOPz8jv6w+9yYJv/LS8r/aDWY/FaqEvzxii73GAoU/JL/OP2iHbj/LshU/xqDnvjI2Ub/quxI/xZ4lv73SXj/ao1s+/aCIPfLiiT+7ZaC/k7gvP2nyiz+EfWy/nHQ4v0uUWb+0k6u/38RlP0jFcj+ffg+/PuBxvzzUkD8TNx8/BORGP5yjeT+zR06/BmMwP7tABkAvj+g+wVGZv99VfD62UM4+LeNNv7pe9j91VsG8dEfoPphpIj8J89I/8Fp4vsOZ8b/g4wm/0n21v0wyojxNs4U+k0qDP9vCrr9qMHs/NrWEv1hPzr9Kb8S+O8ZYPvxlsr8CEgDAhLnrP58eD8CZvse+hokVPh8BOj9lPYW/GrkzP9XjaL+ZJEM/Bj8FP8mVXb8Enke/F/bFvkNXrT8ikQq+kAoVP998Wb82EP4/W2Mvv6mppL/zlLM/bTSlv3u1nb+4Fki/YDsSP7xt672px1A/THqdPKaPwj/Ria47XICDPrC1aD8l90U/24vdPiP0b77Iym2/UVeiPi4TYb8EXwHAdN6zP8d3eL9wrkO/muh2v5xOgz8x+A0/Kx9GPxBZa7/yvi4/dNO0Pz1IzD8pYGW/Ctahvx7hhT7qOt0/vmJQvw==\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"24ce0d0c-bfdc-484c-8290-0a0b0c4c517b\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"97c17b10-d205-441e-a30c-87fa5481a080\",\"type\":\"UnionRenderers\"}},\"id\":\"4cbf8488-f4c5-4d64-adc0-9a49b16f368b\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"below\":[{\"id\":\"c4380341-61e9-49fb-ac7e-305283ab4d6b\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"31e11c4e-c39a-4ebc-a2b1-40f519f7b28a\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"c4380341-61e9-49fb-ac7e-305283ab4d6b\",\"type\":\"LinearAxis\"},{\"id\":\"75250b97-3b18-4002-9f57-109774e23565\",\"type\":\"Grid\"},{\"id\":\"31e11c4e-c39a-4ebc-a2b1-40f519f7b28a\",\"type\":\"LinearAxis\"},{\"id\":\"9846fbef-aad9-4e7b-87e8-9a841f485966\",\"type\":\"Grid\"},{\"id\":\"615f1569-2b49-4044-840b-edefc00c9d27\",\"type\":\"BoxAnnotation\"},{\"id\":\"afac5316-b0ce-4c1a-b34b-69342e298fe1\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"6689bac0-726e-4f66-9f9c-90f87e5dedbb\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"db596f8f-6e86-4533-a286-da83db034c69\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"6734ac2e-5f71-4dca-b5dd-882ee3fbd24a\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"12f4e0d7-95e9-4c95-a425-c703345ae95e\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"ac1a169e-c123-4756-8dd3-a3495f27c4f5\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"68529e97-eed7-4f99-84cf-d91455138467\",\"type\":\"LinearScale\"}},\"id\":\"724bb008-36e4-4441-ae20-2fa7f78035d3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"97c17b10-d205-441e-a30c-87fa5481a080\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"3bc3f417-4b72-4a5b-92be-e1858587e63c\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"e4e3cb7e-cbcc-487b-a023-607414b5088a\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"724bb008-36e4-4441-ae20-2fa7f78035d3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ec0e79bb-8711-4e67-9d2c-0302ff2c5b67\",\"type\":\"BasicTicker\"}},\"id\":\"9846fbef-aad9-4e7b-87e8-9a841f485966\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"ec0e79bb-8711-4e67-9d2c-0302ff2c5b67\",\"type\":\"BasicTicker\"},{\"attributes\":{\"overlay\":{\"id\":\"615f1569-2b49-4044-840b-edefc00c9d27\",\"type\":\"BoxAnnotation\"}},\"id\":\"1bd20d33-c2b9-4dfd-93a4-cd9e20f4eb57\",\"type\":\"BoxZoomTool\"}],\"root_ids\":[\"724bb008-36e4-4441-ae20-2fa7f78035d3\"]},\"title\":\"Bokeh Application\",\"version\":\"0.13.0\"}};\n",
       "  var render_items = [{\"docid\":\"8f1d24df-c3fc-474c-968f-9c2e9843fac6\",\"roots\":{\"724bb008-36e4-4441-ae20-2fa7f78035d3\":\"2a4dac26-349f-4a9d-9314-e9da304e226d\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "724bb008-36e4-4441-ae20-2fa7f78035d3"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    output_notebook()\n",
    "    \n",
    "    if isinstance(color, str): \n",
    "        color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: \n",
    "        pl.show(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_tsne_projection(word_vectors):\n",
    "    tsne = TSNE(n_components=2, verbose=100)\n",
    "    return scale(tsne.fit_transform(word_vectors))\n",
    "    \n",
    "    \n",
    "def visualize_embeddings(embeddings, token):\n",
    "    tsne = get_tsne_projection(embeddings)\n",
    "    draw_vectors(tsne[:, 0], tsne[:, 1], token=token)\n",
    "    \n",
    "\n",
    "visualize_embeddings(embeddings, index2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgmDHM9Dl7W7"
   },
   "source": [
    "**Задание** Посчитайте эмбеддинги для всех слов из трейна и для нескольких случайных слов из теста, которые не встречаются в трейне, найдите их ближайших соседей по их эмбеддигам символьного уровня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bctty__mOOz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzAozOANpnT1"
   },
   "source": [
    "### Словные эмбеддинги\n",
    "\n",
    "**Задание** Только символьных эмбеддингов может быть недостаточно. Верните ещё словные эмбеддинги. Слова стоит приводить к нижнему регистру - признаки, связанные с регистром должны ухватываться символьный LSTM.\n",
    "\n",
    "Эти эмбеддинги можно просто сконкатенировать, можно складывать, а можно использовать гейт (как в LSTM). Например, по эмбеддингу слова предсказывать $o = \\sigma(w)$ - насколько он хорош и сочетать в такой пропорции с символьным эмбеддингом: $o \\odot w + (1 - o) \\odot \\tilde w$, где $\\tilde w$ - эмбеддинг слова, полученный по символьному уровню. Проверьте разные варианты.\n",
    "\n",
    "### Связь словных эмбеддингов и эмбеддингов символьного уровня\n",
    "В словных эмбеддингах мы строим отображение из слова в индекс. В итоге входной батч достаточно небольшой - это хорошо для обучения (быстрее передача на видеокарту). С символьными эмбеддингами беда - но это можно исправить.\n",
    "\n",
    "Давайте предпосчитаем для каждого слова в `word2ind` его последовательность индексов символов. Получится матрица. Эту матрицу можно вместе с моделью перенести на видеокарту. Тогда нужен будет батч из индексов слов - по нему можно сделать лукап (с помощью `F.embedding`) в матрице и получить трехмерную матрицу с символами.\n",
    "\n",
    "Преимущество - по одному батчу можно получить сразу и эмбеддинги слов, и эмбеддинги символьного уровня. Это удобно и энергоэффективно.\n",
    "\n",
    "Другая идея - после того, как мы обучили модель, можно предпосчитать эмбеддинги слов символьного уровня - лукап в таблице эмбеддингов гораздо проще, чем сверточная или рекуррентная сеть над символами. Таким образом, например, получаются эмбеддинги в [FastText](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) - они также исходно считаются на символьном (N-граммном) уровне."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gzxhGe6okls"
   },
   "source": [
    "## Encoder-decoder\n",
    "\n",
    "Можно усложнить модель - добавить еще один рекуррентный слой. Первый слой будет служить энкодером последовательности, второй, более легкий - декодировать последовательность. Декодировать - значит, на вход он должен принимать как состояние для данного токена из энкодера, так и предыдущий предсказанный тег.\n",
    "\n",
    "Выглядеть всё будет как-то так:\n",
    "\n",
    "![encoder-decoder](https://image.ibb.co/jOrfT0/Encoder-Decoder.png =x600)\n",
    "\n",
    "Зеленое - уже `LSTM`, а не `Linear`, а принимает оно сразу скрытое состояние от предыдущего токена (зеленая стрелка), предыдущий предсказанный тег (пунктирная стрелка) и состояние из BiLSTM - контекстное представление слова.\n",
    "\n",
    "Тренироваться данная модель должна с teacher-forcing - передачей правильных меток в качестве ответов по пунктирным стрелкам. На предсказании же нужно реализовать beam search - держать сразу несколько лучших путей (последовательностей тегов) для декодируемой последовательности.\n",
    "\n",
    "**Задание** Рискните реализовать это.\n",
    "\n",
    "(А вообще мы будем разбираться с этим подробнее, когда дойдем до машинного перевода - можно вернуться сюда после него :) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEJAch5Bj4vQ"
   },
   "source": [
    "# Дополнительные материалы\n",
    "\n",
    "## Классические подходы\n",
    "Speech and Language Processing, Chapter 8, Part-of-speech Tagging. Daniel Jurafsky [[pdf](https://web.stanford.edu/~jurafsky/slp3/8.pdf)]\n",
    "\n",
    "## Статьи\n",
    "Learning Character-level Representations for Part-of-Speech Tagging, dos Santos et al, 2014 [pdf](http://proceedings.mlr.press/v32/santos14.pdf)  \n",
    "Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation, Wang Ling et al, 2015 [arxiv](https://arxiv.org/abs/1508.02096)  \n",
    "Bidirectional LSTM-CRF Models for Sequence Tagging, Zhiheng Huang et al, 2015 [arxiv](https://arxiv.org/abs/1508.01991)  \n",
    "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF, Xuezhe Ma et al, 2016 [arxiv](https://arxiv.org/abs/1603.01354)  \n",
    "Improving Part-of-speech Tagging via Multi-task Learning and Character-level Word Representations, Daniil Anastasyev et al, 2018 [pdf](http://www.dialog-21.ru/media/4282/anastasyevdg.pdf) :)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8WVAmMWqsrS"
   },
   "source": [
    "# Сдача\n",
    "\n",
    "[Опрос](https://goo.gl/forms/R6UqcESWIjtVSA6J3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 06 - RNNs, part 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
